{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bcfb71-06cb-4875-a056-d0c6e7a1e03f",
   "metadata": {},
   "source": [
    "# <font size=5> <strong>Heart Disease Prediction - AblationStudy(SMOTE)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f549498-ec6a-486b-a9fa-8bc07bd6aa5b",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbabcdc4-2528-4d97-a565-6b91d0b0633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: C:/Users/prosp/AIgroup4/Group4_HeartDiseasePrediciton/mlp_tuning\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Directory path you want to delete\n",
    "dir_path = 'C:/Users/prosp/AIgroup4/Group4_HeartDiseasePrediciton/mlp_tuning'\n",
    "# Delete the directory and its contents\n",
    "if os.path.exists(dir_path):\n",
    "    shutil.rmtree(dir_path)  # Deletes the directory and all its contents\n",
    "    print(f\"Deleted: {dir_path}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {dir_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d3eb7e-461a-4535-821a-ef64396d461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import(accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
    "                            auc, confusion_matrix, classification_report, make_scorer)\n",
    "\n",
    "# Modeling â€“ XGBoost and TabNet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "import random\n",
    "import os\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a94f5b-532a-4c85-b045-0754856c43e1",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed5e14-1c39-4cd1-b6a0-f7175bdf4f3d",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae88cdd-d479-4855-837e-85e887c863f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_csv(\"Cleveland+Hungary+VA_long_beach+Switzerland.csv\") # Source domain = multi-hospital dataset\n",
    "df_B = pd.read_csv(\"Heart_disease_cleveland.csv\")                     # Target domain = original Cleveland dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4042b1b-b974-4412-9a46-ad17daa5779f",
   "metadata": {},
   "source": [
    "### Exploring and Inspecting Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154cc2bf-576d-4b87-9108-5892e1736f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 919 entries, 0 to 918\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        919 non-null    int64  \n",
      " 1   age       919 non-null    int64  \n",
      " 2   sex       919 non-null    object \n",
      " 3   dataset   919 non-null    object \n",
      " 4   cp        919 non-null    object \n",
      " 5   trestbps  919 non-null    float64\n",
      " 6   chol      919 non-null    float64\n",
      " 7   fbs       919 non-null    bool   \n",
      " 8   restecg   919 non-null    object \n",
      " 9   thalch    919 non-null    float64\n",
      " 10  exang     919 non-null    bool   \n",
      " 11  oldpeak   919 non-null    float64\n",
      " 12  slope     919 non-null    object \n",
      " 13  ca        919 non-null    float64\n",
      " 14  thal      919 non-null    object \n",
      " 15  num       919 non-null    int64  \n",
      "dtypes: bool(2), float64(5), int64(3), object(6)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_A.info() # Displays concise summary of DataFrame A: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4569bfa4-2b5a-4e51-b930-0695fb312a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_B.info() # Displays concise summary of DataFrame B: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e990a-d349-4170-bb43-96a53e2a7ede",
   "metadata": {},
   "source": [
    "##### Cleaning and harmonizing information in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9653ec03-f608-4290-82f6-d6a39b3ef5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets before preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m                       0               1                  2\n",
      "id                     1               2                  3\n",
      "age                   63              67                 67\n",
      "sex                 Male            Male               Male\n",
      "dataset        Cleveland       Cleveland          Cleveland\n",
      "cp        typical angina    asymptomatic       asymptomatic\n",
      "trestbps           145.0           160.0              120.0\n",
      "chol               233.0           286.0              229.0\n",
      "fbs                 True           False              False\n",
      "restecg   lv hypertrophy  lv hypertrophy     lv hypertrophy\n",
      "thalch             150.0           108.0              129.0\n",
      "exang              False            True               True\n",
      "oldpeak              2.3             1.5                2.6\n",
      "slope        downsloping            flat               flat\n",
      "ca                   0.0             3.0                2.0\n",
      "thal        fixed defect          normal  reversable defect\n",
      "num                    0               2                  1\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "age        63.0   67.0   67.0\n",
      "sex         1.0    1.0    1.0\n",
      "cp          0.0    3.0    3.0\n",
      "trestbps  145.0  160.0  120.0\n",
      "chol      233.0  286.0  229.0\n",
      "fbs         1.0    0.0    0.0\n",
      "restecg     2.0    2.0    2.0\n",
      "thalach   150.0  108.0  129.0\n",
      "exang       0.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "slope       2.0    1.0    1.0\n",
      "ca          0.0    3.0    2.0\n",
      "thal        2.0    1.0    3.0\n",
      "target      0.0    1.0    1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets before preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2df8ede-ec12-435d-96b3-69ea3f3ba6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Cleveland data from df_A before pretraining\n",
    "df_A = df_A[df_A['dataset'] != 'Cleveland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f871dd-ca19-4a0c-a2f0-5bf65455002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
      "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
      "      dtype='object')\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_A.columns) # Prints the list of column names in DataFrame A.\n",
    "print(df_B.columns) # Prints the list of column names in DataFrame B."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edb2754-fbd5-44da-a9a9-310d6f34d472",
   "metadata": {},
   "source": [
    "1. We inspected the datasets using df.info(), df.columns, and df.head().\n",
    "#    Observations from Dataset A (combined multi-hospital dataset):\n",
    "- Many categorical columns (sex, cp, fbs, restecg, slope, thal, exang) are strings/booleans.\n",
    "- Some numeric columns have missing values (trestbps, chol, thalach, oldpeak, ca).\n",
    "- Column names differ from Dataset B (e.g., 'thalch' vs 'thalach', 'num' vs 'target').\n",
    "- Extra columns exist (e.g., 'id', 'dataset') that are irrelevant for modeling.\n",
    "- The target column uses 0â€“4 scale instead of 0/1 like Dataset B.\n",
    "\n",
    "#    Observations from Dataset B (Cleveland dataset):\n",
    "- All categorical columns are already numeric (int64), matching expected encoding.\n",
    "- No missing values.\n",
    "- Target column is binary (0=no disease, 1=disease).\n",
    "\n",
    "2. Based on these observations, the following harmonization steps are necessary:\n",
    "- Rename columns in Dataset A to match Dataset B.\n",
    "- Drop irrelevant columns in Dataset A (id, dataset).\n",
    "- Map all categorical strings/booleans in Dataset A to numeric codes matching Dataset B.\n",
    "- Fill missing values: \n",
    "#           â€¢ Categorical â†’ mode of column\n",
    "#           â€¢ Numeric â†’ median of column\n",
    "- Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "- Align features so both datasets have identical column names and encodings.\n",
    "\n",
    "3. Purpose:\n",
    "- Ensure that Dataset A (pretraining) and Dataset B (fine-tuning) are fully compatible.\n",
    "- Prevent encoding mismatches that would break transfer learning.\n",
    "- Guarantee that the XGBoost model receives numeric input for all features.\n",
    "- Maintain consistency for feature importance and SHAP explainability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856b1cf3-d252-4c47-a02e-1450c084d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.rename(columns={'thalch': 'thalach','num': 'target'}) #Rename columns in Dataset A to match Dataset B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0bc1c1-cea8-40ab-b12e-5e694f524027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.drop(columns=['id', 'dataset']) #Drop irrelevant columns in Dataset A (id, dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1915aeb1-8cdf-4f58-a0a6-20c303b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "df_A['target'] = df_A['target'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae38850-7e49-4efc-b2e2-ccb20ca3da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all categorical strings/booleans in Dataset A to numeric codes matching the target domain.\n",
    "sex_map = {'Male': 1, 'Female': 0}\n",
    "\n",
    "cp_map = {\n",
    "    'typical angina': 0,\n",
    "    'atypical angina': 1,\n",
    "    'non-anginal': 2,\n",
    "    'asymptomatic': 3\n",
    "}\n",
    "\n",
    "fbs_map = {True: 1, False: 0}\n",
    "\n",
    "restecg_map = {\n",
    "    'normal': 0,\n",
    "    'st-t abnormality': 1,\n",
    "    'lv hypertrophy': 2\n",
    "}\n",
    "\n",
    "exang_map = {True: 1, False: 0}\n",
    "\n",
    "slope_map = {\n",
    "    'upsloping': 0,\n",
    "    'flat': 1,\n",
    "    'downsloping': 2\n",
    "}\n",
    "\n",
    "thal_map = {\n",
    "    'normal': 1,\n",
    "    'fixed defect': 2,\n",
    "    'reversable defect': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2ac638-c3d6-4ad2-b138-6de8b87454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features so both datasets have identical column names and encodings.\n",
    "df_A['sex'] = df_A['sex'].map(sex_map)\n",
    "df_A['cp'] = df_A['cp'].map(cp_map)\n",
    "df_A['fbs'] = df_A['fbs'].map(fbs_map)\n",
    "df_A['restecg'] = df_A['restecg'].map(restecg_map)\n",
    "df_A['exang'] = df_A['exang'].map(exang_map)\n",
    "df_A['slope'] = df_A['slope'].map(slope_map)\n",
    "df_A['thal'] = df_A['thal'].map(thal_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e875d2bd-fdd7-4f55-98d3-b73e4b58589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Check (Both should return zero missing values.)\n",
    "print(df_A.isnull().sum())\n",
    "print(df_B.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed95ab7-b7dd-4f15-be3c-fb4b6bf2c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       615 non-null    int64  \n",
      " 1   sex       615 non-null    int64  \n",
      " 2   cp        615 non-null    int64  \n",
      " 3   trestbps  615 non-null    float64\n",
      " 4   chol      615 non-null    float64\n",
      " 5   fbs       615 non-null    int64  \n",
      " 6   restecg   615 non-null    int64  \n",
      " 7   thalach   615 non-null    float64\n",
      " 8   exang     615 non-null    int64  \n",
      " 9   oldpeak   615 non-null    float64\n",
      " 10  slope     615 non-null    int64  \n",
      " 11  ca        615 non-null    float64\n",
      " 12  thal      615 non-null    int64  \n",
      " 13  target    615 non-null    int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 72.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the target domain to ensure all columns are non-null.\n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bd4404-68aa-497c-8c21-7b57d80c56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the source domain to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969b614-5aed-4a91-8584-7309764272e7",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6b773-fed8-4de1-ba04-349f3ad7de80",
   "metadata": {},
   "source": [
    "What to Look For:\n",
    "\n",
    "Similar Feature Correlations: If the correlations between the target variable and the features are similar in both datasets, that suggests that the features carry similar predictive power in both datasets. This means that the pre-trained model could transfer knowledge effectively to the Cleveland dataset during fine-tuning.\n",
    "\n",
    "Discrepant Feature Correlations: If the correlations are significantly different between the two datasets, it may indicate that the relationship between the features and the target is dataset-specific, which could make transfer learning less effective. For example, a feature with a strong correlation with the target in Dataset A but weak or no correlation in Dataset B may not transfer well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a10497-d1e8-414a-8e12-c60d87a4fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for Dataset A:\n",
      "target      1.000000\n",
      "cp          0.495185\n",
      "ca          0.491253\n",
      "exang       0.444419\n",
      "slope       0.441124\n",
      "thal        0.432714\n",
      "oldpeak     0.368210\n",
      "thalach     0.345887\n",
      "age         0.326379\n",
      "sex         0.302330\n",
      "chol        0.268136\n",
      "fbs         0.150083\n",
      "trestbps    0.099018\n",
      "restecg     0.086977\n",
      "Name: target, dtype: float64\n",
      "Correlation for Dataset B:\n",
      "target      1.000000\n",
      "thal        0.515894\n",
      "ca          0.460033\n",
      "exang       0.431894\n",
      "oldpeak     0.424510\n",
      "thalach     0.417167\n",
      "cp          0.414446\n",
      "slope       0.339213\n",
      "sex         0.276816\n",
      "age         0.223120\n",
      "restecg     0.169202\n",
      "trestbps    0.150825\n",
      "chol        0.085164\n",
      "fbs         0.025264\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlation between each feature and the target for Dataset A\n",
    "corr_A = df_A.corr()[\"target\"].abs().sort_values(ascending=False)\n",
    "\n",
    "# Calculate correlation between each feature and the target for Dataset B\n",
    "corr_B = df_B.corr()[\"target\"].abs().sort_values(ascending=False)\n",
    "\n",
    "# Show the correlation for each dataset\n",
    "print(\"Correlation for Dataset A:\")\n",
    "print(corr_A)\n",
    "\n",
    "print(\"Correlation for Dataset B:\")\n",
    "print(corr_B)\n",
    "# Selected features: ['sex', 'cp', 'ca', 'trestbps', 'oldpeak', 'restecg', 'exang', 'target', 'age', 'thalach', 'thal', 'slope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df2c792b-75b2-47e3-aab3-59eefc90386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['trestbps', 'ca', 'cp', 'sex', 'thalach', 'age', 'target', 'exang', 'thal', 'slope', 'oldpeak', 'restecg']\n"
     ]
    }
   ],
   "source": [
    "# Compute *signed* correlations\n",
    "corr_A = df_A.corr()[\"target\"].sort_values(ascending=False)\n",
    "corr_B = df_B.corr()[\"target\"].sort_values(ascending=False)\n",
    "\n",
    "# Threshold (tunable)\n",
    "corr_diff_threshold = 0.1  # Relaxed threshold to include more features\n",
    "direction_consistency = False  # Don't require the same direction for correlation\n",
    "\n",
    "# Initialize a list for similar features\n",
    "similar_features = []\n",
    "\n",
    "for feature in corr_A.index:\n",
    "    if feature in corr_B.index:\n",
    "        diff = abs(corr_A[feature] - corr_B[feature])\n",
    "        \n",
    "        # Check if the correlation difference is below the threshold\n",
    "        if diff < corr_diff_threshold:\n",
    "            similar_features.append(feature)\n",
    "\n",
    "\n",
    "high_corr_threshold = 0.3  # Set threshold for \"high correlation\" with the target\n",
    "\n",
    "# Add features with high correlation with the target in either dataset\n",
    "for feature in set(corr_A.index).union(corr_B.index):\n",
    "    if feature in corr_A.index and corr_A[feature] >= high_corr_threshold:\n",
    "        similar_features.append(feature)\n",
    "    if feature in corr_B.index and corr_B[feature] >= high_corr_threshold:\n",
    "        similar_features.append(feature)\n",
    "\n",
    "# Remove duplicate features from the final list\n",
    "similar_features = list(set(similar_features))\n",
    "\n",
    "print(\"Selected features:\", similar_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86fb3b16-01a1-442c-b380-b9da5bca3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new datasets with only the selected features\n",
    "df_A = df_A[similar_features]\n",
    "df_B = df_B[similar_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "942f2971-925d-45e2-a4cb-c175fb3f4785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trestbps</th>\n",
       "      <th>ca</th>\n",
       "      <th>cp</th>\n",
       "      <th>sex</th>\n",
       "      <th>thalach</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "      <th>exang</th>\n",
       "      <th>thal</th>\n",
       "      <th>slope</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>restecg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>133.209366</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>2.297561</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>130.435220</td>\n",
       "      <td>53.092683</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>2.347967</td>\n",
       "      <td>0.808130</td>\n",
       "      <td>0.942377</td>\n",
       "      <td>0.414634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.305233</td>\n",
       "      <td>0.689712</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.364778</td>\n",
       "      <td>24.077586</td>\n",
       "      <td>9.544659</td>\n",
       "      <td>0.490297</td>\n",
       "      <td>0.499294</td>\n",
       "      <td>0.887421</td>\n",
       "      <td>0.578326</td>\n",
       "      <td>1.099715</td>\n",
       "      <td>0.611066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>142.450000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         trestbps          ca          cp         sex     thalach         age  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean   133.209366    0.422764    2.297561    0.842276  130.435220   53.092683   \n",
       "std     18.305233    0.689712    0.913655    0.364778   24.077586    9.544659   \n",
       "min     80.000000    0.000000    0.000000    0.000000   60.000000   29.000000   \n",
       "25%    120.000000    0.000000    2.000000    1.000000  116.000000   47.000000   \n",
       "50%    130.000000    0.000000    3.000000    1.000000  129.000000   54.000000   \n",
       "75%    142.450000    1.000000    3.000000    1.000000  148.000000   60.000000   \n",
       "max    200.000000    2.000000    3.000000    1.000000  190.000000   77.000000   \n",
       "\n",
       "           target       exang        thal       slope     oldpeak     restecg  \n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000  \n",
       "mean     0.600000    0.466667    2.347967    0.808130    0.942377    0.414634  \n",
       "std      0.490297    0.499294    0.887421    0.578326    1.099715    0.611066  \n",
       "min      0.000000    0.000000    1.000000    0.000000   -2.600000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    3.000000    1.000000    0.700000    0.000000  \n",
       "75%      1.000000    1.000000    3.000000    1.000000    2.000000    1.000000  \n",
       "max      1.000000    1.000000    3.000000    2.000000    5.000000    2.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measure about the dataset A\n",
    "df_A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93a17240-a2d2-4928-8760-ae4a4e1c2004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trestbps</th>\n",
       "      <th>ca</th>\n",
       "      <th>cp</th>\n",
       "      <th>sex</th>\n",
       "      <th>thalach</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "      <th>exang</th>\n",
       "      <th>thal</th>\n",
       "      <th>slope</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>restecg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>131.689769</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>2.158416</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.458746</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.831683</td>\n",
       "      <td>0.600660</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>0.990099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.599748</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.499120</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>0.956705</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.994971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         trestbps          ca          cp         sex     thalach         age  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean   131.689769    0.663366    2.158416    0.679868  149.607261   54.438944   \n",
       "std     17.599748    0.934375    0.960126    0.467299   22.875003    9.038662   \n",
       "min     94.000000    0.000000    0.000000    0.000000   71.000000   29.000000   \n",
       "25%    120.000000    0.000000    2.000000    0.000000  133.500000   48.000000   \n",
       "50%    130.000000    0.000000    2.000000    1.000000  153.000000   56.000000   \n",
       "75%    140.000000    1.000000    3.000000    1.000000  166.000000   61.000000   \n",
       "max    200.000000    3.000000    3.000000    1.000000  202.000000   77.000000   \n",
       "\n",
       "           target       exang        thal       slope     oldpeak     restecg  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.458746    0.326733    1.831683    0.600660    1.039604    0.990099  \n",
       "std      0.499120    0.469794    0.956705    0.616226    1.161075    0.994971  \n",
       "min      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    1.000000    1.000000    0.800000    1.000000  \n",
       "75%      1.000000    1.000000    3.000000    1.000000    1.600000    2.000000  \n",
       "max      1.000000    1.000000    3.000000    2.000000    6.200000    2.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measure about the dataset B\n",
    "df_B.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a6f21b3-09fa-4906-bcd0-787cec6e8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleanedup dataset A\n",
    "df_A.to_csv(\"Preprocessed_Cleveland+Hungary+VA_long_beach+Switzerland.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1379d430-3f33-4601-b561-d88b27bfb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleanedup dataset B\n",
    "df_B.to_csv(\"Preprocessed_Heart_disease_cleveland.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d65ebbf-ecdc-4821-9ae1-fd383ac64e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets after preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m            304    305    306\n",
      "trestbps  120.0  140.0  170.0\n",
      "ca          0.0    0.0    0.0\n",
      "cp          1.0    1.0    0.0\n",
      "sex         1.0    1.0    0.0\n",
      "thalach   160.0  170.0  170.0\n",
      "age        29.0   29.0   30.0\n",
      "target      0.0    0.0    0.0\n",
      "exang       0.0    0.0    0.0\n",
      "thal        1.0    1.0    2.0\n",
      "slope       0.0    0.0    0.0\n",
      "oldpeak     0.0    0.0    0.0\n",
      "restecg     0.0    0.0    1.0\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "trestbps  145.0  160.0  120.0\n",
      "ca          0.0    3.0    2.0\n",
      "cp          0.0    3.0    3.0\n",
      "sex         1.0    1.0    1.0\n",
      "thalach   150.0  108.0  129.0\n",
      "age        63.0   67.0   67.0\n",
      "target      0.0    1.0    1.0\n",
      "exang       0.0    1.0    1.0\n",
      "thal        2.0    1.0    3.0\n",
      "slope       2.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "restecg     2.0    2.0    2.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets after preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2989af38-42d7-4737-877a-165b905ea3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   trestbps  615 non-null    float64\n",
      " 1   ca        615 non-null    float64\n",
      " 2   cp        615 non-null    int64  \n",
      " 3   sex       615 non-null    int64  \n",
      " 4   thalach   615 non-null    float64\n",
      " 5   age       615 non-null    int64  \n",
      " 6   target    615 non-null    int64  \n",
      " 7   exang     615 non-null    int64  \n",
      " 8   thal      615 non-null    int64  \n",
      " 9   slope     615 non-null    int64  \n",
      " 10  oldpeak   615 non-null    float64\n",
      " 11  restecg   615 non-null    int64  \n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 62.5 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for dataset A to ensure all columns are non-null. \n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a42ddf0-70a5-4544-becd-878ea6d9fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   trestbps  303 non-null    int64  \n",
      " 1   ca        303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   sex       303 non-null    int64  \n",
      " 4   thalach   303 non-null    int64  \n",
      " 5   age       303 non-null    int64  \n",
      " 6   target    303 non-null    int64  \n",
      " 7   exang     303 non-null    int64  \n",
      " 8   thal      303 non-null    int64  \n",
      " 9   slope     303 non-null    int64  \n",
      " 10  oldpeak   303 non-null    float64\n",
      " 11  restecg   303 non-null    int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 28.5 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for dataset B to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159229f-e4d9-4664-8d8f-e1580b957da5",
   "metadata": {},
   "source": [
    "## 3. Data split and NO class imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d69b4881-6507-4e0d-97c5-f4669664b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain = df_A.drop('target', axis=1) \n",
    "y_pretrain = df_A['target']               \n",
    "\n",
    "# Split the source domain into 80% train and 20% temp (for val+test)\n",
    "X_pretrain_train, X_pretrain_temp, y_pretrain_train, y_pretrain_temp = train_test_split(\n",
    "    X_pretrain, y_pretrain,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test)\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test â†’ each 10% of total\n",
    "X_pretrain_val, X_pretrain_test, y_pretrain_val, y_pretrain_test = train_test_split(\n",
    "    X_pretrain_temp, y_pretrain_temp,\n",
    "    test_size=0.5,          # half of temp = 10% of total\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain_temp\n",
    ")\n",
    "\n",
    "# Target domain: Cleveland dataset for FINE-TUNING and evaluation\n",
    "X_finetune = df_B.drop('target', axis=1)\n",
    "y_finetune = df_B['target']\n",
    "\n",
    "\n",
    "# Split target domain into 80% train and 20% temp (for val+test)\n",
    "X_finetune_train, X_finetune_temp, y_finetune_train, y_finetune_temp = train_test_split(\n",
    "    X_finetune, y_finetune,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test) \n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune     # preserve class distribution\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test â†’ each 10% of total\n",
    "X_finetune_val, X_finetune_test, y_finetune_val, y_finetune_test = train_test_split(\n",
    "    X_finetune_temp, y_finetune_temp,\n",
    "    test_size=0.5,          # 20% of training data will be used as the validation set\n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune_temp  # preserve class distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "260d9c15-74da-40eb-a352-35ea458bc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ðŸ“Š Source Domain Shapes ##\n",
      "---\n",
      "X_pretrain_train shape: (492, 11)\n",
      "X_pretrain_val   shape: (61, 11)\n",
      "X_pretrain_test  shape: (62, 11)\n",
      "Total X rows: 615\n",
      "\n",
      "\n",
      "y_pretrain_train shape: (492,)\n",
      "y_pretrain_val   shape: (61,)\n",
      "y_pretrain_test  shape: (62,)\n",
      "\n",
      "## ðŸŽ¯ Target Domain Shapes ##\n",
      "---\n",
      "X_finetune_train shape: (242, 11)\n",
      "X_finetune_val   shape: (30, 11)\n",
      "X_finetune_test  shape: (31, 11)\n",
      "Total X rows: 303\n",
      "\n",
      "\n",
      "y_finetune_train shape: (242,)\n",
      "y_finetune_val   shape: (30,)\n",
      "y_finetune_test  shape: (31,)\n"
     ]
    }
   ],
   "source": [
    "print(\"## ðŸ“Š Source Domain Shapes ##\")\n",
    "print(\"---\")\n",
    "\n",
    "# Feature Matrix (X) Shapes\n",
    "print(\"X_pretrain_train shape:\", X_pretrain_train.shape)\n",
    "print(\"X_pretrain_val   shape:\", X_pretrain_val.shape)\n",
    "print(\"X_pretrain_test  shape:\", X_pretrain_test.shape)\n",
    "print(\"Total X rows:\", \n",
    "      X_pretrain_train.shape[0] + X_pretrain_val.shape[0] + X_pretrain_test.shape[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Target Vector (y) Shapes\n",
    "print(\"y_pretrain_train shape:\", y_pretrain_train.shape)\n",
    "print(\"y_pretrain_val   shape:\", y_pretrain_val.shape)\n",
    "print(\"y_pretrain_test  shape:\", y_pretrain_test.shape)\n",
    "\n",
    "\n",
    "## --- Target domain Splits ---\n",
    "print(\"\\n## ðŸŽ¯ Target Domain Shapes ##\")\n",
    "print(\"---\")\n",
    "\n",
    "# Feature Matrix (X) Shapes\n",
    "print(\"X_finetune_train shape:\", X_finetune_train.shape)\n",
    "print(\"X_finetune_val   shape:\", X_finetune_val.shape)\n",
    "print(\"X_finetune_test  shape:\", X_finetune_test.shape)\n",
    "print(\"Total X rows:\", \n",
    "      X_finetune_train.shape[0] + X_finetune_val.shape[0] + X_finetune_test.shape[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Target Vector (y) Shapes\n",
    "print(\"y_finetune_train shape:\", y_finetune_train.shape)\n",
    "print(\"y_finetune_val   shape:\", y_finetune_val.shape)\n",
    "print(\"y_finetune_test  shape:\", y_finetune_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21018af5-37a7-4e67-878e-39dfb70cb439",
   "metadata": {},
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a6b5e-ed72-44d9-afb4-d1c9a756ceb7",
   "metadata": {},
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb972dad-3d65-4aa5-9a35-17ef70094585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best parameters found during the Grid Search for pretraining on Dataset A\n",
    "best_pretrain_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 0.5, \n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Best parameters for pretraining: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6,\n",
    "#                                   'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
    "# Best F1-score: 0.8647\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ff71334-005f-4c43-85e7-ad7ef8d86ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.01\n",
      "  max_depth: 8\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 0.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.66587\n",
      "[1]\tvalidation_0-logloss:0.66229\n",
      "[2]\tvalidation_0-logloss:0.65758\n",
      "[3]\tvalidation_0-logloss:0.65300\n",
      "[4]\tvalidation_0-logloss:0.64897\n",
      "[5]\tvalidation_0-logloss:0.64469\n",
      "[6]\tvalidation_0-logloss:0.64122\n",
      "[7]\tvalidation_0-logloss:0.63743\n",
      "[8]\tvalidation_0-logloss:0.63395\n",
      "[9]\tvalidation_0-logloss:0.63069\n",
      "[10]\tvalidation_0-logloss:0.62659\n",
      "[11]\tvalidation_0-logloss:0.62355\n",
      "[12]\tvalidation_0-logloss:0.62033\n",
      "[13]\tvalidation_0-logloss:0.61637\n",
      "[14]\tvalidation_0-logloss:0.61256\n",
      "[15]\tvalidation_0-logloss:0.60883\n",
      "[16]\tvalidation_0-logloss:0.60551\n",
      "[17]\tvalidation_0-logloss:0.60221\n",
      "[18]\tvalidation_0-logloss:0.59831\n",
      "[19]\tvalidation_0-logloss:0.59533\n",
      "[20]\tvalidation_0-logloss:0.59269\n",
      "[21]\tvalidation_0-logloss:0.58923\n",
      "[22]\tvalidation_0-logloss:0.58723\n",
      "[23]\tvalidation_0-logloss:0.58555\n",
      "[24]\tvalidation_0-logloss:0.58348\n",
      "[25]\tvalidation_0-logloss:0.58105\n",
      "[26]\tvalidation_0-logloss:0.57777\n",
      "[27]\tvalidation_0-logloss:0.57488\n",
      "[28]\tvalidation_0-logloss:0.57199\n",
      "[29]\tvalidation_0-logloss:0.56926\n",
      "[30]\tvalidation_0-logloss:0.56692\n",
      "[31]\tvalidation_0-logloss:0.56496\n",
      "[32]\tvalidation_0-logloss:0.56302\n",
      "[33]\tvalidation_0-logloss:0.56120\n",
      "[34]\tvalidation_0-logloss:0.55903\n",
      "[35]\tvalidation_0-logloss:0.55716\n",
      "[36]\tvalidation_0-logloss:0.55500\n",
      "[37]\tvalidation_0-logloss:0.55374\n",
      "[38]\tvalidation_0-logloss:0.55100\n",
      "[39]\tvalidation_0-logloss:0.54870\n",
      "[40]\tvalidation_0-logloss:0.54674\n",
      "[41]\tvalidation_0-logloss:0.54482\n",
      "[42]\tvalidation_0-logloss:0.54265\n",
      "[43]\tvalidation_0-logloss:0.54031\n",
      "[44]\tvalidation_0-logloss:0.53791\n",
      "[45]\tvalidation_0-logloss:0.53579\n",
      "[46]\tvalidation_0-logloss:0.53338\n",
      "[47]\tvalidation_0-logloss:0.53157\n",
      "[48]\tvalidation_0-logloss:0.53044\n",
      "[49]\tvalidation_0-logloss:0.52850\n",
      "[50]\tvalidation_0-logloss:0.52761\n",
      "[51]\tvalidation_0-logloss:0.52564\n",
      "[52]\tvalidation_0-logloss:0.52294\n",
      "[53]\tvalidation_0-logloss:0.52095\n",
      "[54]\tvalidation_0-logloss:0.51936\n",
      "[55]\tvalidation_0-logloss:0.51764\n",
      "[56]\tvalidation_0-logloss:0.51591\n",
      "[57]\tvalidation_0-logloss:0.51451\n",
      "[58]\tvalidation_0-logloss:0.51271\n",
      "[59]\tvalidation_0-logloss:0.51026\n",
      "[60]\tvalidation_0-logloss:0.50912\n",
      "[61]\tvalidation_0-logloss:0.50764\n",
      "[62]\tvalidation_0-logloss:0.50646\n",
      "[63]\tvalidation_0-logloss:0.50456\n",
      "[64]\tvalidation_0-logloss:0.50322\n",
      "[65]\tvalidation_0-logloss:0.50250\n",
      "[66]\tvalidation_0-logloss:0.50032\n",
      "[67]\tvalidation_0-logloss:0.49862\n",
      "[68]\tvalidation_0-logloss:0.49752\n",
      "[69]\tvalidation_0-logloss:0.49655\n",
      "[70]\tvalidation_0-logloss:0.49533\n",
      "[71]\tvalidation_0-logloss:0.49365\n",
      "[72]\tvalidation_0-logloss:0.49247\n",
      "[73]\tvalidation_0-logloss:0.49070\n",
      "[74]\tvalidation_0-logloss:0.48861\n",
      "[75]\tvalidation_0-logloss:0.48810\n",
      "[76]\tvalidation_0-logloss:0.48633\n",
      "[77]\tvalidation_0-logloss:0.48439\n",
      "[78]\tvalidation_0-logloss:0.48359\n",
      "[79]\tvalidation_0-logloss:0.48239\n",
      "[80]\tvalidation_0-logloss:0.48101\n",
      "[81]\tvalidation_0-logloss:0.47988\n",
      "[82]\tvalidation_0-logloss:0.47949\n",
      "[83]\tvalidation_0-logloss:0.47789\n",
      "[84]\tvalidation_0-logloss:0.47645\n",
      "[85]\tvalidation_0-logloss:0.47580\n",
      "[86]\tvalidation_0-logloss:0.47420\n",
      "[87]\tvalidation_0-logloss:0.47381\n",
      "[88]\tvalidation_0-logloss:0.47260\n",
      "[89]\tvalidation_0-logloss:0.47129\n",
      "[90]\tvalidation_0-logloss:0.47032\n",
      "[91]\tvalidation_0-logloss:0.46983\n",
      "[92]\tvalidation_0-logloss:0.46874\n",
      "[93]\tvalidation_0-logloss:0.46779\n",
      "[94]\tvalidation_0-logloss:0.46685\n",
      "[95]\tvalidation_0-logloss:0.46633\n",
      "[96]\tvalidation_0-logloss:0.46506\n",
      "[97]\tvalidation_0-logloss:0.46463\n",
      "[98]\tvalidation_0-logloss:0.46373\n",
      "[99]\tvalidation_0-logloss:0.46345\n",
      "[100]\tvalidation_0-logloss:0.46257\n",
      "[101]\tvalidation_0-logloss:0.46136\n",
      "[102]\tvalidation_0-logloss:0.46058\n",
      "[103]\tvalidation_0-logloss:0.46003\n",
      "[104]\tvalidation_0-logloss:0.45896\n",
      "[105]\tvalidation_0-logloss:0.45774\n",
      "[106]\tvalidation_0-logloss:0.45692\n",
      "[107]\tvalidation_0-logloss:0.45574\n",
      "[108]\tvalidation_0-logloss:0.45524\n",
      "[109]\tvalidation_0-logloss:0.45538\n",
      "[110]\tvalidation_0-logloss:0.45454\n",
      "[111]\tvalidation_0-logloss:0.45411\n",
      "[112]\tvalidation_0-logloss:0.45302\n",
      "[113]\tvalidation_0-logloss:0.45276\n",
      "[114]\tvalidation_0-logloss:0.45167\n",
      "[115]\tvalidation_0-logloss:0.45046\n",
      "[116]\tvalidation_0-logloss:0.44960\n",
      "[117]\tvalidation_0-logloss:0.44936\n",
      "[118]\tvalidation_0-logloss:0.44825\n",
      "[119]\tvalidation_0-logloss:0.44781\n",
      "[120]\tvalidation_0-logloss:0.44679\n",
      "[121]\tvalidation_0-logloss:0.44588\n",
      "[122]\tvalidation_0-logloss:0.44481\n",
      "[123]\tvalidation_0-logloss:0.44385\n",
      "[124]\tvalidation_0-logloss:0.44348\n",
      "[125]\tvalidation_0-logloss:0.44317\n",
      "[126]\tvalidation_0-logloss:0.44288\n",
      "[127]\tvalidation_0-logloss:0.44247\n",
      "[128]\tvalidation_0-logloss:0.44194\n",
      "[129]\tvalidation_0-logloss:0.44149\n",
      "[130]\tvalidation_0-logloss:0.44073\n",
      "[131]\tvalidation_0-logloss:0.44017\n",
      "[132]\tvalidation_0-logloss:0.43938\n",
      "[133]\tvalidation_0-logloss:0.43895\n",
      "[134]\tvalidation_0-logloss:0.43867\n",
      "[135]\tvalidation_0-logloss:0.43759\n",
      "[136]\tvalidation_0-logloss:0.43666\n",
      "[137]\tvalidation_0-logloss:0.43597\n",
      "[138]\tvalidation_0-logloss:0.43502\n",
      "[139]\tvalidation_0-logloss:0.43468\n",
      "[140]\tvalidation_0-logloss:0.43450\n",
      "[141]\tvalidation_0-logloss:0.43435\n",
      "[142]\tvalidation_0-logloss:0.43363\n",
      "[143]\tvalidation_0-logloss:0.43256\n",
      "[144]\tvalidation_0-logloss:0.43236\n",
      "[145]\tvalidation_0-logloss:0.43113\n",
      "[146]\tvalidation_0-logloss:0.43066\n",
      "[147]\tvalidation_0-logloss:0.42994\n",
      "[148]\tvalidation_0-logloss:0.42919\n",
      "[149]\tvalidation_0-logloss:0.42847\n",
      "[150]\tvalidation_0-logloss:0.42799\n",
      "[151]\tvalidation_0-logloss:0.42749\n",
      "[152]\tvalidation_0-logloss:0.42743\n",
      "[153]\tvalidation_0-logloss:0.42658\n",
      "[154]\tvalidation_0-logloss:0.42634\n",
      "[155]\tvalidation_0-logloss:0.42533\n",
      "[156]\tvalidation_0-logloss:0.42511\n",
      "[157]\tvalidation_0-logloss:0.42502\n",
      "[158]\tvalidation_0-logloss:0.42463\n",
      "[159]\tvalidation_0-logloss:0.42413\n",
      "[160]\tvalidation_0-logloss:0.42391\n",
      "[161]\tvalidation_0-logloss:0.42332\n",
      "[162]\tvalidation_0-logloss:0.42253\n",
      "[163]\tvalidation_0-logloss:0.42210\n",
      "[164]\tvalidation_0-logloss:0.42177\n",
      "[165]\tvalidation_0-logloss:0.42142\n",
      "[166]\tvalidation_0-logloss:0.42086\n",
      "[167]\tvalidation_0-logloss:0.42025\n",
      "[168]\tvalidation_0-logloss:0.41987\n",
      "[169]\tvalidation_0-logloss:0.41954\n",
      "[170]\tvalidation_0-logloss:0.41940\n",
      "[171]\tvalidation_0-logloss:0.41947\n",
      "[172]\tvalidation_0-logloss:0.41934\n",
      "[173]\tvalidation_0-logloss:0.41900\n",
      "[174]\tvalidation_0-logloss:0.41845\n",
      "[175]\tvalidation_0-logloss:0.41799\n",
      "[176]\tvalidation_0-logloss:0.41764\n",
      "[177]\tvalidation_0-logloss:0.41703\n",
      "[178]\tvalidation_0-logloss:0.41650\n",
      "[179]\tvalidation_0-logloss:0.41588\n",
      "[180]\tvalidation_0-logloss:0.41540\n",
      "[181]\tvalidation_0-logloss:0.41525\n",
      "[182]\tvalidation_0-logloss:0.41444\n",
      "[183]\tvalidation_0-logloss:0.41424\n",
      "[184]\tvalidation_0-logloss:0.41389\n",
      "[185]\tvalidation_0-logloss:0.41374\n",
      "[186]\tvalidation_0-logloss:0.41390\n",
      "[187]\tvalidation_0-logloss:0.41296\n",
      "[188]\tvalidation_0-logloss:0.41273\n",
      "[189]\tvalidation_0-logloss:0.41252\n",
      "[190]\tvalidation_0-logloss:0.41241\n",
      "[191]\tvalidation_0-logloss:0.41268\n",
      "[192]\tvalidation_0-logloss:0.41277\n",
      "[193]\tvalidation_0-logloss:0.41248\n",
      "[194]\tvalidation_0-logloss:0.41230\n",
      "[195]\tvalidation_0-logloss:0.41196\n",
      "[196]\tvalidation_0-logloss:0.41183\n",
      "[197]\tvalidation_0-logloss:0.41174\n",
      "[198]\tvalidation_0-logloss:0.41106\n",
      "[199]\tvalidation_0-logloss:0.41057\n",
      "[200]\tvalidation_0-logloss:0.41011\n",
      "[201]\tvalidation_0-logloss:0.40963\n",
      "[202]\tvalidation_0-logloss:0.40971\n",
      "[203]\tvalidation_0-logloss:0.40943\n",
      "[204]\tvalidation_0-logloss:0.40932\n",
      "[205]\tvalidation_0-logloss:0.40947\n",
      "[206]\tvalidation_0-logloss:0.40926\n",
      "[207]\tvalidation_0-logloss:0.40886\n",
      "[208]\tvalidation_0-logloss:0.40808\n",
      "[209]\tvalidation_0-logloss:0.40796\n",
      "[210]\tvalidation_0-logloss:0.40775\n",
      "[211]\tvalidation_0-logloss:0.40777\n",
      "[212]\tvalidation_0-logloss:0.40730\n",
      "[213]\tvalidation_0-logloss:0.40703\n",
      "[214]\tvalidation_0-logloss:0.40716\n",
      "[215]\tvalidation_0-logloss:0.40669\n",
      "[216]\tvalidation_0-logloss:0.40678\n",
      "[217]\tvalidation_0-logloss:0.40654\n",
      "[218]\tvalidation_0-logloss:0.40615\n",
      "[219]\tvalidation_0-logloss:0.40645\n",
      "[220]\tvalidation_0-logloss:0.40653\n",
      "[221]\tvalidation_0-logloss:0.40634\n",
      "[222]\tvalidation_0-logloss:0.40628\n",
      "[223]\tvalidation_0-logloss:0.40648\n",
      "[224]\tvalidation_0-logloss:0.40655\n",
      "[225]\tvalidation_0-logloss:0.40651\n",
      "[226]\tvalidation_0-logloss:0.40672\n",
      "[227]\tvalidation_0-logloss:0.40670\n",
      "[228]\tvalidation_0-logloss:0.40626\n",
      "[229]\tvalidation_0-logloss:0.40633\n",
      "[230]\tvalidation_0-logloss:0.40630\n",
      "[231]\tvalidation_0-logloss:0.40600\n",
      "[232]\tvalidation_0-logloss:0.40604\n",
      "[233]\tvalidation_0-logloss:0.40592\n",
      "[234]\tvalidation_0-logloss:0.40554\n",
      "[235]\tvalidation_0-logloss:0.40569\n",
      "[236]\tvalidation_0-logloss:0.40585\n",
      "[237]\tvalidation_0-logloss:0.40563\n",
      "[238]\tvalidation_0-logloss:0.40547\n",
      "[239]\tvalidation_0-logloss:0.40527\n",
      "[240]\tvalidation_0-logloss:0.40545\n",
      "[241]\tvalidation_0-logloss:0.40531\n",
      "[242]\tvalidation_0-logloss:0.40569\n",
      "[243]\tvalidation_0-logloss:0.40563\n",
      "[244]\tvalidation_0-logloss:0.40595\n",
      "[245]\tvalidation_0-logloss:0.40617\n",
      "[246]\tvalidation_0-logloss:0.40633\n",
      "[247]\tvalidation_0-logloss:0.40621\n",
      "[248]\tvalidation_0-logloss:0.40596\n",
      "[249]\tvalidation_0-logloss:0.40532\n",
      "[250]\tvalidation_0-logloss:0.40512\n",
      "[251]\tvalidation_0-logloss:0.40457\n",
      "[252]\tvalidation_0-logloss:0.40410\n",
      "[253]\tvalidation_0-logloss:0.40393\n",
      "[254]\tvalidation_0-logloss:0.40397\n",
      "[255]\tvalidation_0-logloss:0.40411\n",
      "[256]\tvalidation_0-logloss:0.40433\n",
      "[257]\tvalidation_0-logloss:0.40396\n",
      "[258]\tvalidation_0-logloss:0.40398\n",
      "[259]\tvalidation_0-logloss:0.40355\n",
      "[260]\tvalidation_0-logloss:0.40329\n",
      "[261]\tvalidation_0-logloss:0.40335\n",
      "[262]\tvalidation_0-logloss:0.40349\n",
      "[263]\tvalidation_0-logloss:0.40372\n",
      "[264]\tvalidation_0-logloss:0.40368\n",
      "[265]\tvalidation_0-logloss:0.40349\n",
      "[266]\tvalidation_0-logloss:0.40338\n",
      "[267]\tvalidation_0-logloss:0.40328\n",
      "[268]\tvalidation_0-logloss:0.40298\n",
      "[269]\tvalidation_0-logloss:0.40300\n",
      "[270]\tvalidation_0-logloss:0.40283\n",
      "[271]\tvalidation_0-logloss:0.40296\n",
      "[272]\tvalidation_0-logloss:0.40300\n",
      "[273]\tvalidation_0-logloss:0.40283\n",
      "[274]\tvalidation_0-logloss:0.40234\n",
      "[275]\tvalidation_0-logloss:0.40217\n",
      "[276]\tvalidation_0-logloss:0.40262\n",
      "[277]\tvalidation_0-logloss:0.40272\n",
      "[278]\tvalidation_0-logloss:0.40274\n",
      "[279]\tvalidation_0-logloss:0.40305\n",
      "[280]\tvalidation_0-logloss:0.40302\n",
      "[281]\tvalidation_0-logloss:0.40293\n",
      "[282]\tvalidation_0-logloss:0.40283\n",
      "[283]\tvalidation_0-logloss:0.40264\n",
      "[284]\tvalidation_0-logloss:0.40234\n",
      "[285]\tvalidation_0-logloss:0.40173\n",
      "[286]\tvalidation_0-logloss:0.40161\n",
      "[287]\tvalidation_0-logloss:0.40147\n",
      "[288]\tvalidation_0-logloss:0.40156\n",
      "[289]\tvalidation_0-logloss:0.40178\n",
      "[290]\tvalidation_0-logloss:0.40179\n",
      "[291]\tvalidation_0-logloss:0.40227\n",
      "[292]\tvalidation_0-logloss:0.40235\n",
      "[293]\tvalidation_0-logloss:0.40259\n",
      "[294]\tvalidation_0-logloss:0.40237\n",
      "[295]\tvalidation_0-logloss:0.40198\n",
      "[296]\tvalidation_0-logloss:0.40201\n",
      "[297]\tvalidation_0-logloss:0.40200\n",
      "[298]\tvalidation_0-logloss:0.40201\n",
      "[299]\tvalidation_0-logloss:0.40191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "# best_pretrain_params = grid_search.best_params_\n",
    "\n",
    "for param, value in best_pretrain_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create and train fresh model\n",
    "xgb_pretrain = xgb.XGBClassifier(\n",
    "    **best_pretrain_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_pretrain.fit(\n",
    "    X_pretrain_train,\n",
    "    y_pretrain_train,\n",
    "    eval_set=[(X_pretrain_val, y_pretrain_val)],\n",
    "    verbose=1  # Show progress every 100 trees\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0502320a-0a6e-4474-9a85-d5ba30124a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Test Accuracy on Source domain: 83.87%\n",
      "Pretraining Test F1 on Source domain: 87.18%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 91.89%\n",
      "Pretraining Test Specificity on Source domain: 72.00%\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED MODEL EVALUATION ON A-TEST\n",
    "Dataset_A_Pretrain = xgb_pretrain.predict(X_pretrain_test)\n",
    "\n",
    "#Calculate and print metrics on source domain's test set\n",
    "Dataset_A_Pretrain_acc = accuracy_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "Dataset_A_Pretrain_f1  = f1_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "\n",
    "cm_A = confusion_matrix(y_pretrain_test, Dataset_A_Pretrain)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A.ravel()\n",
    "\n",
    "\n",
    "recall_A = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A = TN_A / (TN_A + FP_A) * 100\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {Dataset_A_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {Dataset_A_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_A:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_A:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6f04989-11e6-4193-a3b7-c9861654f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Accuracy on target domain's test Set: 77.42%\n",
      "Pretraining F1 on target domain's test Set: 80.00%\n",
      "Pretraining Recall (Sensitivity) on target domain's test Set: 100.00%\n",
      "Pretraining Specificity on target domain's test Set: 58.82%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain = xgb_pretrain.predict(X_finetune_test)\n",
    "\n",
    "#Calculate and print metrics on target domain's test set\n",
    "Dataset_B_Pretrain_acc = accuracy_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "Dataset_B_Pretrain_f1 = f1_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "cm_B = confusion_matrix(y_finetune_test, Dataset_B_Pretrain)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B.ravel()\n",
    "recall_B = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pretraining Accuracy on target domain's test Set: {Dataset_B_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining F1 on target domain's test Set: {Dataset_B_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Recall (Sensitivity) on target domain's test Set: {recall_B:.2f}%\")\n",
    "print(f\"Pretraining Specificity on target domain's test Set: {specificity_B:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdaffd-5589-4825-a70c-53c2d7f5562f",
   "metadata": {},
   "source": [
    "### Finetuning on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bddce10f-fb66-44ac-8ecf-754a03f87809",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_finetune_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.009,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 1.5, \n",
    "    'subsample': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc73f4df-52f0-45e6-b742-9ada28c944aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.009\n",
      "  max_depth: 6\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 1.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.31882\n",
      "[1]\tvalidation_0-logloss:0.31769\n",
      "[2]\tvalidation_0-logloss:0.31631\n",
      "[3]\tvalidation_0-logloss:0.31523\n",
      "[4]\tvalidation_0-logloss:0.31398\n",
      "[5]\tvalidation_0-logloss:0.31282\n",
      "[6]\tvalidation_0-logloss:0.31161\n",
      "[7]\tvalidation_0-logloss:0.31067\n",
      "[8]\tvalidation_0-logloss:0.30970\n",
      "[9]\tvalidation_0-logloss:0.30827\n",
      "[10]\tvalidation_0-logloss:0.30758\n",
      "[11]\tvalidation_0-logloss:0.30656\n",
      "[12]\tvalidation_0-logloss:0.30560\n",
      "[13]\tvalidation_0-logloss:0.30434\n",
      "[14]\tvalidation_0-logloss:0.30389\n",
      "[15]\tvalidation_0-logloss:0.30245\n",
      "[16]\tvalidation_0-logloss:0.30101\n",
      "[17]\tvalidation_0-logloss:0.29996\n",
      "[18]\tvalidation_0-logloss:0.29908\n",
      "[19]\tvalidation_0-logloss:0.29805\n",
      "[20]\tvalidation_0-logloss:0.29692\n",
      "[21]\tvalidation_0-logloss:0.29626\n",
      "[22]\tvalidation_0-logloss:0.29581\n",
      "[23]\tvalidation_0-logloss:0.29494\n",
      "[24]\tvalidation_0-logloss:0.29489\n",
      "[25]\tvalidation_0-logloss:0.29436\n",
      "[26]\tvalidation_0-logloss:0.29407\n",
      "[27]\tvalidation_0-logloss:0.29371\n",
      "[28]\tvalidation_0-logloss:0.29338\n",
      "[29]\tvalidation_0-logloss:0.29247\n",
      "[30]\tvalidation_0-logloss:0.29158\n",
      "[31]\tvalidation_0-logloss:0.29079\n",
      "[32]\tvalidation_0-logloss:0.28968\n",
      "[33]\tvalidation_0-logloss:0.28889\n",
      "[34]\tvalidation_0-logloss:0.28791\n",
      "[35]\tvalidation_0-logloss:0.28747\n",
      "[36]\tvalidation_0-logloss:0.28715\n",
      "[37]\tvalidation_0-logloss:0.28670\n",
      "[38]\tvalidation_0-logloss:0.28591\n",
      "[39]\tvalidation_0-logloss:0.28501\n",
      "[40]\tvalidation_0-logloss:0.28452\n",
      "[41]\tvalidation_0-logloss:0.28407\n",
      "[42]\tvalidation_0-logloss:0.28340\n",
      "[43]\tvalidation_0-logloss:0.28278\n",
      "[44]\tvalidation_0-logloss:0.28226\n",
      "[45]\tvalidation_0-logloss:0.28146\n",
      "[46]\tvalidation_0-logloss:0.28059\n",
      "[47]\tvalidation_0-logloss:0.27991\n",
      "[48]\tvalidation_0-logloss:0.27947\n",
      "[49]\tvalidation_0-logloss:0.27875\n",
      "[50]\tvalidation_0-logloss:0.27809\n",
      "[51]\tvalidation_0-logloss:0.27773\n",
      "[52]\tvalidation_0-logloss:0.27699\n",
      "[53]\tvalidation_0-logloss:0.27625\n",
      "[54]\tvalidation_0-logloss:0.27543\n",
      "[55]\tvalidation_0-logloss:0.27506\n",
      "[56]\tvalidation_0-logloss:0.27440\n",
      "[57]\tvalidation_0-logloss:0.27397\n",
      "[58]\tvalidation_0-logloss:0.27335\n",
      "[59]\tvalidation_0-logloss:0.27268\n",
      "[60]\tvalidation_0-logloss:0.27211\n",
      "[61]\tvalidation_0-logloss:0.27121\n",
      "[62]\tvalidation_0-logloss:0.27028\n",
      "[63]\tvalidation_0-logloss:0.26995\n",
      "[64]\tvalidation_0-logloss:0.26961\n",
      "[65]\tvalidation_0-logloss:0.26890\n",
      "[66]\tvalidation_0-logloss:0.26828\n",
      "[67]\tvalidation_0-logloss:0.26749\n",
      "[68]\tvalidation_0-logloss:0.26676\n",
      "[69]\tvalidation_0-logloss:0.26644\n",
      "[70]\tvalidation_0-logloss:0.26579\n",
      "[71]\tvalidation_0-logloss:0.26506\n",
      "[72]\tvalidation_0-logloss:0.26445\n",
      "[73]\tvalidation_0-logloss:0.26398\n",
      "[74]\tvalidation_0-logloss:0.26340\n",
      "[75]\tvalidation_0-logloss:0.26284\n",
      "[76]\tvalidation_0-logloss:0.26238\n",
      "[77]\tvalidation_0-logloss:0.26156\n",
      "[78]\tvalidation_0-logloss:0.26134\n",
      "[79]\tvalidation_0-logloss:0.26103\n",
      "[80]\tvalidation_0-logloss:0.26088\n",
      "[81]\tvalidation_0-logloss:0.26023\n",
      "[82]\tvalidation_0-logloss:0.25959\n",
      "[83]\tvalidation_0-logloss:0.25870\n",
      "[84]\tvalidation_0-logloss:0.25863\n",
      "[85]\tvalidation_0-logloss:0.25861\n",
      "[86]\tvalidation_0-logloss:0.25863\n",
      "[87]\tvalidation_0-logloss:0.25812\n",
      "[88]\tvalidation_0-logloss:0.25765\n",
      "[89]\tvalidation_0-logloss:0.25732\n",
      "[90]\tvalidation_0-logloss:0.25654\n",
      "[91]\tvalidation_0-logloss:0.25631\n",
      "[92]\tvalidation_0-logloss:0.25590\n",
      "[93]\tvalidation_0-logloss:0.25521\n",
      "[94]\tvalidation_0-logloss:0.25508\n",
      "[95]\tvalidation_0-logloss:0.25461\n",
      "[96]\tvalidation_0-logloss:0.25449\n",
      "[97]\tvalidation_0-logloss:0.25438\n",
      "[98]\tvalidation_0-logloss:0.25375\n",
      "[99]\tvalidation_0-logloss:0.25318\n",
      "[100]\tvalidation_0-logloss:0.25282\n",
      "[101]\tvalidation_0-logloss:0.25267\n",
      "[102]\tvalidation_0-logloss:0.25223\n",
      "[103]\tvalidation_0-logloss:0.25176\n",
      "[104]\tvalidation_0-logloss:0.25166\n",
      "[105]\tvalidation_0-logloss:0.25159\n",
      "[106]\tvalidation_0-logloss:0.25128\n",
      "[107]\tvalidation_0-logloss:0.25104\n",
      "[108]\tvalidation_0-logloss:0.25084\n",
      "[109]\tvalidation_0-logloss:0.25040\n",
      "[110]\tvalidation_0-logloss:0.24986\n",
      "[111]\tvalidation_0-logloss:0.24933\n",
      "[112]\tvalidation_0-logloss:0.24905\n",
      "[113]\tvalidation_0-logloss:0.24864\n",
      "[114]\tvalidation_0-logloss:0.24788\n",
      "[115]\tvalidation_0-logloss:0.24751\n",
      "[116]\tvalidation_0-logloss:0.24748\n",
      "[117]\tvalidation_0-logloss:0.24734\n",
      "[118]\tvalidation_0-logloss:0.24704\n",
      "[119]\tvalidation_0-logloss:0.24666\n",
      "[120]\tvalidation_0-logloss:0.24641\n",
      "[121]\tvalidation_0-logloss:0.24622\n",
      "[122]\tvalidation_0-logloss:0.24586\n",
      "[123]\tvalidation_0-logloss:0.24549\n",
      "[124]\tvalidation_0-logloss:0.24539\n",
      "[125]\tvalidation_0-logloss:0.24520\n",
      "[126]\tvalidation_0-logloss:0.24473\n",
      "[127]\tvalidation_0-logloss:0.24444\n",
      "[128]\tvalidation_0-logloss:0.24403\n",
      "[129]\tvalidation_0-logloss:0.24361\n",
      "[130]\tvalidation_0-logloss:0.24301\n",
      "[131]\tvalidation_0-logloss:0.24271\n",
      "[132]\tvalidation_0-logloss:0.24250\n",
      "[133]\tvalidation_0-logloss:0.24241\n",
      "[134]\tvalidation_0-logloss:0.24187\n",
      "[135]\tvalidation_0-logloss:0.24153\n",
      "[136]\tvalidation_0-logloss:0.24149\n",
      "[137]\tvalidation_0-logloss:0.24083\n",
      "[138]\tvalidation_0-logloss:0.24043\n",
      "[139]\tvalidation_0-logloss:0.24025\n",
      "[140]\tvalidation_0-logloss:0.23992\n",
      "[141]\tvalidation_0-logloss:0.23972\n",
      "[142]\tvalidation_0-logloss:0.23904\n",
      "[143]\tvalidation_0-logloss:0.23889\n",
      "[144]\tvalidation_0-logloss:0.23874\n",
      "[145]\tvalidation_0-logloss:0.23832\n",
      "[146]\tvalidation_0-logloss:0.23818\n",
      "[147]\tvalidation_0-logloss:0.23791\n",
      "[148]\tvalidation_0-logloss:0.23779\n",
      "[149]\tvalidation_0-logloss:0.23774\n",
      "[150]\tvalidation_0-logloss:0.23752\n",
      "[151]\tvalidation_0-logloss:0.23741\n",
      "[152]\tvalidation_0-logloss:0.23704\n",
      "[153]\tvalidation_0-logloss:0.23714\n",
      "[154]\tvalidation_0-logloss:0.23683\n",
      "[155]\tvalidation_0-logloss:0.23692\n",
      "[156]\tvalidation_0-logloss:0.23668\n",
      "[157]\tvalidation_0-logloss:0.23640\n",
      "[158]\tvalidation_0-logloss:0.23603\n",
      "[159]\tvalidation_0-logloss:0.23587\n",
      "[160]\tvalidation_0-logloss:0.23552\n",
      "[161]\tvalidation_0-logloss:0.23549\n",
      "[162]\tvalidation_0-logloss:0.23522\n",
      "[163]\tvalidation_0-logloss:0.23510\n",
      "[164]\tvalidation_0-logloss:0.23466\n",
      "[165]\tvalidation_0-logloss:0.23431\n",
      "[166]\tvalidation_0-logloss:0.23395\n",
      "[167]\tvalidation_0-logloss:0.23348\n",
      "[168]\tvalidation_0-logloss:0.23326\n",
      "[169]\tvalidation_0-logloss:0.23326\n",
      "[170]\tvalidation_0-logloss:0.23316\n",
      "[171]\tvalidation_0-logloss:0.23289\n",
      "[172]\tvalidation_0-logloss:0.23254\n",
      "[173]\tvalidation_0-logloss:0.23221\n",
      "[174]\tvalidation_0-logloss:0.23196\n",
      "[175]\tvalidation_0-logloss:0.23177\n",
      "[176]\tvalidation_0-logloss:0.23177\n",
      "[177]\tvalidation_0-logloss:0.23148\n",
      "[178]\tvalidation_0-logloss:0.23118\n",
      "[179]\tvalidation_0-logloss:0.23084\n",
      "[180]\tvalidation_0-logloss:0.23044\n",
      "[181]\tvalidation_0-logloss:0.23009\n",
      "[182]\tvalidation_0-logloss:0.22976\n",
      "[183]\tvalidation_0-logloss:0.22985\n",
      "[184]\tvalidation_0-logloss:0.22952\n",
      "[185]\tvalidation_0-logloss:0.22932\n",
      "[186]\tvalidation_0-logloss:0.22934\n",
      "[187]\tvalidation_0-logloss:0.22921\n",
      "[188]\tvalidation_0-logloss:0.22898\n",
      "[189]\tvalidation_0-logloss:0.22875\n",
      "[190]\tvalidation_0-logloss:0.22839\n",
      "[191]\tvalidation_0-logloss:0.22802\n",
      "[192]\tvalidation_0-logloss:0.22775\n",
      "[193]\tvalidation_0-logloss:0.22749\n",
      "[194]\tvalidation_0-logloss:0.22728\n",
      "[195]\tvalidation_0-logloss:0.22685\n",
      "[196]\tvalidation_0-logloss:0.22668\n",
      "[197]\tvalidation_0-logloss:0.22647\n",
      "[198]\tvalidation_0-logloss:0.22636\n",
      "[199]\tvalidation_0-logloss:0.22624\n",
      "[200]\tvalidation_0-logloss:0.22616\n",
      "[201]\tvalidation_0-logloss:0.22588\n",
      "[202]\tvalidation_0-logloss:0.22570\n",
      "[203]\tvalidation_0-logloss:0.22577\n",
      "[204]\tvalidation_0-logloss:0.22544\n",
      "[205]\tvalidation_0-logloss:0.22552\n",
      "[206]\tvalidation_0-logloss:0.22551\n",
      "[207]\tvalidation_0-logloss:0.22524\n",
      "[208]\tvalidation_0-logloss:0.22491\n",
      "[209]\tvalidation_0-logloss:0.22459\n",
      "[210]\tvalidation_0-logloss:0.22446\n",
      "[211]\tvalidation_0-logloss:0.22441\n",
      "[212]\tvalidation_0-logloss:0.22423\n",
      "[213]\tvalidation_0-logloss:0.22390\n",
      "[214]\tvalidation_0-logloss:0.22343\n",
      "[215]\tvalidation_0-logloss:0.22325\n",
      "[216]\tvalidation_0-logloss:0.22286\n",
      "[217]\tvalidation_0-logloss:0.22265\n",
      "[218]\tvalidation_0-logloss:0.22230\n",
      "[219]\tvalidation_0-logloss:0.22211\n",
      "[220]\tvalidation_0-logloss:0.22203\n",
      "[221]\tvalidation_0-logloss:0.22176\n",
      "[222]\tvalidation_0-logloss:0.22141\n",
      "[223]\tvalidation_0-logloss:0.22137\n",
      "[224]\tvalidation_0-logloss:0.22098\n",
      "[225]\tvalidation_0-logloss:0.22099\n",
      "[226]\tvalidation_0-logloss:0.22096\n",
      "[227]\tvalidation_0-logloss:0.22093\n",
      "[228]\tvalidation_0-logloss:0.22076\n",
      "[229]\tvalidation_0-logloss:0.22084\n",
      "[230]\tvalidation_0-logloss:0.22075\n",
      "[231]\tvalidation_0-logloss:0.22037\n",
      "[232]\tvalidation_0-logloss:0.22007\n",
      "[233]\tvalidation_0-logloss:0.22016\n",
      "[234]\tvalidation_0-logloss:0.21995\n",
      "[235]\tvalidation_0-logloss:0.21980\n",
      "[236]\tvalidation_0-logloss:0.21961\n",
      "[237]\tvalidation_0-logloss:0.21933\n",
      "[238]\tvalidation_0-logloss:0.21937\n",
      "[239]\tvalidation_0-logloss:0.21934\n",
      "[240]\tvalidation_0-logloss:0.21927\n",
      "[241]\tvalidation_0-logloss:0.21904\n",
      "[242]\tvalidation_0-logloss:0.21865\n",
      "[243]\tvalidation_0-logloss:0.21866\n",
      "[244]\tvalidation_0-logloss:0.21821\n",
      "[245]\tvalidation_0-logloss:0.21793\n",
      "[246]\tvalidation_0-logloss:0.21799\n",
      "[247]\tvalidation_0-logloss:0.21810\n",
      "[248]\tvalidation_0-logloss:0.21797\n",
      "[249]\tvalidation_0-logloss:0.21796\n",
      "[250]\tvalidation_0-logloss:0.21776\n",
      "[251]\tvalidation_0-logloss:0.21741\n",
      "[252]\tvalidation_0-logloss:0.21726\n",
      "[253]\tvalidation_0-logloss:0.21687\n",
      "[254]\tvalidation_0-logloss:0.21667\n",
      "[255]\tvalidation_0-logloss:0.21662\n",
      "[256]\tvalidation_0-logloss:0.21645\n",
      "[257]\tvalidation_0-logloss:0.21631\n",
      "[258]\tvalidation_0-logloss:0.21639\n",
      "[259]\tvalidation_0-logloss:0.21646\n",
      "[260]\tvalidation_0-logloss:0.21629\n",
      "[261]\tvalidation_0-logloss:0.21637\n",
      "[262]\tvalidation_0-logloss:0.21614\n",
      "[263]\tvalidation_0-logloss:0.21601\n",
      "[264]\tvalidation_0-logloss:0.21569\n",
      "[265]\tvalidation_0-logloss:0.21544\n",
      "[266]\tvalidation_0-logloss:0.21555\n",
      "[267]\tvalidation_0-logloss:0.21557\n",
      "[268]\tvalidation_0-logloss:0.21566\n",
      "[269]\tvalidation_0-logloss:0.21560\n",
      "[270]\tvalidation_0-logloss:0.21546\n",
      "[271]\tvalidation_0-logloss:0.21552\n",
      "[272]\tvalidation_0-logloss:0.21530\n",
      "[273]\tvalidation_0-logloss:0.21498\n",
      "[274]\tvalidation_0-logloss:0.21481\n",
      "[275]\tvalidation_0-logloss:0.21480\n",
      "[276]\tvalidation_0-logloss:0.21491\n",
      "[277]\tvalidation_0-logloss:0.21500\n",
      "[278]\tvalidation_0-logloss:0.21483\n",
      "[279]\tvalidation_0-logloss:0.21489\n",
      "[280]\tvalidation_0-logloss:0.21484\n",
      "[281]\tvalidation_0-logloss:0.21492\n",
      "[282]\tvalidation_0-logloss:0.21477\n",
      "[283]\tvalidation_0-logloss:0.21465\n",
      "[284]\tvalidation_0-logloss:0.21463\n",
      "[285]\tvalidation_0-logloss:0.21464\n",
      "[286]\tvalidation_0-logloss:0.21475\n",
      "[287]\tvalidation_0-logloss:0.21450\n",
      "[288]\tvalidation_0-logloss:0.21459\n",
      "[289]\tvalidation_0-logloss:0.21487\n",
      "[290]\tvalidation_0-logloss:0.21487\n",
      "[291]\tvalidation_0-logloss:0.21487\n",
      "[292]\tvalidation_0-logloss:0.21466\n",
      "[293]\tvalidation_0-logloss:0.21477\n",
      "[294]\tvalidation_0-logloss:0.21442\n",
      "[295]\tvalidation_0-logloss:0.21429\n",
      "[296]\tvalidation_0-logloss:0.21438\n",
      "[297]\tvalidation_0-logloss:0.21432\n",
      "[298]\tvalidation_0-logloss:0.21419\n",
      "[299]\tvalidation_0-logloss:0.21391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters from fine-tuning grid search\n",
    "# best_finetune_params = grid_search_finetune.best_params_\n",
    "\n",
    "for param, value in best_finetune_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "xgb_finetune = xgb.XGBClassifier(\n",
    "    **best_finetune_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_finetune.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train, \n",
    "    eval_set=[(X_finetune_val, y_finetune_val)], \n",
    "    xgb_model=xgb_pretrain.get_booster(),\n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b386de1-f1cb-4ba2-ad3c-dd10c4138c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test Accuracy on Source domain: 80.65%\n",
      "Fine-Tuning Test F1 on Source domain: 84.62%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Source domain: 89.19%\n",
      "Fine-Tuning Test Specificity on Source domain: 68.00%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON A-TEST (Checking for Catastrophic Forgetting)\n",
    "Dataset_A_Finetune = xgb_finetune.predict(X_pretrain_test) # Using the fine-tuned model on A's test set\n",
    "\n",
    "# Calculate and print metrics on source domain's test set\n",
    "acc_A_Finetune = accuracy_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "f1_A_Finetune = f1_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "\n",
    "cm_A_Finetune = confusion_matrix(y_pretrain_test, Dataset_A_Finetune)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune.ravel()\n",
    "\n",
    "recall_A_Finetune = TP_A_F / (TP_A_F + FN_A_F) * 100\n",
    "specificity_A_Finetune = TN_A_F / (TN_A_F + FP_A_F) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test Accuracy on Source domain: {acc_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Source domain: {f1_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Source domain: {recall_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Source domain: {specificity_A_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afac6e80-0424-49c3-abc1-27ce75b57a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test ROC-AUC on Target domain (B): 78.15%\n",
      "Fine-Tuning Test Accuracy on Target domain (B): 77.42%\n",
      "Fine-Tuning Test F1 on Target domain (B): 77.42%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Target domain (B): 85.71%\n",
      "Fine-Tuning Test Specificity on Target domain (B): 70.59%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON B-TEST (Final Transfer Learning Performance)\n",
    "Dataset_B_Finetune = xgb_finetune.predict(X_finetune_test) # Using the fine-tuned model on B's test set\n",
    "\n",
    "# Calculate and print metrics on target domain's test set\n",
    "acc_B_Finetune = accuracy_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1_B_Finetune = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "cm_B_Finetune = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "TN_B_F, FP_B_F, FN_B_F, TP_B_F = cm_B_Finetune.ravel()\n",
    "\n",
    "recall_B_Finetune = TP_B_F / (TP_B_F + FN_B_F) * 100\n",
    "specificity_B_Finetune = TN_B_F / (TN_B_F + FP_B_F) * 100\n",
    "roc_auc_B_Finetune = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test ROC-AUC on Target domain (B): {roc_auc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Accuracy on Target domain (B): {acc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Target domain (B): {f1_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Target domain (B): {recall_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Target domain (B): {specificity_B_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66408ef9-e5a5-41ea-9707-7417a382bb75",
   "metadata": {},
   "source": [
    "#### SHAP figure from the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f9d46-d7cd-4c36-acf5-464f9c42e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# Create SHAP explainer for XGBoost model\n",
    "explainer = shap.TreeExplainer(xgb_finetune)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_finetune_test)\n",
    "\n",
    "# Create a larger figure\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Generate summary plot with custom settings, no caption\n",
    "shap.summary_plot(shap_values, X_finetune_test, \n",
    "                  max_display=20,  # Show top 20 features\n",
    "                  show=False)\n",
    "\n",
    "# Customize the plot\n",
    "plt.gcf().axes[-1].set_aspect(100)\n",
    "plt.gcf().axes[-1].set_box_aspect(100)\n",
    "\n",
    "# Save the plot as an image with high resolution and no caption\n",
    "plt.savefig('shap_summary_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2010a-5856-4e2c-962f-158e8df937bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Confusion matrix and ROC-AUC curve for the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba10ea4-ab9b-4d57-914a-c4f843778d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "# plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Assuming y_finetune_test and Dataset_B_Finetune are already defined\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.invert_yaxis()  # You can uncomment this if you want to invert the Y-axis\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        # Set the text in Times New Roman\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c790849-940f-44e0-b416-6e65f4e90ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "recall = recall_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1 = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate') # Changed back to match the image axis label\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a481e-9936-409b-972e-3021ab1952b7",
   "metadata": {},
   "source": [
    "### XGBoost with no Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44636e68-a03d-4dca-ae99-4163c450919b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.69057\n",
      "[1]\tvalidation_0-logloss:0.69010\n",
      "[2]\tvalidation_0-logloss:0.68961\n",
      "[3]\tvalidation_0-logloss:0.68914\n",
      "[4]\tvalidation_0-logloss:0.68863\n",
      "[5]\tvalidation_0-logloss:0.68808\n",
      "[6]\tvalidation_0-logloss:0.68785\n",
      "[7]\tvalidation_0-logloss:0.68735\n",
      "[8]\tvalidation_0-logloss:0.68697\n",
      "[9]\tvalidation_0-logloss:0.68661\n",
      "[10]\tvalidation_0-logloss:0.68619\n",
      "[11]\tvalidation_0-logloss:0.68583\n",
      "[12]\tvalidation_0-logloss:0.68532\n",
      "[13]\tvalidation_0-logloss:0.68495\n",
      "[14]\tvalidation_0-logloss:0.68440\n",
      "[15]\tvalidation_0-logloss:0.68384\n",
      "[16]\tvalidation_0-logloss:0.68340\n",
      "[17]\tvalidation_0-logloss:0.68293\n",
      "[18]\tvalidation_0-logloss:0.68250\n",
      "[19]\tvalidation_0-logloss:0.68200\n",
      "[20]\tvalidation_0-logloss:0.68168\n",
      "[21]\tvalidation_0-logloss:0.68116\n",
      "[22]\tvalidation_0-logloss:0.68076\n",
      "[23]\tvalidation_0-logloss:0.68037\n",
      "[24]\tvalidation_0-logloss:0.68002\n",
      "[25]\tvalidation_0-logloss:0.67961\n",
      "[26]\tvalidation_0-logloss:0.67905\n",
      "[27]\tvalidation_0-logloss:0.67853\n",
      "[28]\tvalidation_0-logloss:0.67815\n",
      "[29]\tvalidation_0-logloss:0.67768\n",
      "[30]\tvalidation_0-logloss:0.67733\n",
      "[31]\tvalidation_0-logloss:0.67697\n",
      "[32]\tvalidation_0-logloss:0.67663\n",
      "[33]\tvalidation_0-logloss:0.67632\n",
      "[34]\tvalidation_0-logloss:0.67610\n",
      "[35]\tvalidation_0-logloss:0.67574\n",
      "[36]\tvalidation_0-logloss:0.67525\n",
      "[37]\tvalidation_0-logloss:0.67493\n",
      "[38]\tvalidation_0-logloss:0.67439\n",
      "[39]\tvalidation_0-logloss:0.67390\n",
      "[40]\tvalidation_0-logloss:0.67339\n",
      "[41]\tvalidation_0-logloss:0.67295\n",
      "[42]\tvalidation_0-logloss:0.67248\n",
      "[43]\tvalidation_0-logloss:0.67199\n",
      "[44]\tvalidation_0-logloss:0.67164\n",
      "[45]\tvalidation_0-logloss:0.67129\n",
      "[46]\tvalidation_0-logloss:0.67094\n",
      "[47]\tvalidation_0-logloss:0.67062\n",
      "[48]\tvalidation_0-logloss:0.67025\n",
      "[49]\tvalidation_0-logloss:0.66983\n",
      "[50]\tvalidation_0-logloss:0.66945\n",
      "[51]\tvalidation_0-logloss:0.66918\n",
      "[52]\tvalidation_0-logloss:0.66868\n",
      "[53]\tvalidation_0-logloss:0.66822\n",
      "[54]\tvalidation_0-logloss:0.66774\n",
      "[55]\tvalidation_0-logloss:0.66733\n",
      "[56]\tvalidation_0-logloss:0.66692\n",
      "[57]\tvalidation_0-logloss:0.66647\n",
      "[58]\tvalidation_0-logloss:0.66595\n",
      "[59]\tvalidation_0-logloss:0.66555\n",
      "[60]\tvalidation_0-logloss:0.66512\n",
      "[61]\tvalidation_0-logloss:0.66480\n",
      "[62]\tvalidation_0-logloss:0.66440\n",
      "[63]\tvalidation_0-logloss:0.66397\n",
      "[64]\tvalidation_0-logloss:0.66346\n",
      "[65]\tvalidation_0-logloss:0.66309\n",
      "[66]\tvalidation_0-logloss:0.66261\n",
      "[67]\tvalidation_0-logloss:0.66210\n",
      "[68]\tvalidation_0-logloss:0.66180\n",
      "[69]\tvalidation_0-logloss:0.66145\n",
      "[70]\tvalidation_0-logloss:0.66101\n",
      "[71]\tvalidation_0-logloss:0.66057\n",
      "[72]\tvalidation_0-logloss:0.66018\n",
      "[73]\tvalidation_0-logloss:0.65967\n",
      "[74]\tvalidation_0-logloss:0.65924\n",
      "[75]\tvalidation_0-logloss:0.65882\n",
      "[76]\tvalidation_0-logloss:0.65844\n",
      "[77]\tvalidation_0-logloss:0.65806\n",
      "[78]\tvalidation_0-logloss:0.65770\n",
      "[79]\tvalidation_0-logloss:0.65731\n",
      "[80]\tvalidation_0-logloss:0.65691\n",
      "[81]\tvalidation_0-logloss:0.65645\n",
      "[82]\tvalidation_0-logloss:0.65600\n",
      "[83]\tvalidation_0-logloss:0.65549\n",
      "[84]\tvalidation_0-logloss:0.65515\n",
      "[85]\tvalidation_0-logloss:0.65485\n",
      "[86]\tvalidation_0-logloss:0.65441\n",
      "[87]\tvalidation_0-logloss:0.65405\n",
      "[88]\tvalidation_0-logloss:0.65359\n",
      "[89]\tvalidation_0-logloss:0.65320\n",
      "[90]\tvalidation_0-logloss:0.65278\n",
      "[91]\tvalidation_0-logloss:0.65251\n",
      "[92]\tvalidation_0-logloss:0.65204\n",
      "[93]\tvalidation_0-logloss:0.65161\n",
      "[94]\tvalidation_0-logloss:0.65117\n",
      "[95]\tvalidation_0-logloss:0.65093\n",
      "[96]\tvalidation_0-logloss:0.65053\n",
      "[97]\tvalidation_0-logloss:0.65011\n",
      "[98]\tvalidation_0-logloss:0.64978\n",
      "[99]\tvalidation_0-logloss:0.64937\n",
      "[100]\tvalidation_0-logloss:0.64904\n",
      "[101]\tvalidation_0-logloss:0.64866\n",
      "[102]\tvalidation_0-logloss:0.64825\n",
      "[103]\tvalidation_0-logloss:0.64791\n",
      "[104]\tvalidation_0-logloss:0.64749\n",
      "[105]\tvalidation_0-logloss:0.64716\n",
      "[106]\tvalidation_0-logloss:0.64674\n",
      "[107]\tvalidation_0-logloss:0.64636\n",
      "[108]\tvalidation_0-logloss:0.64601\n",
      "[109]\tvalidation_0-logloss:0.64561\n",
      "[110]\tvalidation_0-logloss:0.64520\n",
      "[111]\tvalidation_0-logloss:0.64481\n",
      "[112]\tvalidation_0-logloss:0.64440\n",
      "[113]\tvalidation_0-logloss:0.64405\n",
      "[114]\tvalidation_0-logloss:0.64363\n",
      "[115]\tvalidation_0-logloss:0.64320\n",
      "[116]\tvalidation_0-logloss:0.64275\n",
      "[117]\tvalidation_0-logloss:0.64240\n",
      "[118]\tvalidation_0-logloss:0.64203\n",
      "[119]\tvalidation_0-logloss:0.64169\n",
      "[120]\tvalidation_0-logloss:0.64125\n",
      "[121]\tvalidation_0-logloss:0.64082\n",
      "[122]\tvalidation_0-logloss:0.64042\n",
      "[123]\tvalidation_0-logloss:0.63993\n",
      "[124]\tvalidation_0-logloss:0.63958\n",
      "[125]\tvalidation_0-logloss:0.63931\n",
      "[126]\tvalidation_0-logloss:0.63897\n",
      "[127]\tvalidation_0-logloss:0.63870\n",
      "[128]\tvalidation_0-logloss:0.63825\n",
      "[129]\tvalidation_0-logloss:0.63778\n",
      "[130]\tvalidation_0-logloss:0.63738\n",
      "[131]\tvalidation_0-logloss:0.63700\n",
      "[132]\tvalidation_0-logloss:0.63662\n",
      "[133]\tvalidation_0-logloss:0.63628\n",
      "[134]\tvalidation_0-logloss:0.63581\n",
      "[135]\tvalidation_0-logloss:0.63539\n",
      "[136]\tvalidation_0-logloss:0.63505\n",
      "[137]\tvalidation_0-logloss:0.63465\n",
      "[138]\tvalidation_0-logloss:0.63434\n",
      "[139]\tvalidation_0-logloss:0.63399\n",
      "[140]\tvalidation_0-logloss:0.63367\n",
      "[141]\tvalidation_0-logloss:0.63342\n",
      "[142]\tvalidation_0-logloss:0.63306\n",
      "[143]\tvalidation_0-logloss:0.63271\n",
      "[144]\tvalidation_0-logloss:0.63226\n",
      "[145]\tvalidation_0-logloss:0.63181\n",
      "[146]\tvalidation_0-logloss:0.63151\n",
      "[147]\tvalidation_0-logloss:0.63104\n",
      "[148]\tvalidation_0-logloss:0.63074\n",
      "[149]\tvalidation_0-logloss:0.63027\n",
      "[150]\tvalidation_0-logloss:0.62994\n",
      "[151]\tvalidation_0-logloss:0.62955\n",
      "[152]\tvalidation_0-logloss:0.62922\n",
      "[153]\tvalidation_0-logloss:0.62886\n",
      "[154]\tvalidation_0-logloss:0.62869\n",
      "[155]\tvalidation_0-logloss:0.62828\n",
      "[156]\tvalidation_0-logloss:0.62791\n",
      "[157]\tvalidation_0-logloss:0.62754\n",
      "[158]\tvalidation_0-logloss:0.62715\n",
      "[159]\tvalidation_0-logloss:0.62671\n",
      "[160]\tvalidation_0-logloss:0.62629\n",
      "[161]\tvalidation_0-logloss:0.62600\n",
      "[162]\tvalidation_0-logloss:0.62561\n",
      "[163]\tvalidation_0-logloss:0.62531\n",
      "[164]\tvalidation_0-logloss:0.62499\n",
      "[165]\tvalidation_0-logloss:0.62466\n",
      "[166]\tvalidation_0-logloss:0.62432\n",
      "[167]\tvalidation_0-logloss:0.62391\n",
      "[168]\tvalidation_0-logloss:0.62354\n",
      "[169]\tvalidation_0-logloss:0.62312\n",
      "[170]\tvalidation_0-logloss:0.62275\n",
      "[171]\tvalidation_0-logloss:0.62243\n",
      "[172]\tvalidation_0-logloss:0.62206\n",
      "[173]\tvalidation_0-logloss:0.62176\n",
      "[174]\tvalidation_0-logloss:0.62133\n",
      "[175]\tvalidation_0-logloss:0.62104\n",
      "[176]\tvalidation_0-logloss:0.62063\n",
      "[177]\tvalidation_0-logloss:0.62030\n",
      "[178]\tvalidation_0-logloss:0.61992\n",
      "[179]\tvalidation_0-logloss:0.61957\n",
      "[180]\tvalidation_0-logloss:0.61919\n",
      "[181]\tvalidation_0-logloss:0.61873\n",
      "[182]\tvalidation_0-logloss:0.61838\n",
      "[183]\tvalidation_0-logloss:0.61797\n",
      "[184]\tvalidation_0-logloss:0.61760\n",
      "[185]\tvalidation_0-logloss:0.61725\n",
      "[186]\tvalidation_0-logloss:0.61693\n",
      "[187]\tvalidation_0-logloss:0.61658\n",
      "[188]\tvalidation_0-logloss:0.61620\n",
      "[189]\tvalidation_0-logloss:0.61584\n",
      "[190]\tvalidation_0-logloss:0.61543\n",
      "[191]\tvalidation_0-logloss:0.61512\n",
      "[192]\tvalidation_0-logloss:0.61480\n",
      "[193]\tvalidation_0-logloss:0.61451\n",
      "[194]\tvalidation_0-logloss:0.61417\n",
      "[195]\tvalidation_0-logloss:0.61389\n",
      "[196]\tvalidation_0-logloss:0.61352\n",
      "[197]\tvalidation_0-logloss:0.61336\n",
      "[198]\tvalidation_0-logloss:0.61305\n",
      "[199]\tvalidation_0-logloss:0.61269\n",
      "[200]\tvalidation_0-logloss:0.61241\n",
      "[201]\tvalidation_0-logloss:0.61196\n",
      "[202]\tvalidation_0-logloss:0.61168\n",
      "[203]\tvalidation_0-logloss:0.61125\n",
      "[204]\tvalidation_0-logloss:0.61085\n",
      "[205]\tvalidation_0-logloss:0.61056\n",
      "[206]\tvalidation_0-logloss:0.61021\n",
      "[207]\tvalidation_0-logloss:0.60984\n",
      "[208]\tvalidation_0-logloss:0.60946\n",
      "[209]\tvalidation_0-logloss:0.60912\n",
      "[210]\tvalidation_0-logloss:0.60878\n",
      "[211]\tvalidation_0-logloss:0.60856\n",
      "[212]\tvalidation_0-logloss:0.60821\n",
      "[213]\tvalidation_0-logloss:0.60786\n",
      "[214]\tvalidation_0-logloss:0.60743\n",
      "[215]\tvalidation_0-logloss:0.60709\n",
      "[216]\tvalidation_0-logloss:0.60678\n",
      "[217]\tvalidation_0-logloss:0.60634\n",
      "[218]\tvalidation_0-logloss:0.60606\n",
      "[219]\tvalidation_0-logloss:0.60577\n",
      "[220]\tvalidation_0-logloss:0.60539\n",
      "[221]\tvalidation_0-logloss:0.60496\n",
      "[222]\tvalidation_0-logloss:0.60470\n",
      "[223]\tvalidation_0-logloss:0.60434\n",
      "[224]\tvalidation_0-logloss:0.60398\n",
      "[225]\tvalidation_0-logloss:0.60360\n",
      "[226]\tvalidation_0-logloss:0.60331\n",
      "[227]\tvalidation_0-logloss:0.60295\n",
      "[228]\tvalidation_0-logloss:0.60252\n",
      "[229]\tvalidation_0-logloss:0.60221\n",
      "[230]\tvalidation_0-logloss:0.60187\n",
      "[231]\tvalidation_0-logloss:0.60152\n",
      "[232]\tvalidation_0-logloss:0.60125\n",
      "[233]\tvalidation_0-logloss:0.60090\n",
      "[234]\tvalidation_0-logloss:0.60047\n",
      "[235]\tvalidation_0-logloss:0.60008\n",
      "[236]\tvalidation_0-logloss:0.59969\n",
      "[237]\tvalidation_0-logloss:0.59935\n",
      "[238]\tvalidation_0-logloss:0.59898\n",
      "[239]\tvalidation_0-logloss:0.59859\n",
      "[240]\tvalidation_0-logloss:0.59832\n",
      "[241]\tvalidation_0-logloss:0.59797\n",
      "[242]\tvalidation_0-logloss:0.59771\n",
      "[243]\tvalidation_0-logloss:0.59728\n",
      "[244]\tvalidation_0-logloss:0.59708\n",
      "[245]\tvalidation_0-logloss:0.59676\n",
      "[246]\tvalidation_0-logloss:0.59648\n",
      "[247]\tvalidation_0-logloss:0.59619\n",
      "[248]\tvalidation_0-logloss:0.59591\n",
      "[249]\tvalidation_0-logloss:0.59567\n",
      "[250]\tvalidation_0-logloss:0.59526\n",
      "[251]\tvalidation_0-logloss:0.59488\n",
      "[252]\tvalidation_0-logloss:0.59450\n",
      "[253]\tvalidation_0-logloss:0.59415\n",
      "[254]\tvalidation_0-logloss:0.59376\n",
      "[255]\tvalidation_0-logloss:0.59347\n",
      "[256]\tvalidation_0-logloss:0.59308\n",
      "[257]\tvalidation_0-logloss:0.59270\n",
      "[258]\tvalidation_0-logloss:0.59243\n",
      "[259]\tvalidation_0-logloss:0.59206\n",
      "[260]\tvalidation_0-logloss:0.59185\n",
      "[261]\tvalidation_0-logloss:0.59149\n",
      "[262]\tvalidation_0-logloss:0.59130\n",
      "[263]\tvalidation_0-logloss:0.59091\n",
      "[264]\tvalidation_0-logloss:0.59067\n",
      "[265]\tvalidation_0-logloss:0.59029\n",
      "[266]\tvalidation_0-logloss:0.59008\n",
      "[267]\tvalidation_0-logloss:0.58981\n",
      "[268]\tvalidation_0-logloss:0.58952\n",
      "[269]\tvalidation_0-logloss:0.58923\n",
      "[270]\tvalidation_0-logloss:0.58882\n",
      "[271]\tvalidation_0-logloss:0.58856\n",
      "[272]\tvalidation_0-logloss:0.58827\n",
      "[273]\tvalidation_0-logloss:0.58786\n",
      "[274]\tvalidation_0-logloss:0.58746\n",
      "[275]\tvalidation_0-logloss:0.58706\n",
      "[276]\tvalidation_0-logloss:0.58669\n",
      "[277]\tvalidation_0-logloss:0.58639\n",
      "[278]\tvalidation_0-logloss:0.58608\n",
      "[279]\tvalidation_0-logloss:0.58582\n",
      "[280]\tvalidation_0-logloss:0.58550\n",
      "[281]\tvalidation_0-logloss:0.58519\n",
      "[282]\tvalidation_0-logloss:0.58499\n",
      "[283]\tvalidation_0-logloss:0.58475\n",
      "[284]\tvalidation_0-logloss:0.58438\n",
      "[285]\tvalidation_0-logloss:0.58398\n",
      "[286]\tvalidation_0-logloss:0.58369\n",
      "[287]\tvalidation_0-logloss:0.58346\n",
      "[288]\tvalidation_0-logloss:0.58317\n",
      "[289]\tvalidation_0-logloss:0.58283\n",
      "[290]\tvalidation_0-logloss:0.58249\n",
      "[291]\tvalidation_0-logloss:0.58215\n",
      "[292]\tvalidation_0-logloss:0.58187\n",
      "[293]\tvalidation_0-logloss:0.58156\n",
      "[294]\tvalidation_0-logloss:0.58129\n",
      "[295]\tvalidation_0-logloss:0.58103\n",
      "[296]\tvalidation_0-logloss:0.58067\n",
      "[297]\tvalidation_0-logloss:0.58038\n",
      "[298]\tvalidation_0-logloss:0.58000\n",
      "[299]\tvalidation_0-logloss:0.57964\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = XGBClassifier(\n",
    "    # 'colsample_bytree': 0.7,\n",
    "    # 'learning_rate': 0.009,\n",
    "    # 'max_depth': 6,\n",
    "    # 'n_estimators': 300,\n",
    "    # 'reg_alpha': 0.1, \n",
    "    # 'reg_lambda': 1.5, \n",
    "    # 'subsample': 1.0\n",
    "    n_estimators=300,            \n",
    "    max_depth=10,\n",
    "    learning_rate=0.001,          # slightly higher for adaptation\n",
    "    subsample=1.0,\n",
    "    seed=42,\n",
    "    colsample_bytree=0.7,\n",
    "    eval_metric='logloss',\n",
    "    reg_lambda = 1.5,\n",
    "    reg_alpha = 0.1,\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train using only Dataset B (resampled training set)\n",
    "baseline_model.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train,\n",
    "    eval_set=[(X_finetune_val, y_finetune_val)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bab295b0-00fb-44d5-be89-b0a3367bbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (Dataset B): 80.65%\n",
      "Baseline F1-score (Dataset B): 76.92%\n",
      "Baseline Recall (Sensitivity): 71.43%\n",
      "Baseline Specificity: 88.24%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Dataset B test set\n",
    "y_pred_baseline = baseline_model.predict(X_finetune_test)\n",
    "\n",
    "baseline_acc = accuracy_score(y_finetune_test, y_pred_baseline) * 100\n",
    "baseline_f1  = f1_score(y_finetune_test, y_pred_baseline) * 100\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, y_pred_baseline)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "recall_score_calc = TP / (TP + FN) * 100\n",
    "specificity_score_calc = TN / (TN + FP) * 100\n",
    "\n",
    "\n",
    "print(f\"Baseline Accuracy (Dataset B): {baseline_acc:.2f}%\")\n",
    "print(f\"Baseline F1-score (Dataset B): {baseline_f1:.2f}%\")\n",
    "print(f\"Baseline Recall (Sensitivity): {recall_score_calc:.2f}%\")\n",
    "print(f\"Baseline Specificity: {specificity_score_calc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ada6c-57c4-4083-b15b-4a9f32ce3e7d",
   "metadata": {},
   "source": [
    "## 5. Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce404869-1c59-4adf-af80-11c0431b1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2baf0ab6-9b0b-462b-9157-66d45fdc5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training, validation, and test datasets for the source domain\n",
    "X_A_train = X_pretrain_train.values  # Features for training on the source domain (pre-training phase)\n",
    "y_A_train = y_pretrain_train.values  # Target labels for training on the source domain\n",
    "\n",
    "X_A_val   = X_pretrain_val.values  # Features for validation on the source domain\n",
    "y_A_val   = y_pretrain_val.values  # Target labels for validation on the source domain\n",
    "\n",
    "X_A_test  = X_pretrain_test.values  # Features for testing on the source domain\n",
    "y_A_test  = y_pretrain_test.values  # Target labels for testing on the source domain\n",
    "\n",
    "# Defining the training, validation, and test datasets for the target domain\n",
    "X_B_train = X_finetune_train.values  # Features for training on the target domain (fine-tuning phase)\n",
    "y_B_train = y_finetune_train.values  # Target labels for training on the target domain\n",
    "\n",
    "X_B_val   = X_finetune_val.values  # Features for validation on the target domain\n",
    "y_B_val   = y_finetune_val.values  # Target labels for validation on the target domain\n",
    "\n",
    "X_B_test  = X_finetune_test.values  # Features for testing on the target domain\n",
    "y_B_test  = y_finetune_test.values  # Target labels for testing on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71aa0290-a98b-4f3c-916e-427ebc557794",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_A_train = scaler.fit_transform(X_A_train).astype(np.float32)  # Fit scaler on source train set, transform it\n",
    "X_A_val = scaler.transform(X_A_val).astype(np.float32)          # Transform source validation set\n",
    "X_A_test = scaler.transform(X_A_test).astype(np.float32)        # Transform source test set\n",
    "\n",
    "y_A_train = y_A_train.astype(np.int64)  # Convert source train labels to int64\n",
    "y_A_val = y_A_val.astype(np.int64)      # Convert source validation labels\n",
    "y_A_test = y_A_test.astype(np.int64)    # Convert source test labels\n",
    "\n",
    "X_B_train = scaler.transform(X_B_train).astype(np.float32)      # Apply source-domain scaling to target train set\n",
    "X_B_val = scaler.transform(X_B_val).astype(np.float32)          # Apply scaling to target validation set\n",
    "X_B_test = scaler.transform(X_B_test).astype(np.float32)        # Apply scaling to target test set\n",
    "\n",
    "y_B_train = y_B_train.astype(np.int64)  # Convert target train labels to int64\n",
    "y_B_val = y_B_val.astype(np.int64)      # Convert target validation labels\n",
    "y_B_test = y_B_test.astype(np.int64)    # Convert target test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f43b5b-4246-48f2-bf12-642d16222412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_d_a: 16\n",
      "n_steps: 9\n",
      "gamma: 1.7899467948557366\n",
      "lambda_sparse: 4.387608964907318e-05\n",
      "lr: 0.003074702431245894\n",
      "momentum: 0.22\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 40\n",
      "scheduler_gamma: 0.9464940708357479\n"
     ]
    }
   ],
   "source": [
    "best_pretrain_params = {\n",
    "    \"n_d_a\": 16,\n",
    "    \"n_steps\": 9,\n",
    "    \"gamma\": 1.7899467948557366,\n",
    "    \"lambda_sparse\": 4.387608964907318e-05,\n",
    "    \"lr\": 0.003074702431245894,\n",
    "    \"momentum\": 0.22,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 40,\n",
    "    \"scheduler_gamma\": 0.9464940708357479,\n",
    "}\n",
    "for key, value in best_pretrain_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e6cf23c-94a0-4d00-b5b7-94b8f78973a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.29289 | val_logloss: 0.66683 |  0:00:01s\n",
      "epoch 1  | loss: 0.80163 | val_logloss: 0.59553 |  0:00:03s\n",
      "epoch 2  | loss: 0.65788 | val_logloss: 0.65257 |  0:00:04s\n",
      "epoch 3  | loss: 0.66673 | val_logloss: 0.62212 |  0:00:05s\n",
      "epoch 4  | loss: 0.6139  | val_logloss: 0.54675 |  0:00:06s\n",
      "epoch 5  | loss: 0.5311  | val_logloss: 0.65341 |  0:00:08s\n",
      "epoch 6  | loss: 0.55766 | val_logloss: 0.58791 |  0:00:09s\n",
      "epoch 7  | loss: 0.51891 | val_logloss: 0.72932 |  0:00:10s\n",
      "epoch 8  | loss: 0.49172 | val_logloss: 0.55952 |  0:00:11s\n",
      "epoch 9  | loss: 0.48336 | val_logloss: 0.58642 |  0:00:13s\n",
      "epoch 10 | loss: 0.44669 | val_logloss: 0.55581 |  0:00:14s\n",
      "epoch 11 | loss: 0.57065 | val_logloss: 0.71071 |  0:00:15s\n",
      "epoch 12 | loss: 0.44823 | val_logloss: 0.5389  |  0:00:16s\n",
      "epoch 13 | loss: 0.41954 | val_logloss: 0.67987 |  0:00:17s\n",
      "epoch 14 | loss: 0.42052 | val_logloss: 0.54445 |  0:00:19s\n",
      "epoch 15 | loss: 0.43591 | val_logloss: 0.4292  |  0:00:20s\n",
      "epoch 16 | loss: 0.45141 | val_logloss: 0.51819 |  0:00:21s\n",
      "epoch 17 | loss: 0.42635 | val_logloss: 0.57825 |  0:00:23s\n",
      "epoch 18 | loss: 0.44046 | val_logloss: 0.55707 |  0:00:24s\n",
      "epoch 19 | loss: 0.39467 | val_logloss: 0.49092 |  0:00:25s\n",
      "epoch 20 | loss: 0.40135 | val_logloss: 0.56043 |  0:00:26s\n",
      "epoch 21 | loss: 0.38935 | val_logloss: 0.55933 |  0:00:28s\n",
      "epoch 22 | loss: 0.37601 | val_logloss: 0.48331 |  0:00:29s\n",
      "epoch 23 | loss: 0.40071 | val_logloss: 0.66644 |  0:00:30s\n",
      "epoch 24 | loss: 0.38481 | val_logloss: 0.5866  |  0:00:31s\n",
      "epoch 25 | loss: 0.38096 | val_logloss: 0.59412 |  0:00:33s\n",
      "epoch 26 | loss: 0.39675 | val_logloss: 0.5019  |  0:00:34s\n",
      "epoch 27 | loss: 0.40876 | val_logloss: 0.49031 |  0:00:35s\n",
      "epoch 28 | loss: 0.40389 | val_logloss: 0.55671 |  0:00:36s\n",
      "epoch 29 | loss: 0.41605 | val_logloss: 0.54513 |  0:00:37s\n",
      "epoch 30 | loss: 0.4095  | val_logloss: 0.54325 |  0:00:39s\n",
      "epoch 31 | loss: 0.42972 | val_logloss: 0.60502 |  0:00:40s\n",
      "epoch 32 | loss: 0.3933  | val_logloss: 0.57873 |  0:00:41s\n",
      "epoch 33 | loss: 0.38658 | val_logloss: 0.67949 |  0:00:42s\n",
      "epoch 34 | loss: 0.44878 | val_logloss: 0.60084 |  0:00:44s\n",
      "epoch 35 | loss: 0.48038 | val_logloss: 0.65624 |  0:00:45s\n",
      "epoch 36 | loss: 0.41952 | val_logloss: 0.58198 |  0:00:46s\n",
      "epoch 37 | loss: 0.38762 | val_logloss: 0.46729 |  0:00:47s\n",
      "epoch 38 | loss: 0.36452 | val_logloss: 0.473   |  0:00:49s\n",
      "epoch 39 | loss: 0.37937 | val_logloss: 0.61203 |  0:00:50s\n",
      "epoch 40 | loss: 0.38578 | val_logloss: 0.56567 |  0:00:51s\n",
      "epoch 41 | loss: 0.37851 | val_logloss: 0.57494 |  0:00:52s\n",
      "epoch 42 | loss: 0.37979 | val_logloss: 0.39991 |  0:00:53s\n",
      "epoch 43 | loss: 0.34421 | val_logloss: 0.47739 |  0:00:55s\n",
      "epoch 44 | loss: 0.38028 | val_logloss: 0.50493 |  0:00:56s\n",
      "epoch 45 | loss: 0.34517 | val_logloss: 0.46938 |  0:00:57s\n",
      "epoch 46 | loss: 0.34171 | val_logloss: 0.45803 |  0:00:58s\n",
      "epoch 47 | loss: 0.34037 | val_logloss: 0.60171 |  0:01:00s\n",
      "epoch 48 | loss: 0.32911 | val_logloss: 0.476   |  0:01:01s\n",
      "epoch 49 | loss: 0.34664 | val_logloss: 0.48312 |  0:01:02s\n",
      "epoch 50 | loss: 0.38377 | val_logloss: 0.40844 |  0:01:03s\n",
      "epoch 51 | loss: 0.34192 | val_logloss: 0.42758 |  0:01:05s\n",
      "epoch 52 | loss: 0.35749 | val_logloss: 0.45727 |  0:01:06s\n",
      "epoch 53 | loss: 0.36334 | val_logloss: 0.41782 |  0:01:07s\n",
      "epoch 54 | loss: 0.34783 | val_logloss: 0.49165 |  0:01:09s\n",
      "epoch 55 | loss: 0.38553 | val_logloss: 0.49986 |  0:01:10s\n",
      "epoch 56 | loss: 0.33887 | val_logloss: 0.4719  |  0:01:11s\n",
      "epoch 57 | loss: 0.33181 | val_logloss: 0.52008 |  0:01:13s\n",
      "epoch 58 | loss: 0.36608 | val_logloss: 0.35945 |  0:01:14s\n",
      "epoch 59 | loss: 0.35698 | val_logloss: 0.52157 |  0:01:15s\n",
      "epoch 60 | loss: 0.31817 | val_logloss: 0.38279 |  0:01:16s\n",
      "epoch 61 | loss: 0.36217 | val_logloss: 0.46397 |  0:01:18s\n",
      "epoch 62 | loss: 0.34132 | val_logloss: 0.3699  |  0:01:19s\n",
      "epoch 63 | loss: 0.32553 | val_logloss: 0.42223 |  0:01:20s\n",
      "epoch 64 | loss: 0.37303 | val_logloss: 0.4639  |  0:01:21s\n",
      "epoch 65 | loss: 0.3528  | val_logloss: 0.49502 |  0:01:23s\n",
      "epoch 66 | loss: 0.42434 | val_logloss: 0.47376 |  0:01:24s\n",
      "epoch 67 | loss: 0.33687 | val_logloss: 0.52368 |  0:01:25s\n",
      "epoch 68 | loss: 0.33819 | val_logloss: 0.50959 |  0:01:26s\n",
      "epoch 69 | loss: 0.36193 | val_logloss: 0.43612 |  0:01:28s\n",
      "epoch 70 | loss: 0.33924 | val_logloss: 0.49774 |  0:01:29s\n",
      "epoch 71 | loss: 0.3632  | val_logloss: 0.41861 |  0:01:30s\n",
      "epoch 72 | loss: 0.32654 | val_logloss: 0.45323 |  0:01:31s\n",
      "epoch 73 | loss: 0.32817 | val_logloss: 0.41774 |  0:01:33s\n",
      "epoch 74 | loss: 0.32736 | val_logloss: 0.39273 |  0:01:34s\n",
      "epoch 75 | loss: 0.32815 | val_logloss: 0.54995 |  0:01:35s\n",
      "epoch 76 | loss: 0.3355  | val_logloss: 0.50857 |  0:01:36s\n",
      "epoch 77 | loss: 0.33278 | val_logloss: 0.43479 |  0:01:37s\n",
      "epoch 78 | loss: 0.32035 | val_logloss: 0.45876 |  0:01:39s\n",
      "epoch 79 | loss: 0.35279 | val_logloss: 0.42342 |  0:01:40s\n",
      "epoch 80 | loss: 0.32889 | val_logloss: 0.44979 |  0:01:41s\n",
      "epoch 81 | loss: 0.30144 | val_logloss: 0.50775 |  0:01:42s\n",
      "epoch 82 | loss: 0.32567 | val_logloss: 0.41891 |  0:01:43s\n",
      "epoch 83 | loss: 0.32959 | val_logloss: 0.46191 |  0:01:45s\n",
      "epoch 84 | loss: 0.3555  | val_logloss: 0.4931  |  0:01:46s\n",
      "epoch 85 | loss: 0.32509 | val_logloss: 0.40019 |  0:01:47s\n",
      "epoch 86 | loss: 0.3226  | val_logloss: 0.45432 |  0:01:48s\n",
      "epoch 87 | loss: 0.35375 | val_logloss: 0.49642 |  0:01:49s\n",
      "epoch 88 | loss: 0.35495 | val_logloss: 0.4911  |  0:01:51s\n",
      "\n",
      "Early stopping occurred at epoch 88 with best_epoch = 58 and best_val_logloss = 0.35945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at tabnet_pretrain_model.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tabnet_pretrain_model.zip'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tabnet_pretrain = TabNetClassifier(\n",
    "    n_d=best_pretrain_params['n_d_a'],           # split n_d_a into n_d\n",
    "    n_a=best_pretrain_params['n_d_a'],           # and n_a\n",
    "    n_steps=best_pretrain_params['n_steps'],\n",
    "    gamma=best_pretrain_params['gamma'],\n",
    "    lambda_sparse=best_pretrain_params['lambda_sparse'],\n",
    "    momentum=best_pretrain_params['momentum'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={'lr': best_pretrain_params['lr']},\n",
    "    mask_type='sparsemax',\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_pretrain_params['step_size'], 'gamma': best_pretrain_params['scheduler_gamma']},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# Train the final model\n",
    "tabnet_pretrain.fit(\n",
    "    X_train=X_A_train,\n",
    "    y_train=y_A_train,\n",
    "    eval_set=[(X_A_val, y_A_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"logloss\"],\n",
    "    max_epochs=150,\n",
    "    patience=30,\n",
    "    batch_size=best_pretrain_params['batch_size'],\n",
    "    virtual_batch_size=best_pretrain_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "tabnet_pretrain.save_model(\"tabnet_pretrain_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8244220-7390-4797-a19a-4d7e158111ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset A, Test Accuracy: 79.03%\n",
      "Pre-training, test on Dataset A, Test F1-score: 83.12%\n",
      "Pre-training, test on Dataset A, Test Recall (Sensitivity): 86.49%\n",
      "Pre-training, test on Dataset A, Test Specificity: 68.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Pretrain_TNet = tabnet_pretrain.predict(X_A_test)\n",
    "\n",
    "cm_A_TNet = confusion_matrix(y_A_test, Dataset_A_Pretrain_TNet)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A_TNet.ravel()\n",
    "\n",
    "# Calculate Metrics for TabNet on Dataset A\n",
    "acc_A_TNet = accuracy_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "f1_A_TNet = f1_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "recall_A_TNet = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A_TNet = TN_A / (TN_A + FP_A) * 100\n",
    "\n",
    "\n",
    "print(f\"Pre-training, test on Dataset A, Test Accuracy: {acc_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test F1-score: {f1_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Recall (Sensitivity): {recall_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Specificity: {specificity_A_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c40aac0-e457-447b-8a49-bca02c5b9a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset B, Accuracy: 67.74%\n",
      "Pre-training, test on Dataset B, F1-score: 68.75%\n",
      "Pre-training, test on Dataset B, Recall (Sensitivity): 78.57%\n",
      "Pre-training, test on Dataset B, Specificity: 58.82%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain_TNet = tabnet_pretrain.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_TNet = confusion_matrix(y_B_test, Dataset_B_Pretrain_TNet)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_TNet = accuracy_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "f1_B_TNet = f1_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_TNet = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B_TNet = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pre-training, test on Dataset B, Accuracy: {acc_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, F1-score: {f1_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Recall (Sensitivity): {recall_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Specificity: {specificity_B_TNet:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08c2ea6a-c6c8-4ca0-80aa-dea7c5ee0780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 1.8676698399014517\n",
      "lambda_sparse: 0.0042824862550021525\n",
      "lr: 0.0013627631079900057\n",
      "momentum: 0.92\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 10\n",
      "scheduler_gamma: 0.8296240533908424\n"
     ]
    }
   ],
   "source": [
    "best_finetune_params = {\n",
    "    \"gamma\": 1.8676698399014517,\n",
    "    \"lambda_sparse\": 0.0042824862550021525,\n",
    "    \"lr\": 0.0013627631079900058,\n",
    "    \"momentum\": 0.92,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 10,\n",
    "    \"scheduler_gamma\": 0.8296240533908424,\n",
    "}\n",
    "for key, value in best_finetune_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60a1ed99-b4e0-49c3-b7f3-3e48f2446be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_a changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_d changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_steps changed from 3 to 9\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.66797 | val_logloss: 0.26428 |  0:00:00s\n",
      "epoch 1  | loss: 0.62809 | val_logloss: 0.21759 |  0:00:01s\n",
      "epoch 2  | loss: 0.49261 | val_logloss: 0.20173 |  0:00:01s\n",
      "epoch 3  | loss: 0.62191 | val_logloss: 0.23361 |  0:00:01s\n",
      "epoch 4  | loss: 0.4889  | val_logloss: 0.21194 |  0:00:02s\n",
      "epoch 5  | loss: 0.54504 | val_logloss: 0.22894 |  0:00:02s\n",
      "epoch 6  | loss: 0.58965 | val_logloss: 0.25812 |  0:00:03s\n",
      "epoch 7  | loss: 0.54476 | val_logloss: 0.31101 |  0:00:03s\n",
      "epoch 8  | loss: 0.47734 | val_logloss: 0.33299 |  0:00:04s\n",
      "epoch 9  | loss: 0.50536 | val_logloss: 0.32882 |  0:00:04s\n",
      "epoch 10 | loss: 0.49509 | val_logloss: 0.32578 |  0:00:04s\n",
      "epoch 11 | loss: 0.51802 | val_logloss: 0.33166 |  0:00:05s\n",
      "epoch 12 | loss: 0.48774 | val_logloss: 0.35808 |  0:00:05s\n",
      "epoch 13 | loss: 0.52383 | val_logloss: 0.355   |  0:00:06s\n",
      "epoch 14 | loss: 0.46621 | val_logloss: 0.29594 |  0:00:06s\n",
      "epoch 15 | loss: 0.45271 | val_logloss: 0.30033 |  0:00:06s\n",
      "epoch 16 | loss: 0.42356 | val_logloss: 0.31306 |  0:00:07s\n",
      "epoch 17 | loss: 0.47395 | val_logloss: 0.30254 |  0:00:07s\n",
      "epoch 18 | loss: 0.4764  | val_logloss: 0.34161 |  0:00:08s\n",
      "epoch 19 | loss: 0.446   | val_logloss: 0.2935  |  0:00:08s\n",
      "epoch 20 | loss: 0.51441 | val_logloss: 0.32057 |  0:00:08s\n",
      "epoch 21 | loss: 0.42262 | val_logloss: 0.34642 |  0:00:09s\n",
      "epoch 22 | loss: 0.44369 | val_logloss: 0.34566 |  0:00:09s\n",
      "epoch 23 | loss: 0.42765 | val_logloss: 0.30622 |  0:00:10s\n",
      "epoch 24 | loss: 0.38415 | val_logloss: 0.30899 |  0:00:10s\n",
      "epoch 25 | loss: 0.44891 | val_logloss: 0.32119 |  0:00:10s\n",
      "epoch 26 | loss: 0.45935 | val_logloss: 0.33339 |  0:00:11s\n",
      "epoch 27 | loss: 0.43347 | val_logloss: 0.327   |  0:00:11s\n",
      "epoch 28 | loss: 0.42628 | val_logloss: 0.37627 |  0:00:12s\n",
      "epoch 29 | loss: 0.45725 | val_logloss: 0.32978 |  0:00:12s\n",
      "epoch 30 | loss: 0.38606 | val_logloss: 0.34797 |  0:00:12s\n",
      "epoch 31 | loss: 0.44606 | val_logloss: 0.34766 |  0:00:13s\n",
      "epoch 32 | loss: 0.4261  | val_logloss: 0.34993 |  0:00:13s\n",
      "epoch 33 | loss: 0.39862 | val_logloss: 0.33811 |  0:00:14s\n",
      "epoch 34 | loss: 0.44517 | val_logloss: 0.33651 |  0:00:14s\n",
      "epoch 35 | loss: 0.44336 | val_logloss: 0.33074 |  0:00:14s\n",
      "epoch 36 | loss: 0.39639 | val_logloss: 0.30915 |  0:00:15s\n",
      "epoch 37 | loss: 0.4212  | val_logloss: 0.3419  |  0:00:15s\n",
      "epoch 38 | loss: 0.42104 | val_logloss: 0.34382 |  0:00:16s\n",
      "epoch 39 | loss: 0.41461 | val_logloss: 0.34073 |  0:00:16s\n",
      "epoch 40 | loss: 0.4342  | val_logloss: 0.34369 |  0:00:16s\n",
      "epoch 41 | loss: 0.43828 | val_logloss: 0.33132 |  0:00:17s\n",
      "epoch 42 | loss: 0.37955 | val_logloss: 0.3221  |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 2 and best_val_logloss = 0.20173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# best_finetune_params = study_finetune.best_params\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "tabnet_finetuned = TabNetClassifier(\n",
    "    n_d=8,\n",
    "    n_a=8,\n",
    "    n_steps=3,\n",
    "    gamma=best_finetune_params['gamma'],\n",
    "    lambda_sparse=best_finetune_params['lambda_sparse'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={\n",
    "        'lr': best_finetune_params['lr']\n",
    "    },\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_finetune_params['step_size'], 'gamma': best_finetune_params['scheduler_gamma']},\n",
    "    seed=42,\n",
    "    verbose=1,\n",
    "    device_name='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "tabnet_finetuned.fit(\n",
    "    X_train=X_B_train,\n",
    "    y_train=y_B_train,           \n",
    "    eval_set=[(X_B_val, y_B_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=['logloss'],\n",
    "    max_epochs=100,\n",
    "    patience=40,\n",
    "    batch_size=best_finetune_params['batch_size'],\n",
    "    virtual_batch_size=best_finetune_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # Initialize with pre-trained weights\n",
    "    from_unsupervised=tabnet_pretrain  # Transfer learning!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcb0603e-8399-4861-9f00-b943aeff7fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset A, Test Accuracy: 82.26%\n",
      "Fine-tuned, test on Dataset A, Test F1-score: 84.51%\n",
      "Fine-tuned, test on Dataset A, Test Recall (Sensitivity): 81.08%\n",
      "Fine-tuned, test on Dataset A, Test Specificity: 84.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Finetune_TNet = tabnet_finetuned.predict(X_A_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset A\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_A_Finetune_TNet = confusion_matrix(y_A_test, Dataset_A_Finetune_TNet)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_A_Finetune_TNet = accuracy_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "f1_A_Finetune_TNet = f1_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_A_Finetune_TNet = TP_A_F / (TP_A_F + FN_A_F) * 100 if (TP_A_F + FN_A_F) > 0 else 0\n",
    "specificity_A_Finetune_TNet = TN_A_F / (TN_A_F + FP_A_F) * 100 if (TN_A_F + FP_A_F) > 0 else 0\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Accuracy: {acc_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test F1-score: {f1_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Recall (Sensitivity): {recall_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Specificity: {specificity_A_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "357c6039-9f26-4de1-a9da-1f10dcda17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset B, Accuracy: 77.42%\n",
      "Fine-tuned, test on Dataset B, F1-score: 74.07%\n",
      "Fine-tuned, test on Dataset B, Recall (Sensitivity): 71.43%\n",
      "Fine-tuned, test on Dataset B, Specificity: 82.35%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Finetune_TNet = tabnet_finetuned.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_Finetune_TNet = confusion_matrix(y_B_test, Dataset_B_Finetune_TNet)\n",
    "TN_F, FP_F, FN_F, TP_F = cm_B_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_Finetune_TNet = accuracy_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "f1_B_Finetune_TNet = f1_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_Finetune_TNet = TP_F / (TP_F + FN_F) * 100\n",
    "specificity_B_Finetune_TNet = TN_F / (TN_F + FP_F) * 100\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset B, Accuracy: {acc_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, F1-score: {f1_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Recall (Sensitivity): {recall_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Specificity: {specificity_B_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81509e62-8502-4cb6-a7e1-d6c997fb4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Create the plot with a specific size\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Display confusion matrix as an image with the 'Blues' color map\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "# Set color bar ticks based on the max value of the matrix\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# Remove title as per request (You can uncomment the next line if you want to add a title)\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "# Label the axes\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Normalize the color range based on the confusion matrix values\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "# Iterate through the matrix to add text inside each cell\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))  # Get the color of the cell based on the value\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]  # Calculate luminance\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'  # Choose white or black text based on luminance\n",
    "        \n",
    "        # Add the text inside the cell with bold and Times New Roman font\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image with high resolution\n",
    "plt.savefig('confusion_matrix_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26f9b1-2251-4300-90ca-eca153ba1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Times New Roman font is used in all plots\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '20'})\n",
    "\n",
    "# Get predictions for TabNet model\n",
    "y_pred = tabnet_finetuned.predict(X_B_test)  # Get the class predictions for target domain\n",
    "y_pred_prob = tabnet_finetuned.predict_proba(X_B_test)[:, 1]  # Probabilities for the positive class (ROC)\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_B_test, y_pred) * 100\n",
    "recall = recall_score(y_B_test, y_pred) * 100\n",
    "f1 = f1_score(y_B_test, y_pred) * 100\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1-Score: {f1:.2f}%\")\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "tn, fp, fn, tp = confusion_matrix(y_B_test, y_pred).ravel()\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "print(f\"Specificity: {specificity:.2f}%\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_B_test, y_pred_prob) * 100\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_B_test, y_pred_prob)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()  # Display the plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d28fe7-74ba-41e7-8fef-2b8d2b0f3303",
   "metadata": {},
   "source": [
    "## 6. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1df4cc-4459-498a-a4e1-6bc8757c079b",
   "metadata": {},
   "source": [
    "### Pretraining phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6deece6-fe3b-4e0e-beed-38de643fc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'learning_rate' : 0.01,\n",
    "    'l2_reg' : 0.0001,\n",
    "    'neurons_l1' : 128,\n",
    "    'dropout_rate' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90ed9878-a295-4f60-b9fb-cc2c0715e139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m1,536\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_mlp_model(input_shape, best_params):\n",
    "    neurons_l1 = best_params['neurons_l1']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    l2_reg = best_params['l2_reg']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(neurons_l1, activation='relu', name='feature_layer_1', kernel_regularizer=keras.regularizers.l2(l2_reg))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/2), activation='relu', name='feature_layer_2', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/4), activation='relu', name='feature_layer_3', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_dim = X_pretrain_train.shape[1]\n",
    "mlp_pretrain = create_mlp_model(input_dim, best_params)\n",
    "mlp_pretrain.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "654d4553-dfdd-48c9-a387-9d970de06b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.5305 - auc: 0.5232 - loss: 4.0484 - val_accuracy: 0.4754 - val_auc: 0.6194 - val_loss: 0.7659\n",
      "Epoch 2/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5732 - auc: 0.5888 - loss: 0.7706 - val_accuracy: 0.5246 - val_auc: 0.6458 - val_loss: 0.6764\n",
      "Epoch 3/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5996 - auc: 0.6184 - loss: 0.6701 - val_accuracy: 0.6066 - val_auc: 0.6351 - val_loss: 0.6565\n",
      "Epoch 4/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6768 - auc: 0.7001 - loss: 0.6249 - val_accuracy: 0.6393 - val_auc: 0.6593 - val_loss: 0.6604\n",
      "Epoch 5/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6463 - auc: 0.6852 - loss: 0.6379 - val_accuracy: 0.5902 - val_auc: 0.6599 - val_loss: 0.6692\n",
      "Epoch 6/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6748 - auc: 0.7226 - loss: 0.6075 - val_accuracy: 0.5410 - val_auc: 0.6667 - val_loss: 0.6861\n",
      "Epoch 7/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6911 - auc: 0.7277 - loss: 0.6097 - val_accuracy: 0.5574 - val_auc: 0.6689 - val_loss: 0.6827\n",
      "Epoch 8/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6667 - auc: 0.7121 - loss: 0.6201 - val_accuracy: 0.7049 - val_auc: 0.6971 - val_loss: 0.6296\n",
      "Epoch 9/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7134 - auc: 0.7564 - loss: 0.5921 - val_accuracy: 0.6721 - val_auc: 0.7185 - val_loss: 0.6278\n",
      "Epoch 10/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7195 - auc: 0.7750 - loss: 0.5684 - val_accuracy: 0.5410 - val_auc: 0.6976 - val_loss: 0.6583\n",
      "Epoch 11/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6992 - auc: 0.7729 - loss: 0.5692 - val_accuracy: 0.5902 - val_auc: 0.7551 - val_loss: 0.7404\n",
      "Epoch 12/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7215 - auc: 0.7699 - loss: 0.5722 - val_accuracy: 0.7213 - val_auc: 0.7827 - val_loss: 0.5359\n",
      "Epoch 13/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7683 - auc: 0.8295 - loss: 0.5085 - val_accuracy: 0.6885 - val_auc: 0.7810 - val_loss: 0.6217\n",
      "Epoch 14/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7439 - auc: 0.8223 - loss: 0.5247 - val_accuracy: 0.6885 - val_auc: 0.7889 - val_loss: 0.5644\n",
      "Epoch 15/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7724 - auc: 0.8504 - loss: 0.4885 - val_accuracy: 0.6885 - val_auc: 0.8102 - val_loss: 0.5236\n",
      "Epoch 16/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8028 - auc: 0.8748 - loss: 0.4514 - val_accuracy: 0.6885 - val_auc: 0.8181 - val_loss: 0.6042\n",
      "Epoch 17/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7907 - auc: 0.8498 - loss: 0.4969 - val_accuracy: 0.7705 - val_auc: 0.8530 - val_loss: 0.4861\n",
      "Epoch 18/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7988 - auc: 0.8859 - loss: 0.4415 - val_accuracy: 0.7049 - val_auc: 0.8446 - val_loss: 0.5143\n",
      "Epoch 19/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8049 - auc: 0.8773 - loss: 0.4510 - val_accuracy: 0.7377 - val_auc: 0.8570 - val_loss: 0.4746\n",
      "Epoch 20/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8191 - auc: 0.9011 - loss: 0.4116 - val_accuracy: 0.7705 - val_auc: 0.8688 - val_loss: 0.4561\n",
      "Epoch 21/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8252 - auc: 0.8995 - loss: 0.4145 - val_accuracy: 0.7869 - val_auc: 0.8649 - val_loss: 0.4736\n",
      "Epoch 22/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8313 - auc: 0.8986 - loss: 0.4146 - val_accuracy: 0.7541 - val_auc: 0.8705 - val_loss: 0.4565\n",
      "Epoch 23/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - auc: 0.9064 - loss: 0.4043 - val_accuracy: 0.7541 - val_auc: 0.8609 - val_loss: 0.4997\n",
      "Epoch 24/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8049 - auc: 0.8956 - loss: 0.4193 - val_accuracy: 0.7869 - val_auc: 0.8626 - val_loss: 0.4888\n",
      "Epoch 25/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7988 - auc: 0.8889 - loss: 0.4300 - val_accuracy: 0.7705 - val_auc: 0.8682 - val_loss: 0.4788\n",
      "Epoch 26/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8130 - auc: 0.9034 - loss: 0.4065 - val_accuracy: 0.7705 - val_auc: 0.8750 - val_loss: 0.4421\n",
      "Epoch 27/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8293 - auc: 0.9059 - loss: 0.3984 - val_accuracy: 0.7869 - val_auc: 0.8688 - val_loss: 0.4757\n",
      "Epoch 28/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - auc: 0.9036 - loss: 0.4032 - val_accuracy: 0.7869 - val_auc: 0.8671 - val_loss: 0.4405\n",
      "Epoch 29/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9184 - loss: 0.3790 - val_accuracy: 0.7705 - val_auc: 0.8615 - val_loss: 0.4589\n",
      "Epoch 30/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - auc: 0.9170 - loss: 0.3843 - val_accuracy: 0.7869 - val_auc: 0.8716 - val_loss: 0.4634\n",
      "Epoch 31/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9139 - loss: 0.3911 - val_accuracy: 0.7869 - val_auc: 0.8649 - val_loss: 0.4799\n",
      "Epoch 32/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8150 - auc: 0.9026 - loss: 0.4112 - val_accuracy: 0.7869 - val_auc: 0.8750 - val_loss: 0.4788\n",
      "Epoch 33/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - auc: 0.8988 - loss: 0.4165 - val_accuracy: 0.7705 - val_auc: 0.8694 - val_loss: 0.4754\n",
      "Epoch 34/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8130 - auc: 0.8922 - loss: 0.4204 - val_accuracy: 0.7541 - val_auc: 0.8632 - val_loss: 0.4865\n",
      "Epoch 35/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8211 - auc: 0.9077 - loss: 0.4162 - val_accuracy: 0.7541 - val_auc: 0.8519 - val_loss: 0.5060\n",
      "Epoch 36/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8232 - auc: 0.9126 - loss: 0.3927 - val_accuracy: 0.7705 - val_auc: 0.8643 - val_loss: 0.4536\n",
      "Epoch 37/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8008 - auc: 0.8847 - loss: 0.4395 - val_accuracy: 0.7869 - val_auc: 0.8812 - val_loss: 0.4357\n",
      "Epoch 38/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8272 - auc: 0.9126 - loss: 0.3964 - val_accuracy: 0.7705 - val_auc: 0.8694 - val_loss: 0.4539\n",
      "Epoch 39/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8435 - auc: 0.9181 - loss: 0.3812 - val_accuracy: 0.7705 - val_auc: 0.8756 - val_loss: 0.4468\n",
      "Epoch 40/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8313 - auc: 0.9024 - loss: 0.4126 - val_accuracy: 0.7869 - val_auc: 0.8637 - val_loss: 0.4631\n",
      "Epoch 41/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9233 - loss: 0.3717 - val_accuracy: 0.7541 - val_auc: 0.8637 - val_loss: 0.4741\n",
      "Epoch 42/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8415 - auc: 0.9200 - loss: 0.3779 - val_accuracy: 0.7705 - val_auc: 0.8688 - val_loss: 0.4626\n",
      "Epoch 43/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8598 - auc: 0.9224 - loss: 0.3783 - val_accuracy: 0.7377 - val_auc: 0.8739 - val_loss: 0.4553\n",
      "Epoch 44/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8455 - auc: 0.9175 - loss: 0.3819 - val_accuracy: 0.8033 - val_auc: 0.8637 - val_loss: 0.4672\n",
      "Epoch 45/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8577 - auc: 0.9230 - loss: 0.3714 - val_accuracy: 0.7869 - val_auc: 0.8705 - val_loss: 0.4595\n",
      "Epoch 46/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9169 - loss: 0.3824 - val_accuracy: 0.8033 - val_auc: 0.8750 - val_loss: 0.4381\n",
      "Epoch 47/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - auc: 0.9164 - loss: 0.3799 - val_accuracy: 0.8033 - val_auc: 0.8750 - val_loss: 0.4441\n",
      "Epoch 48/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8354 - auc: 0.9153 - loss: 0.3913 - val_accuracy: 0.7541 - val_auc: 0.8660 - val_loss: 0.4578\n",
      "Epoch 49/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8638 - auc: 0.9283 - loss: 0.3599 - val_accuracy: 0.7869 - val_auc: 0.8727 - val_loss: 0.4610\n",
      "Epoch 50/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8659 - auc: 0.9309 - loss: 0.3532 - val_accuracy: 0.7869 - val_auc: 0.8750 - val_loss: 0.4574\n",
      "Epoch 51/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - auc: 0.9087 - loss: 0.3974 - val_accuracy: 0.7377 - val_auc: 0.8739 - val_loss: 0.4479\n",
      "Epoch 52/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - auc: 0.9192 - loss: 0.3840 - val_accuracy: 0.8033 - val_auc: 0.8739 - val_loss: 0.4935\n",
      "Epoch 53/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - auc: 0.9222 - loss: 0.3721 - val_accuracy: 0.7869 - val_auc: 0.8649 - val_loss: 0.4735\n",
      "Epoch 54/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8333 - auc: 0.9145 - loss: 0.3889 - val_accuracy: 0.8197 - val_auc: 0.8789 - val_loss: 0.4662\n",
      "Epoch 55/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9224 - loss: 0.3739 - val_accuracy: 0.7705 - val_auc: 0.8773 - val_loss: 0.4590\n",
      "Epoch 56/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9226 - loss: 0.3725 - val_accuracy: 0.7705 - val_auc: 0.8750 - val_loss: 0.4583\n",
      "Epoch 57/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9249 - loss: 0.3681 - val_accuracy: 0.8033 - val_auc: 0.8739 - val_loss: 0.4523\n",
      "Epoch 58/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8354 - auc: 0.9223 - loss: 0.3758 - val_accuracy: 0.7869 - val_auc: 0.8812 - val_loss: 0.4518\n",
      "Epoch 59/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8516 - auc: 0.9284 - loss: 0.3563 - val_accuracy: 0.7541 - val_auc: 0.8705 - val_loss: 0.4873\n",
      "Epoch 60/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8293 - auc: 0.9143 - loss: 0.3960 - val_accuracy: 0.7869 - val_auc: 0.8620 - val_loss: 0.4826\n",
      "Epoch 61/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - auc: 0.9181 - loss: 0.3817 - val_accuracy: 0.8033 - val_auc: 0.8744 - val_loss: 0.4640\n",
      "Epoch 62/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9211 - loss: 0.3786 - val_accuracy: 0.7869 - val_auc: 0.8789 - val_loss: 0.4407\n",
      "Epoch 63/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - auc: 0.9173 - loss: 0.3888 - val_accuracy: 0.8033 - val_auc: 0.8739 - val_loss: 0.4586\n",
      "Epoch 64/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8557 - auc: 0.9228 - loss: 0.3705 - val_accuracy: 0.8033 - val_auc: 0.8727 - val_loss: 0.4529\n",
      "Epoch 65/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9291 - loss: 0.3627 - val_accuracy: 0.7541 - val_auc: 0.8778 - val_loss: 0.4968\n",
      "Epoch 66/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9211 - loss: 0.3771 - val_accuracy: 0.8197 - val_auc: 0.8806 - val_loss: 0.4567\n",
      "Epoch 67/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8415 - auc: 0.9265 - loss: 0.3633 - val_accuracy: 0.8033 - val_auc: 0.8756 - val_loss: 0.4940\n",
      "Epoch 68/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8354 - auc: 0.8994 - loss: 0.4107 - val_accuracy: 0.8033 - val_auc: 0.8874 - val_loss: 0.4443\n",
      "Epoch 69/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - auc: 0.9221 - loss: 0.3810 - val_accuracy: 0.8033 - val_auc: 0.8829 - val_loss: 0.4470\n",
      "Epoch 70/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - auc: 0.9137 - loss: 0.3917 - val_accuracy: 0.7705 - val_auc: 0.8699 - val_loss: 0.4723\n",
      "Epoch 71/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8232 - auc: 0.9052 - loss: 0.4065 - val_accuracy: 0.7541 - val_auc: 0.8744 - val_loss: 0.4513\n",
      "Epoch 72/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8232 - auc: 0.9059 - loss: 0.4030 - val_accuracy: 0.7705 - val_auc: 0.8739 - val_loss: 0.4627\n",
      "Epoch 73/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8293 - auc: 0.9123 - loss: 0.3931 - val_accuracy: 0.8033 - val_auc: 0.8705 - val_loss: 0.4520\n",
      "Epoch 74/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8435 - auc: 0.9167 - loss: 0.3843 - val_accuracy: 0.8033 - val_auc: 0.8649 - val_loss: 0.4734\n",
      "Epoch 75/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - auc: 0.9065 - loss: 0.4031 - val_accuracy: 0.8361 - val_auc: 0.8789 - val_loss: 0.4641\n",
      "Epoch 76/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8679 - auc: 0.9251 - loss: 0.3705 - val_accuracy: 0.7869 - val_auc: 0.8812 - val_loss: 0.4705\n",
      "Epoch 77/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8516 - auc: 0.9184 - loss: 0.3789 - val_accuracy: 0.7869 - val_auc: 0.8722 - val_loss: 0.4544\n",
      "Epoch 78/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8354 - auc: 0.9229 - loss: 0.3742 - val_accuracy: 0.8033 - val_auc: 0.8688 - val_loss: 0.4598\n",
      "Epoch 79/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9194 - loss: 0.3775 - val_accuracy: 0.8033 - val_auc: 0.8705 - val_loss: 0.4442\n",
      "Epoch 80/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9280 - loss: 0.3669 - val_accuracy: 0.8033 - val_auc: 0.8727 - val_loss: 0.4715\n",
      "Epoch 81/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9220 - loss: 0.3735 - val_accuracy: 0.8361 - val_auc: 0.8908 - val_loss: 0.4736\n",
      "Epoch 82/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8435 - auc: 0.9197 - loss: 0.3797 - val_accuracy: 0.7869 - val_auc: 0.8744 - val_loss: 0.4574\n",
      "Epoch 83/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8496 - auc: 0.9227 - loss: 0.3767 - val_accuracy: 0.8033 - val_auc: 0.8671 - val_loss: 0.4635\n",
      "Epoch 84/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9195 - loss: 0.3749 - val_accuracy: 0.7869 - val_auc: 0.8750 - val_loss: 0.4398\n",
      "Epoch 85/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8415 - auc: 0.9132 - loss: 0.3915 - val_accuracy: 0.8033 - val_auc: 0.8834 - val_loss: 0.4423\n",
      "Epoch 86/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - auc: 0.9215 - loss: 0.3780 - val_accuracy: 0.8033 - val_auc: 0.8829 - val_loss: 0.4373\n",
      "Epoch 87/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - auc: 0.9145 - loss: 0.3903 - val_accuracy: 0.8033 - val_auc: 0.8789 - val_loss: 0.4397\n",
      "Epoch 88/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9281 - loss: 0.3601 - val_accuracy: 0.8033 - val_auc: 0.8851 - val_loss: 0.4407\n",
      "Epoch 89/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9353 - loss: 0.3447 - val_accuracy: 0.7869 - val_auc: 0.8868 - val_loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "pretrain_history = mlp_pretrain.fit(\n",
    "    X_pretrain_train, \n",
    "    y_pretrain_train,\n",
    "    epochs=150, # Start with a reasonable number of epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_pretrain_val, y_pretrain_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=52, restore_best_weights=True)\n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the pre-trained weights using the required extension\n",
    "mlp_pretrain.save_weights('mlp_pretrain.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d505ca53-a0de-4398-87c6-ccfe472c3f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.4958\n",
      "Max F1 Score at this threshold: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Use the fine-tune validation set (X_finetune_val) to find the threshold\n",
    "y_val_proba = mlp_pretrain.predict(X_finetune_val).ravel()\n",
    "precision, recall, thresholds = precision_recall_curve(y_finetune_val, y_val_proba)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6) # Added 1e-6 to prevent division by zero\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")\n",
    "\n",
    "# Now, use best_threshold instead of 0.5 for final testing (e.g., y_pred = (y_pred_proba > best_threshold).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cf444f1-dd04-40e2-9648-f1314e5065f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Pretraining Test Accuracy on Source domain: 80.65%\n",
      "Pretraining Test F1 on Source domain: 84.21%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 86.49%\n",
      "Pretraining Test Specificity on Source domain: 72.00%\n",
      "Pretraining Test ROC-AUC on Source domain: 0.90%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\")\n",
    "\n",
    "y_pred_proba_a = mlp_pretrain.predict(X_pretrain_test).ravel()\n",
    "\n",
    "\n",
    "y_pred_a = (y_pred_proba_a > best_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a = accuracy_score(y_pretrain_test, y_pred_a) * 100\n",
    "f1_a = f1_score(y_pretrain_test, y_pred_a) * 100\n",
    "roc_auc_a = roc_auc_score(y_pretrain_test, y_pred_proba_a) * 100\n",
    "recall_a = recall_score(y_pretrain_test, y_pred_a) * 100\n",
    "precision_a = precision_score(y_pretrain_test, y_pred_a) * 100\n",
    "specificity_a = recall_score(y_pretrain_test, y_pred_a, pos_label=0) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {accuracy_a:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {f1_a:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_a:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_a:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on Source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b01219ae-3d2a-4660-88f5-84ef12d70ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Pretraining Test Accuracy on target domain: 77.42%\n",
      "Pretraining Test F1 on target domain: 77.42%\n",
      "Pretraining Test Recall (Sensitivity) on target domain: 85.71%\n",
      "Pretraining Test Specificity on target domain: 70.59%\n",
      "Pretraining Test ROC-AUC on target domain: 0.84%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\")\n",
    "\n",
    "# Get raw probability predictions\n",
    "y_pred_proba_b = mlp_pretrain.predict(X_finetune_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_b = (y_pred_proba_b > best_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b = accuracy_score(y_finetune_test, y_pred_b) * 100\n",
    "f1_b = f1_score(y_finetune_test, y_pred_b) * 100\n",
    "roc_auc_b = roc_auc_score(y_finetune_test, y_pred_proba_b) * 100\n",
    "recall_b = recall_score(y_finetune_test, y_pred_b) * 100\n",
    "precision_b = precision_score(y_finetune_test, y_pred_b) * 100\n",
    "specificity_b = recall_score(y_finetune_test, y_pred_b, pos_label=0) * 100\n",
    "\n",
    "print(f\"Pretraining Test Accuracy on target domain: {accuracy_b:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on target domain: {f1_b:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on target domain: {recall_b:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on target domain: {specificity_b:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on target domain: {roc_auc_score(y_finetune_test, y_pred_proba_b):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e01e12-434e-48a8-bd31-fe2a5ae61bbf",
   "metadata": {},
   "source": [
    "### Finetuning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cdd7167-26dd-4d0c-9a56-ca4e44086c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m1,536\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,905</span> (46.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,905\u001b[0m (46.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,369</span> (40.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,369\u001b[0m (40.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def setup_fine_tuning(input_shape, pretrain_weights_path, best_params, fine_tune_lr=1e-1):\n",
    "    # Create the model with exactly the same architecture as pre-training\n",
    "    model_ft = create_mlp_model(input_shape, best_params)\n",
    "    \n",
    "    # Load pre-trained weights\n",
    "    model_ft.load_weights(pretrain_weights_path)\n",
    "\n",
    "    # Freeze layers for fine-tuning\n",
    "    model_ft.get_layer('feature_layer_1').trainable = False\n",
    "    model_ft.get_layer('feature_layer_2').trainable = True\n",
    "    model_ft.get_layer('feature_layer_3').trainable = True\n",
    "    \n",
    "    # Recompile with lower learning rate for fine-tuning\n",
    "    model_ft.compile(\n",
    "        optimizer=Adam(learning_rate=fine_tune_lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "\n",
    "    )\n",
    "    \n",
    "    finetune_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return model_ft, finetune_scheduler\n",
    "\n",
    "\n",
    "mlp_finetune, finetune_scheduler = setup_fine_tuning(\n",
    "    input_shape=input_dim,  # Use the input dimension from Dataset B\n",
    "    pretrain_weights_path='mlp_pretrain.weights.h5', \n",
    "    best_params=best_params,  # Add best_trial here\n",
    "    fine_tune_lr=0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Save the fine-tuned model weights (optional)\n",
    "mlp_finetune.save_weights('mlp_finetune_weights.weights.h5')\n",
    "\n",
    "# Check the model summary to ensure layers are frozen correctly\n",
    "mlp_finetune.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fc5d9c6-5dbc-425f-b6e0-5d5891ec0c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7231 - auc: 0.7644 - loss: 0.7858 - val_accuracy: 0.9333 - val_auc: 0.9688 - val_loss: 0.3253\n",
      "Epoch 2/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7645 - auc: 0.8018 - loss: 0.5481 - val_accuracy: 0.9667 - val_auc: 0.9643 - val_loss: 0.3555\n",
      "Epoch 3/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8572 - loss: 0.4863 - val_accuracy: 0.9000 - val_auc: 0.9710 - val_loss: 0.3348\n",
      "Epoch 4/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7810 - auc: 0.8598 - loss: 0.4736 - val_accuracy: 0.9667 - val_auc: 0.9665 - val_loss: 0.2807\n",
      "Epoch 5/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - auc: 0.8344 - loss: 0.4958 - val_accuracy: 0.9333 - val_auc: 0.9665 - val_loss: 0.3366\n",
      "Epoch 6/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - auc: 0.8427 - loss: 0.4933 - val_accuracy: 0.9333 - val_auc: 0.9643 - val_loss: 0.3351\n",
      "Epoch 7/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8099 - auc: 0.8520 - loss: 0.4934 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3766\n",
      "Epoch 8/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - auc: 0.8628 - loss: 0.4650 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3297\n",
      "Epoch 9/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6653 - auc: 0.8021 - loss: 0.5827 - val_accuracy: 0.8333 - val_auc: 0.9911 - val_loss: 0.5049\n",
      "Epoch 10/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7810 - auc: 0.8255 - loss: 0.6201 - val_accuracy: 0.9667 - val_auc: 0.9844 - val_loss: 0.4409\n",
      "Epoch 11/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8386 - loss: 0.5647 - val_accuracy: 0.8667 - val_auc: 0.9821 - val_loss: 0.4219\n",
      "Epoch 12/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7025 - auc: 0.8485 - loss: 0.5463 - val_accuracy: 0.8667 - val_auc: 0.9688 - val_loss: 0.3375\n",
      "Epoch 13/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7769 - auc: 0.8805 - loss: 0.4410 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.2490\n",
      "Epoch 14/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - auc: 0.8621 - loss: 0.4634 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.2697\n",
      "Epoch 15/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7975 - auc: 0.8547 - loss: 0.4925 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3367\n",
      "Epoch 16/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - auc: 0.8671 - loss: 0.4752 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.2834\n",
      "Epoch 17/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7686 - auc: 0.8647 - loss: 0.4712 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3100\n",
      "Epoch 18/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7645 - auc: 0.8531 - loss: 0.5204 - val_accuracy: 0.9000 - val_auc: 0.9576 - val_loss: 0.4025\n",
      "Epoch 19/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7810 - auc: 0.8206 - loss: 0.5180 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3303\n",
      "Epoch 20/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8099 - auc: 0.8635 - loss: 0.4701 - val_accuracy: 0.9333 - val_auc: 0.9933 - val_loss: 0.3454\n",
      "Epoch 21/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - auc: 0.8711 - loss: 0.4669 - val_accuracy: 0.9000 - val_auc: 0.9911 - val_loss: 0.3065\n",
      "Epoch 22/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - auc: 0.8519 - loss: 0.4888 - val_accuracy: 0.9333 - val_auc: 0.9821 - val_loss: 0.3674\n",
      "Epoch 23/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - auc: 0.8106 - loss: 0.5657 - val_accuracy: 0.9667 - val_auc: 0.9844 - val_loss: 0.4052\n",
      "Epoch 24/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8223 - auc: 0.8309 - loss: 0.5193 - val_accuracy: 0.9667 - val_auc: 0.9844 - val_loss: 0.3104\n",
      "Epoch 25/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7645 - auc: 0.8190 - loss: 0.5194 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.2704\n",
      "Epoch 26/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7397 - auc: 0.7942 - loss: 0.5762 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3909\n",
      "Epoch 27/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7645 - auc: 0.8015 - loss: 0.5420 - val_accuracy: 0.9333 - val_auc: 0.9576 - val_loss: 0.3289\n",
      "Epoch 28/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7975 - auc: 0.8454 - loss: 0.5095 - val_accuracy: 0.9333 - val_auc: 0.9821 - val_loss: 0.2849\n",
      "Epoch 29/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7562 - auc: 0.8179 - loss: 0.5475 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.2958\n",
      "Epoch 30/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6983 - auc: 0.7466 - loss: 0.6119 - val_accuracy: 0.8667 - val_auc: 0.9286 - val_loss: 0.4148\n",
      "Epoch 31/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7645 - auc: 0.7851 - loss: 0.5589 - val_accuracy: 0.9333 - val_auc: 0.9554 - val_loss: 0.3604\n",
      "Epoch 32/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7810 - auc: 0.8060 - loss: 0.5210 - val_accuracy: 0.9000 - val_auc: 0.9888 - val_loss: 0.3029\n",
      "Epoch 33/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7603 - auc: 0.8373 - loss: 0.5290 - val_accuracy: 0.9000 - val_auc: 0.9911 - val_loss: 0.2951\n",
      "Epoch 34/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7231 - auc: 0.7568 - loss: 0.6036 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3874\n",
      "Epoch 35/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7851 - auc: 0.8007 - loss: 0.5470 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.3704\n",
      "Epoch 36/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - auc: 0.7876 - loss: 0.5287 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.3650\n",
      "Epoch 37/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7645 - auc: 0.7654 - loss: 0.5224 - val_accuracy: 0.8667 - val_auc: 0.9598 - val_loss: 0.3767\n",
      "Epoch 38/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8017 - auc: 0.8021 - loss: 0.5215 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3468\n",
      "Epoch 39/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - auc: 0.8185 - loss: 0.5230 - val_accuracy: 0.9000 - val_auc: 0.9911 - val_loss: 0.3351\n",
      "Epoch 40/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6942 - auc: 0.7189 - loss: 0.6244 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3169\n",
      "Epoch 41/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - auc: 0.7885 - loss: 0.5246 - val_accuracy: 0.9667 - val_auc: 0.9911 - val_loss: 0.3366\n",
      "Epoch 42/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7562 - auc: 0.7611 - loss: 0.5479 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3736\n",
      "Epoch 43/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - auc: 0.8277 - loss: 0.5291 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.2812\n",
      "Epoch 44/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7314 - auc: 0.7985 - loss: 0.6185 - val_accuracy: 0.9667 - val_auc: 0.9598 - val_loss: 0.3048\n",
      "Epoch 45/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7521 - auc: 0.8218 - loss: 0.5501 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3152\n",
      "Epoch 46/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - auc: 0.8474 - loss: 0.4991 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3659\n",
      "Epoch 47/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7686 - auc: 0.7793 - loss: 0.5292 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.3401\n",
      "Epoch 48/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7810 - auc: 0.8319 - loss: 0.5264 - val_accuracy: 0.9667 - val_auc: 0.9598 - val_loss: 0.3150\n",
      "Epoch 49/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7810 - auc: 0.8204 - loss: 0.5026 - val_accuracy: 0.9667 - val_auc: 0.9598 - val_loss: 0.3092\n",
      "Epoch 50/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7769 - auc: 0.8337 - loss: 0.5283 - val_accuracy: 0.9667 - val_auc: 0.9911 - val_loss: 0.3331\n",
      "Epoch 51/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - auc: 0.8115 - loss: 0.5022 - val_accuracy: 0.9000 - val_auc: 0.9911 - val_loss: 0.2902\n",
      "Epoch 52/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - auc: 0.8170 - loss: 0.5458 - val_accuracy: 0.9333 - val_auc: 0.9576 - val_loss: 0.3001\n",
      "Epoch 53/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8017 - auc: 0.8525 - loss: 0.4789 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.2846\n",
      "Epoch 54/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - auc: 0.8436 - loss: 0.4939 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.3031\n",
      "Epoch 55/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7562 - auc: 0.7907 - loss: 0.5839 - val_accuracy: 0.9333 - val_auc: 0.9576 - val_loss: 0.3226\n",
      "Epoch 56/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7851 - auc: 0.8330 - loss: 0.5229 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.3201\n",
      "Epoch 57/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7479 - auc: 0.7632 - loss: 0.5676 - val_accuracy: 0.8667 - val_auc: 0.9866 - val_loss: 0.4195\n",
      "Epoch 58/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - auc: 0.8242 - loss: 0.5330 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.3199\n",
      "Epoch 59/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - auc: 0.8064 - loss: 0.5228 - val_accuracy: 0.9333 - val_auc: 0.9888 - val_loss: 0.3218\n",
      "Epoch 60/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - auc: 0.8182 - loss: 0.5434 - val_accuracy: 0.9667 - val_auc: 0.9911 - val_loss: 0.3388\n",
      "Epoch 61/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7810 - auc: 0.8265 - loss: 0.5083 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.3290\n",
      "Epoch 62/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7686 - auc: 0.8059 - loss: 0.5112 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.2774\n",
      "Epoch 63/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7562 - auc: 0.8436 - loss: 0.5037 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.3211\n",
      "Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\n"
     ]
    }
   ],
   "source": [
    "history_finetune = mlp_finetune.fit(\n",
    "    X_finetune_train, \n",
    "    y_finetune_train,\n",
    "    epochs=300, # Fewer epochs are usually needed for fine-tuning\n",
    "    batch_size=16, # Smaller batch size often works better for smaller datasets\n",
    "    validation_data=(X_finetune_val, y_finetune_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True), \n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03afe4a2-81e2-4c23-8d80-0081becbce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.5282\n",
      "Max F1 Score at this threshold: 0.9630\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Use the fine-tune validation set (X_finetune_val) to find the optimal threshold ---\n",
    "y_val_proba_ft = mlp_finetune.predict(X_finetune_val).ravel()  # Raw probability predictions\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_finetune_val, y_val_proba_ft)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6)  # Adding 1e-6 to prevent division by zero\n",
    "\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_finetune_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_finetune_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f96e9a9-99dc-4097-9b40-12d0919b4b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Finetune Test Accuracy on source domain: 82.26%\n",
      "Finetune Test F1 on source domain: 84.51%\n",
      "Finetune Test Recall (Sensitivity) on source domain: 81.08%\n",
      "Finetune Test Specificity on source domain: 84.00%\n",
      "Finetune Test ROC-AUC on source domain: 0.88%\n"
     ]
    }
   ],
   "source": [
    "# Get raw probability predictions\n",
    "y_pred_proba_a_ft = mlp_finetune.predict(X_pretrain_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_a_ft = (y_pred_proba_a_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a_ft = accuracy_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "f1_a_ft = f1_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "roc_auc_a_ft = roc_auc_score(y_pretrain_test, y_pred_proba_a_ft) * 100\n",
    "recall_a_ft = recall_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "precision_a_ft = precision_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "specificity_a_ft = recall_score(y_pretrain_test, y_pred_a_ft, pos_label=0) * 100\n",
    "\n",
    "print(f\"Finetune Test Accuracy on source domain: {accuracy_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on source domain: {f1_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on source domain: {recall_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on source domain: {specificity_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a_ft):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cab0016-9400-41f5-a52c-f41a284ef14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Finetune Test Accuracy on target domain: 83.87%\n",
      "Finetune Test F1 on target domain: 82.76%\n",
      "Finetune Test Recall (Sensitivity) on target domain: 85.71%\n",
      "Finetune Test Specificity on target domain: 82.35%\n",
      "Finetune Test ROC-AUC on target domain:0.90%\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_b_ft = mlp_finetune.predict(X_finetune_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions using a 0.5 threshold\n",
    "y_pred_b_ft = (y_pred_proba_b_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b_ft = accuracy_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "f1_b_ft = f1_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "roc_auc_b_ft = roc_auc_score(y_finetune_test, y_pred_proba_b_ft) * 100\n",
    "recall_b_ft = recall_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "precision_b_ft = precision_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "specificity_b_ft = recall_score(y_finetune_test, y_pred_b_ft, pos_label=0) * 100\n",
    "\n",
    "\n",
    "print(f\"Finetune Test Accuracy on target domain: {accuracy_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on target domain: {f1_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on target domain: {recall_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on target domain: {specificity_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on target domain:{roc_auc_score(y_finetune_test, y_pred_proba_b_ft):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41a579-48bb-43e7-a376-f650c63a5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Confusion matrix\n",
    "cm_mlp = confusion_matrix(y_finetune_test, y_pred_b_ft)\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm_mlp.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm_mlp, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm_mlp.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['Disease', 'No Disease'])\n",
    "# Set Y-axis labels (Actual: Disease then No Disease)\n",
    "plt.yticks([0, 1], ['No Disease', 'Disease'], rotation=90)  # Horizontal labels\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm_mlp.min(), vmax=cm_mlp.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm_mlp[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_mlp.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8075ea8-bc65-4ba4-ac42-11a3da38929e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03ed7f-4771-44e8-8c83-f0f239c44aab",
   "metadata": {},
   "source": [
    "## 8. Decision Curve Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844cb082-d33c-41e3-bf4e-f97f4c4fb786",
   "metadata": {},
   "source": [
    "## 9. Combined models ROC-AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "13e93627-3128-4f21-a053-1e4f5f70dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tabnet_finetuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred_prob_mlp \u001b[38;5;241m=\u001b[39m mlp_finetune\u001b[38;5;241m.\u001b[39mpredict(X_finetune_test)\n\u001b[1;32m----> 2\u001b[0m y_pred_prob_tabnet \u001b[38;5;241m=\u001b[39m tabnet_finetuned\u001b[38;5;241m.\u001b[39mpredict(X_B_test)\n\u001b[0;32m      3\u001b[0m y_pred_prob_xgb \u001b[38;5;241m=\u001b[39m xgb_finetune\u001b[38;5;241m.\u001b[39mpredict_proba(X_finetune_test)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tabnet_finetuned' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_prob_mlp = mlp_finetune.predict(X_finetune_test)\n",
    "y_pred_prob_tabnet = tabnet_finetuned.predict(X_B_test)\n",
    "y_pred_prob_xgb = xgb_finetune.predict_proba(X_finetune_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f0f19-fcd3-4444-b6ee-8111823392c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size': 18})\n",
    "\n",
    "# Get predicted probabilities for each model\n",
    "y_pred_prob_mlp = mlp_finetune.predict(X_finetune_test)\n",
    "y_pred_prob_tabnet = tabnet_finetuned.predict(X_B_test)  # Probabilities for the positive class (ROC)\n",
    "y_pred_proba_xgb = xgb_finetune.predict(X_finetune_test) \n",
    "\n",
    "# Calculate ROC curve and AUC for each model\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_finetune_test, y_pred_prob_mlp)\n",
    "fpr_tabnet, tpr_tabnet, _ = roc_curve(y_B_test, y_pred_prob_tabnet)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Calculate AUC for each model\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "roc_auc_tabnet = auc(fpr_tabnet, tpr_tabnet)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Also calculate using roc_auc_score for verification\n",
    "roc_auc_score_mlp = roc_auc_score(y_B_test, y_pred_prob_mlp)\n",
    "roc_auc_score_tabnet = roc_auc_score(y_B_test, y_pred_prob_tabnet)\n",
    "roc_auc_score_xgb = roc_auc_score(y_B_test, y_pred_proba_xgb)\n",
    "\n",
    "print(f\"MLP AUC (auc function): {roc_auc_mlp:.4f}\")\n",
    "print(f\"MLP AUC (roc_auc_score): {roc_auc_score_mlp:.4f}\")\n",
    "print(f\"TabNet AUC: {roc_auc_tabnet:.4f}\")\n",
    "print(f\"XGBoost AUC: {roc_auc_xgb:.4f}\")\n",
    "\n",
    "# Plot combined ROC curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot each ROC curve\n",
    "plt.plot(fpr_mlp, tpr_mlp, color='red', lw=2, label=f'MLP (AUC = {roc_auc_mlp:.2f})')\n",
    "plt.plot(fpr_tabnet, tpr_tabnet, color='green', lw=2, label=f'TabNet (AUC = {roc_auc_tabnet:.2f})')\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='orange', lw=2, label=f'XGBoost (AUC = {roc_auc_xgb:.2f})')\n",
    "\n",
    "# Diagonal line for random classifier\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Adjust plot settings\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('Combined ROC Curve for Fine-Tuned Models')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Save the combined ROC curve\n",
    "plt.savefig('roc_curve_combined.png', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f768dd-9508-4dc0-81b2-d060810cb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from your table\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "# Model performance data\n",
    "xgboost = {\n",
    "    \"Accuracy\": [85.48, 88.71, 90.32, 83.87],\n",
    "    \"F1-Score\": [84.85, 88.37, 89.66, 83.87],\n",
    "    \"Sensitivity\": [85.71, 92.86, 92.86, 92.86],\n",
    "    \"Specificity\": [85.29, 85.29, 88.24, 76.47]\n",
    "}\n",
    "\n",
    "tabnet = {\n",
    "    \"Accuracy\": [80.65, 82.26, 83.87, 77.42],\n",
    "    \"F1-Score\": [82.76, 83.33, 84.85, 78.79],\n",
    "    \"Sensitivity\": [92.86, 100.00, 100.00, 85.71],\n",
    "    \"Specificity\": [70.59, 70.59, 70.59, 70.59]\n",
    "}\n",
    "\n",
    "mlp = {\n",
    "    \"Accuracy\": [83.87, 85.48, 87.10, 79.03],\n",
    "    \"F1-Score\": [82.76, 84.21, 85.71, 78.13],\n",
    "    \"Sensitivity\": [85.71, 85.71, 85.71, 78.57],\n",
    "    \"Specificity\": [82.35, 85.29, 88.24, 79.41]\n",
    "}\n",
    "\n",
    "resnet = {\n",
    "    \"Accuracy\": [85.48, 87.10, 88.71, 83.87],\n",
    "    \"F1-Score\": [85.71, 87.18, 88.37, 84.21],\n",
    "    \"Sensitivity\": [92.86, 92.86, 92.86, 92.86],\n",
    "    \"Specificity\": [79.41, 82.35, 85.29, 76.47]\n",
    "}\n",
    "\n",
    "# List of models for iteration\n",
    "models = ['XGBoost', 'TabNet', 'MLP', 'ResNet']\n",
    "metrics = ['Accuracy', 'F1-Score', 'Sensitivity', 'Specificity']\n",
    "\n",
    "# Plotting graphs for each model and metric\n",
    "for model, data in zip(models, [xgboost, tabnet, mlp, resnet]):\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(learning_rates, data[metric], marker='P', linestyle='-', label=f'{model} - {metric}')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{model} - {metric} vs Learning Rate')\n",
    "        plt.xscale('log')  # Log scale for better visualization if needed\n",
    "        plt.xticks(learning_rates)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        # Save the image\n",
    "        plt.savefig(f'{model}_{metric}_vs_learning_rate.png')\n",
    "        plt.close()  # Close the plot to prevent overlapping with the next one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de987cf3-400e-4aae-a75e-f89021b617ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
