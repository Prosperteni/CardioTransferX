{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bcfb71-06cb-4875-a056-d0c6e7a1e03f",
   "metadata": {},
   "source": [
    "# <font size=5> <strong>Heart Disease Prediction -AblationStudy(Feature Selection)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f549498-ec6a-486b-a9fa-8bc07bd6aa5b",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbabcdc4-2528-4d97-a565-6b91d0b0633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: C:/Users/prosp/AIgroup4/Group4_HeartDiseasePrediciton-AblationStudy(Feature Selection)/mlp_tuning\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Directory path you want to delete\n",
    "dir_path = 'C:/Users/prosp/AIgroup4/Group4_HeartDiseasePrediciton-AblationStudy(Feature Selection)/mlp_tuning'\n",
    "# Delete the directory and its contents\n",
    "if os.path.exists(dir_path):\n",
    "    shutil.rmtree(dir_path)  # Deletes the directory and all its contents\n",
    "    print(f\"Deleted: {dir_path}\")\n",
    "else:\n",
    "    print(f\"Directory does not exist: {dir_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35d3eb7e-461a-4535-821a-ef64396d461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import(accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
    "                            auc, confusion_matrix, classification_report, make_scorer)\n",
    "\n",
    "# Modeling â€“ XGBoost and TabNet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "import random\n",
    "import os\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a94f5b-532a-4c85-b045-0754856c43e1",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed5e14-1c39-4cd1-b6a0-f7175bdf4f3d",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cae88cdd-d479-4855-837e-85e887c863f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_csv(\"Cleveland+Hungary+VA_long_beach+Switzerland.csv\") # Source domain = multi-hospital dataset\n",
    "df_B = pd.read_csv(\"Heart_disease_cleveland.csv\")                     # Target domain = original Cleveland dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4042b1b-b974-4412-9a46-ad17daa5779f",
   "metadata": {},
   "source": [
    "### Exploring and Inspecting Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "154cc2bf-576d-4b87-9108-5892e1736f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 919 entries, 0 to 918\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        919 non-null    int64  \n",
      " 1   age       919 non-null    int64  \n",
      " 2   sex       919 non-null    object \n",
      " 3   dataset   919 non-null    object \n",
      " 4   cp        919 non-null    object \n",
      " 5   trestbps  919 non-null    float64\n",
      " 6   chol      919 non-null    float64\n",
      " 7   fbs       919 non-null    bool   \n",
      " 8   restecg   919 non-null    object \n",
      " 9   thalch    919 non-null    float64\n",
      " 10  exang     919 non-null    bool   \n",
      " 11  oldpeak   919 non-null    float64\n",
      " 12  slope     919 non-null    object \n",
      " 13  ca        919 non-null    float64\n",
      " 14  thal      919 non-null    object \n",
      " 15  num       919 non-null    int64  \n",
      "dtypes: bool(2), float64(5), int64(3), object(6)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_A.info() # Displays concise summary of DataFrame A: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4569bfa4-2b5a-4e51-b930-0695fb312a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_B.info() # Displays concise summary of DataFrame B: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e990a-d349-4170-bb43-96a53e2a7ede",
   "metadata": {},
   "source": [
    "##### Cleaning and harmonizing information in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9653ec03-f608-4290-82f6-d6a39b3ef5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets before preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m                       0               1                  2\n",
      "id                     1               2                  3\n",
      "age                   63              67                 67\n",
      "sex                 Male            Male               Male\n",
      "dataset        Cleveland       Cleveland          Cleveland\n",
      "cp        typical angina    asymptomatic       asymptomatic\n",
      "trestbps           145.0           160.0              120.0\n",
      "chol               233.0           286.0              229.0\n",
      "fbs                 True           False              False\n",
      "restecg   lv hypertrophy  lv hypertrophy     lv hypertrophy\n",
      "thalch             150.0           108.0              129.0\n",
      "exang              False            True               True\n",
      "oldpeak              2.3             1.5                2.6\n",
      "slope        downsloping            flat               flat\n",
      "ca                   0.0             3.0                2.0\n",
      "thal        fixed defect          normal  reversable defect\n",
      "num                    0               2                  1\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "age        63.0   67.0   67.0\n",
      "sex         1.0    1.0    1.0\n",
      "cp          0.0    3.0    3.0\n",
      "trestbps  145.0  160.0  120.0\n",
      "chol      233.0  286.0  229.0\n",
      "fbs         1.0    0.0    0.0\n",
      "restecg     2.0    2.0    2.0\n",
      "thalach   150.0  108.0  129.0\n",
      "exang       0.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "slope       2.0    1.0    1.0\n",
      "ca          0.0    3.0    2.0\n",
      "thal        2.0    1.0    3.0\n",
      "target      0.0    1.0    1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets before preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2df8ede-ec12-435d-96b3-69ea3f3ba6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Cleveland data from df_A before pretraining\n",
    "df_A = df_A[df_A['dataset'] != 'Cleveland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2f871dd-ca19-4a0c-a2f0-5bf65455002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
      "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
      "      dtype='object')\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_A.columns) # Prints the list of column names in DataFrame A.\n",
    "print(df_B.columns) # Prints the list of column names in DataFrame B."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edb2754-fbd5-44da-a9a9-310d6f34d472",
   "metadata": {},
   "source": [
    "1. We inspected the datasets using df.info(), df.columns, and df.head().\n",
    "#    Observations from Dataset A (combined multi-hospital dataset):\n",
    "- Many categorical columns (sex, cp, fbs, restecg, slope, thal, exang) are strings/booleans.\n",
    "- Some numeric columns have missing values (trestbps, chol, thalach, oldpeak, ca).\n",
    "- Column names differ from Dataset B (e.g., 'thalch' vs 'thalach', 'num' vs 'target').\n",
    "- Extra columns exist (e.g., 'id', 'dataset') that are irrelevant for modeling.\n",
    "- The target column uses 0â€“4 scale instead of 0/1 like Dataset B.\n",
    "\n",
    "#    Observations from Dataset B (Cleveland dataset):\n",
    "- All categorical columns are already numeric (int64), matching expected encoding.\n",
    "- No missing values.\n",
    "- Target column is binary (0=no disease, 1=disease).\n",
    "\n",
    "2. Based on these observations, the following harmonization steps are necessary:\n",
    "- Rename columns in Dataset A to match Dataset B.\n",
    "- Drop irrelevant columns in Dataset A (id, dataset).\n",
    "- Map all categorical strings/booleans in Dataset A to numeric codes matching Dataset B.\n",
    "- Fill missing values: \n",
    "#           â€¢ Categorical â†’ mode of column\n",
    "#           â€¢ Numeric â†’ median of column\n",
    "- Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "- Align features so both datasets have identical column names and encodings.\n",
    "\n",
    "3. Purpose:\n",
    "- Ensure that Dataset A (pretraining) and Dataset B (fine-tuning) are fully compatible.\n",
    "- Prevent encoding mismatches that would break transfer learning.\n",
    "- Guarantee that the XGBoost model receives numeric input for all features.\n",
    "- Maintain consistency for feature importance and SHAP explainability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "856b1cf3-d252-4c47-a02e-1450c084d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.rename(columns={'thalch': 'thalach','num': 'target'}) #Rename columns in Dataset A to match Dataset B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a0bc1c1-cea8-40ab-b12e-5e694f524027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.drop(columns=['id', 'dataset']) #Drop irrelevant columns in Dataset A (id, dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1915aeb1-8cdf-4f58-a0a6-20c303b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "df_A['target'] = df_A['target'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ae38850-7e49-4efc-b2e2-ccb20ca3da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all categorical strings/booleans in Dataset A to numeric codes matching the target domain.\n",
    "sex_map = {'Male': 1, 'Female': 0}\n",
    "\n",
    "cp_map = {\n",
    "    'typical angina': 0,\n",
    "    'atypical angina': 1,\n",
    "    'non-anginal': 2,\n",
    "    'asymptomatic': 3\n",
    "}\n",
    "\n",
    "fbs_map = {True: 1, False: 0}\n",
    "\n",
    "restecg_map = {\n",
    "    'normal': 0,\n",
    "    'st-t abnormality': 1,\n",
    "    'lv hypertrophy': 2\n",
    "}\n",
    "\n",
    "exang_map = {True: 1, False: 0}\n",
    "\n",
    "slope_map = {\n",
    "    'upsloping': 0,\n",
    "    'flat': 1,\n",
    "    'downsloping': 2\n",
    "}\n",
    "\n",
    "thal_map = {\n",
    "    'normal': 1,\n",
    "    'fixed defect': 2,\n",
    "    'reversable defect': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a2ac638-c3d6-4ad2-b138-6de8b87454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features so both datasets have identical column names and encodings.\n",
    "df_A['sex'] = df_A['sex'].map(sex_map)\n",
    "df_A['cp'] = df_A['cp'].map(cp_map)\n",
    "df_A['fbs'] = df_A['fbs'].map(fbs_map)\n",
    "df_A['restecg'] = df_A['restecg'].map(restecg_map)\n",
    "df_A['exang'] = df_A['exang'].map(exang_map)\n",
    "df_A['slope'] = df_A['slope'].map(slope_map)\n",
    "df_A['thal'] = df_A['thal'].map(thal_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e875d2bd-fdd7-4f55-98d3-b73e4b58589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Check (Both should return zero missing values.)\n",
    "print(df_A.isnull().sum())\n",
    "print(df_B.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ed95ab7-b7dd-4f15-be3c-fb4b6bf2c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       615 non-null    int64  \n",
      " 1   sex       615 non-null    int64  \n",
      " 2   cp        615 non-null    int64  \n",
      " 3   trestbps  615 non-null    float64\n",
      " 4   chol      615 non-null    float64\n",
      " 5   fbs       615 non-null    int64  \n",
      " 6   restecg   615 non-null    int64  \n",
      " 7   thalach   615 non-null    float64\n",
      " 8   exang     615 non-null    int64  \n",
      " 9   oldpeak   615 non-null    float64\n",
      " 10  slope     615 non-null    int64  \n",
      " 11  ca        615 non-null    float64\n",
      " 12  thal      615 non-null    int64  \n",
      " 13  target    615 non-null    int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 72.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the target domain to ensure all columns are non-null.\n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5bd4404-68aa-497c-8c21-7b57d80c56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the source domain to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "942f2971-925d-45e2-a4cb-c175fb3f4785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.092683</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>2.297561</td>\n",
       "      <td>133.209366</td>\n",
       "      <td>178.288276</td>\n",
       "      <td>0.151220</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>130.435220</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.942377</td>\n",
       "      <td>0.808130</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>2.347967</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.544659</td>\n",
       "      <td>0.364778</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>18.305233</td>\n",
       "      <td>122.310526</td>\n",
       "      <td>0.358554</td>\n",
       "      <td>0.611066</td>\n",
       "      <td>24.077586</td>\n",
       "      <td>0.499294</td>\n",
       "      <td>1.099715</td>\n",
       "      <td>0.578326</td>\n",
       "      <td>0.689712</td>\n",
       "      <td>0.887421</td>\n",
       "      <td>0.490297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>142.450000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean    53.092683    0.842276    2.297561  133.209366  178.288276    0.151220   \n",
       "std      9.544659    0.364778    0.913655   18.305233  122.310526    0.358554   \n",
       "min     29.000000    0.000000    0.000000   80.000000    0.000000    0.000000   \n",
       "25%     47.000000    1.000000    2.000000  120.000000    0.000000    0.000000   \n",
       "50%     54.000000    1.000000    3.000000  130.000000  216.000000    0.000000   \n",
       "75%     60.000000    1.000000    3.000000  142.450000  263.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  603.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean     0.414634  130.435220    0.466667    0.942377    0.808130    0.422764   \n",
       "std      0.611066   24.077586    0.499294    1.099715    0.578326    0.689712   \n",
       "min      0.000000   60.000000    0.000000   -2.600000    0.000000    0.000000   \n",
       "25%      0.000000  116.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000  129.000000    0.000000    0.700000    1.000000    0.000000   \n",
       "75%      1.000000  148.000000    1.000000    2.000000    1.000000    1.000000   \n",
       "max      2.000000  190.000000    1.000000    5.000000    2.000000    2.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  615.000000  615.000000  \n",
       "mean     2.347967    0.600000  \n",
       "std      0.887421    0.490297  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      3.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measure about the dataset A\n",
    "df_A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93a17240-a2d2-4928-8760-ae4a4e1c2004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>2.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>0.600660</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>1.831683</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.956705</td>\n",
       "      <td>0.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    2.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    2.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    2.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    3.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    0.600660    0.663366   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.934375   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    1.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    3.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     1.831683    0.458746  \n",
       "std      0.956705    0.499120  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      1.000000    0.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measure about the dataset B\n",
    "df_B.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a6f21b3-09fa-4906-bcd0-787cec6e8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleanedup dataset A\n",
    "df_A.to_csv(\"Preprocessed_Cleveland+Hungary+VA_long_beach+Switzerland.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1379d430-3f33-4601-b561-d88b27bfb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleanedup dataset B\n",
    "df_B.to_csv(\"Preprocessed_Heart_disease_cleveland.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d65ebbf-ecdc-4821-9ae1-fd383ac64e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets after preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m            304     305    306\n",
      "age        29.0   29.00   30.0\n",
      "sex         1.0    1.00    0.0\n",
      "cp          1.0    1.00    0.0\n",
      "trestbps  120.0  140.00  170.0\n",
      "chol      243.0  240.48  237.0\n",
      "fbs         0.0    0.00    0.0\n",
      "restecg     0.0    0.00    1.0\n",
      "thalach   160.0  170.00  170.0\n",
      "exang       0.0    0.00    0.0\n",
      "oldpeak     0.0    0.00    0.0\n",
      "slope       0.0    0.00    0.0\n",
      "ca          0.0    0.00    0.0\n",
      "thal        1.0    1.00    2.0\n",
      "target      0.0    0.00    0.0\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "age        63.0   67.0   67.0\n",
      "sex         1.0    1.0    1.0\n",
      "cp          0.0    3.0    3.0\n",
      "trestbps  145.0  160.0  120.0\n",
      "chol      233.0  286.0  229.0\n",
      "fbs         1.0    0.0    0.0\n",
      "restecg     2.0    2.0    2.0\n",
      "thalach   150.0  108.0  129.0\n",
      "exang       0.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "slope       2.0    1.0    1.0\n",
      "ca          0.0    3.0    2.0\n",
      "thal        2.0    1.0    3.0\n",
      "target      0.0    1.0    1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets after preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2989af38-42d7-4737-877a-165b905ea3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       615 non-null    int64  \n",
      " 1   sex       615 non-null    int64  \n",
      " 2   cp        615 non-null    int64  \n",
      " 3   trestbps  615 non-null    float64\n",
      " 4   chol      615 non-null    float64\n",
      " 5   fbs       615 non-null    int64  \n",
      " 6   restecg   615 non-null    int64  \n",
      " 7   thalach   615 non-null    float64\n",
      " 8   exang     615 non-null    int64  \n",
      " 9   oldpeak   615 non-null    float64\n",
      " 10  slope     615 non-null    int64  \n",
      " 11  ca        615 non-null    float64\n",
      " 12  thal      615 non-null    int64  \n",
      " 13  target    615 non-null    int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 72.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for dataset A to ensure all columns are non-null. \n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a42ddf0-70a5-4544-becd-878ea6d9fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for dataset B to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159229f-e4d9-4664-8d8f-e1580b957da5",
   "metadata": {},
   "source": [
    "## 3. Data split and class imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d69b4881-6507-4e0d-97c5-f4669664b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain = df_A.drop('target', axis=1) \n",
    "y_pretrain = df_A['target']               \n",
    "\n",
    "# Split the source domain into 80% train and 20% temp (for val+test)\n",
    "X_pretrain_train, X_pretrain_temp, y_pretrain_train, y_pretrain_temp = train_test_split(\n",
    "    X_pretrain, y_pretrain,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test)\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test â†’ each 10% of total\n",
    "X_pretrain_val, X_pretrain_test, y_pretrain_val, y_pretrain_test = train_test_split(\n",
    "    X_pretrain_temp, y_pretrain_temp,\n",
    "    test_size=0.5,          # half of temp = 10% of total\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain_temp\n",
    ")\n",
    "\n",
    "# Target domain: Cleveland dataset for FINE-TUNING and evaluation\n",
    "X_finetune = df_B.drop('target', axis=1)\n",
    "y_finetune = df_B['target']\n",
    "\n",
    "\n",
    "# Split target domain into 80% train and 20% temp (for val+test)\n",
    "X_finetune_train, X_finetune_temp, y_finetune_train, y_finetune_temp = train_test_split(\n",
    "    X_finetune, y_finetune,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test) \n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune     # preserve class distribution\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test â†’ each 10% of total\n",
    "X_finetune_val, X_finetune_test, y_finetune_val, y_finetune_test = train_test_split(\n",
    "    X_finetune_temp, y_finetune_temp,\n",
    "    test_size=0.5,          # 20% of training data will be used as the validation set\n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune_temp  # preserve class distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "260d9c15-74da-40eb-a352-35ea458bc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ðŸ“Š Source Domain Shapes ##\n",
      "---\n",
      "X_pretrain_train shape: (492, 13)\n",
      "X_pretrain_val   shape: (61, 13)\n",
      "X_pretrain_test  shape: (62, 13)\n",
      "Total X rows: 615\n",
      "\n",
      "\n",
      "y_pretrain_train shape: (492,)\n",
      "y_pretrain_val   shape: (61,)\n",
      "y_pretrain_test  shape: (62,)\n",
      "\n",
      "## ðŸŽ¯ Target Domain Shapes ##\n",
      "---\n",
      "X_finetune_train shape: (242, 13)\n",
      "X_finetune_val   shape: (30, 13)\n",
      "X_finetune_test  shape: (31, 13)\n",
      "Total X rows: 303\n",
      "\n",
      "\n",
      "y_finetune_train shape: (242,)\n",
      "y_finetune_val   shape: (30,)\n",
      "y_finetune_test  shape: (31,)\n"
     ]
    }
   ],
   "source": [
    "print(\"## ðŸ“Š Source Domain Shapes ##\")\n",
    "print(\"---\")\n",
    "\n",
    "# Feature Matrix (X) Shapes\n",
    "print(\"X_pretrain_train shape:\", X_pretrain_train.shape)\n",
    "print(\"X_pretrain_val   shape:\", X_pretrain_val.shape)\n",
    "print(\"X_pretrain_test  shape:\", X_pretrain_test.shape)\n",
    "print(\"Total X rows:\", \n",
    "      X_pretrain_train.shape[0] + X_pretrain_val.shape[0] + X_pretrain_test.shape[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Target Vector (y) Shapes\n",
    "print(\"y_pretrain_train shape:\", y_pretrain_train.shape)\n",
    "print(\"y_pretrain_val   shape:\", y_pretrain_val.shape)\n",
    "print(\"y_pretrain_test  shape:\", y_pretrain_test.shape)\n",
    "\n",
    "\n",
    "## --- Target domain Splits ---\n",
    "print(\"\\n## ðŸŽ¯ Target Domain Shapes ##\")\n",
    "print(\"---\")\n",
    "\n",
    "# Feature Matrix (X) Shapes\n",
    "print(\"X_finetune_train shape:\", X_finetune_train.shape)\n",
    "print(\"X_finetune_val   shape:\", X_finetune_val.shape)\n",
    "print(\"X_finetune_test  shape:\", X_finetune_test.shape)\n",
    "print(\"Total X rows:\", \n",
    "      X_finetune_train.shape[0] + X_finetune_val.shape[0] + X_finetune_test.shape[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Target Vector (y) Shapes\n",
    "print(\"y_finetune_train shape:\", y_finetune_train.shape)\n",
    "print(\"y_finetune_val   shape:\", y_finetune_val.shape)\n",
    "print(\"y_finetune_test  shape:\", y_finetune_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19949afb-01fc-4657-96ce-2da3f9388d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Dataset A training data shape: (590, 13)\n",
      "Resampled Dataset B training data shape: (262, 13)\n",
      "Class distribution before SMOTE (Source domain): \n",
      "target\n",
      "1    295\n",
      "0    197\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE (Source domain): \n",
      "target\n",
      "1    295\n",
      "0    295\n",
      "Name: count, dtype: int64\n",
      "Class distribution before SMOTE (Target domain): \n",
      "target\n",
      "0    131\n",
      "1    111\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE (Target domain): \n",
      "target\n",
      "1    131\n",
      "0    131\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to source domain data (X_pretrain_train, y_pretrain_train)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_pretrain_train_res, y_pretrain_train_res = smote.fit_resample(X_pretrain_train, y_pretrain_train)\n",
    "\n",
    "# Apply SMOTE to target domain data (X_finetune_train, y_finetune_train)\n",
    "X_finetune_train_res, y_finetune_train_res = smote.fit_resample(X_finetune_train, y_finetune_train)\n",
    "\n",
    "# Check the resampled data shapes and class distributions\n",
    "print(f\"Resampled Dataset A training data shape: {X_pretrain_train_res.shape}\")\n",
    "print(f\"Resampled Dataset B training data shape: {X_finetune_train_res.shape}\")\n",
    "\n",
    "# Optionally, you can print the class distribution before and after SMOTE\n",
    "print(f\"Class distribution before SMOTE (Source domain): \\n{y_pretrain_train.value_counts()}\")\n",
    "print(f\"Class distribution after SMOTE (Source domain): \\n{y_pretrain_train_res.value_counts()}\")\n",
    "\n",
    "print(f\"Class distribution before SMOTE (Target domain): \\n{y_finetune_train.value_counts()}\")\n",
    "print(f\"Class distribution after SMOTE (Target domain): \\n{y_finetune_train_res.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21018af5-37a7-4e67-878e-39dfb70cb439",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a6b5e-ed72-44d9-afb4-d1c9a756ceb7",
   "metadata": {},
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb972dad-3d65-4aa5-9a35-17ef70094585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best parameters found during the Grid Search for pretraining on Dataset A\n",
    "best_pretrain_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 0.5, \n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Best parameters for pretraining: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6,\n",
    "#                                   'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
    "# Best F1-score: 0.8647\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ff71334-005f-4c43-85e7-ad7ef8d86ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.01\n",
      "  max_depth: 8\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 0.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.68833\n",
      "[1]\tvalidation_0-logloss:0.68431\n",
      "[2]\tvalidation_0-logloss:0.67932\n",
      "[3]\tvalidation_0-logloss:0.67484\n",
      "[4]\tvalidation_0-logloss:0.66989\n",
      "[5]\tvalidation_0-logloss:0.66545\n",
      "[6]\tvalidation_0-logloss:0.66105\n",
      "[7]\tvalidation_0-logloss:0.65647\n",
      "[8]\tvalidation_0-logloss:0.65272\n",
      "[9]\tvalidation_0-logloss:0.64901\n",
      "[10]\tvalidation_0-logloss:0.64600\n",
      "[11]\tvalidation_0-logloss:0.64185\n",
      "[12]\tvalidation_0-logloss:0.63813\n",
      "[13]\tvalidation_0-logloss:0.63432\n",
      "[14]\tvalidation_0-logloss:0.63075\n",
      "[15]\tvalidation_0-logloss:0.62796\n",
      "[16]\tvalidation_0-logloss:0.62504\n",
      "[17]\tvalidation_0-logloss:0.62185\n",
      "[18]\tvalidation_0-logloss:0.61795\n",
      "[19]\tvalidation_0-logloss:0.61404\n",
      "[20]\tvalidation_0-logloss:0.61136\n",
      "[21]\tvalidation_0-logloss:0.60773\n",
      "[22]\tvalidation_0-logloss:0.60424\n",
      "[23]\tvalidation_0-logloss:0.60159\n",
      "[24]\tvalidation_0-logloss:0.59848\n",
      "[25]\tvalidation_0-logloss:0.59607\n",
      "[26]\tvalidation_0-logloss:0.59296\n",
      "[27]\tvalidation_0-logloss:0.59003\n",
      "[28]\tvalidation_0-logloss:0.58711\n",
      "[29]\tvalidation_0-logloss:0.58446\n",
      "[30]\tvalidation_0-logloss:0.58111\n",
      "[31]\tvalidation_0-logloss:0.57852\n",
      "[32]\tvalidation_0-logloss:0.57656\n",
      "[33]\tvalidation_0-logloss:0.57326\n",
      "[34]\tvalidation_0-logloss:0.57013\n",
      "[35]\tvalidation_0-logloss:0.56785\n",
      "[36]\tvalidation_0-logloss:0.56502\n",
      "[37]\tvalidation_0-logloss:0.56268\n",
      "[38]\tvalidation_0-logloss:0.56035\n",
      "[39]\tvalidation_0-logloss:0.55830\n",
      "[40]\tvalidation_0-logloss:0.55627\n",
      "[41]\tvalidation_0-logloss:0.55410\n",
      "[42]\tvalidation_0-logloss:0.55151\n",
      "[43]\tvalidation_0-logloss:0.54936\n",
      "[44]\tvalidation_0-logloss:0.54741\n",
      "[45]\tvalidation_0-logloss:0.54535\n",
      "[46]\tvalidation_0-logloss:0.54364\n",
      "[47]\tvalidation_0-logloss:0.54139\n",
      "[48]\tvalidation_0-logloss:0.53950\n",
      "[49]\tvalidation_0-logloss:0.53743\n",
      "[50]\tvalidation_0-logloss:0.53528\n",
      "[51]\tvalidation_0-logloss:0.53352\n",
      "[52]\tvalidation_0-logloss:0.53246\n",
      "[53]\tvalidation_0-logloss:0.53006\n",
      "[54]\tvalidation_0-logloss:0.52829\n",
      "[55]\tvalidation_0-logloss:0.52615\n",
      "[56]\tvalidation_0-logloss:0.52411\n",
      "[57]\tvalidation_0-logloss:0.52287\n",
      "[58]\tvalidation_0-logloss:0.52109\n",
      "[59]\tvalidation_0-logloss:0.51912\n",
      "[60]\tvalidation_0-logloss:0.51707\n",
      "[61]\tvalidation_0-logloss:0.51584\n",
      "[62]\tvalidation_0-logloss:0.51424\n",
      "[63]\tvalidation_0-logloss:0.51252\n",
      "[64]\tvalidation_0-logloss:0.51035\n",
      "[65]\tvalidation_0-logloss:0.50854\n",
      "[66]\tvalidation_0-logloss:0.50720\n",
      "[67]\tvalidation_0-logloss:0.50539\n",
      "[68]\tvalidation_0-logloss:0.50436\n",
      "[69]\tvalidation_0-logloss:0.50255\n",
      "[70]\tvalidation_0-logloss:0.50108\n",
      "[71]\tvalidation_0-logloss:0.50029\n",
      "[72]\tvalidation_0-logloss:0.49922\n",
      "[73]\tvalidation_0-logloss:0.49796\n",
      "[74]\tvalidation_0-logloss:0.49725\n",
      "[75]\tvalidation_0-logloss:0.49571\n",
      "[76]\tvalidation_0-logloss:0.49511\n",
      "[77]\tvalidation_0-logloss:0.49427\n",
      "[78]\tvalidation_0-logloss:0.49300\n",
      "[79]\tvalidation_0-logloss:0.49178\n",
      "[80]\tvalidation_0-logloss:0.49089\n",
      "[81]\tvalidation_0-logloss:0.48978\n",
      "[82]\tvalidation_0-logloss:0.48865\n",
      "[83]\tvalidation_0-logloss:0.48767\n",
      "[84]\tvalidation_0-logloss:0.48608\n",
      "[85]\tvalidation_0-logloss:0.48506\n",
      "[86]\tvalidation_0-logloss:0.48404\n",
      "[87]\tvalidation_0-logloss:0.48361\n",
      "[88]\tvalidation_0-logloss:0.48241\n",
      "[89]\tvalidation_0-logloss:0.48109\n",
      "[90]\tvalidation_0-logloss:0.47980\n",
      "[91]\tvalidation_0-logloss:0.47880\n",
      "[92]\tvalidation_0-logloss:0.47788\n",
      "[93]\tvalidation_0-logloss:0.47665\n",
      "[94]\tvalidation_0-logloss:0.47517\n",
      "[95]\tvalidation_0-logloss:0.47402\n",
      "[96]\tvalidation_0-logloss:0.47280\n",
      "[97]\tvalidation_0-logloss:0.47187\n",
      "[98]\tvalidation_0-logloss:0.47112\n",
      "[99]\tvalidation_0-logloss:0.46980\n",
      "[100]\tvalidation_0-logloss:0.46843\n",
      "[101]\tvalidation_0-logloss:0.46763\n",
      "[102]\tvalidation_0-logloss:0.46666\n",
      "[103]\tvalidation_0-logloss:0.46555\n",
      "[104]\tvalidation_0-logloss:0.46449\n",
      "[105]\tvalidation_0-logloss:0.46380\n",
      "[106]\tvalidation_0-logloss:0.46252\n",
      "[107]\tvalidation_0-logloss:0.46138\n",
      "[108]\tvalidation_0-logloss:0.46060\n",
      "[109]\tvalidation_0-logloss:0.45995\n",
      "[110]\tvalidation_0-logloss:0.45931\n",
      "[111]\tvalidation_0-logloss:0.45865\n",
      "[112]\tvalidation_0-logloss:0.45768\n",
      "[113]\tvalidation_0-logloss:0.45656\n",
      "[114]\tvalidation_0-logloss:0.45531\n",
      "[115]\tvalidation_0-logloss:0.45448\n",
      "[116]\tvalidation_0-logloss:0.45379\n",
      "[117]\tvalidation_0-logloss:0.45368\n",
      "[118]\tvalidation_0-logloss:0.45285\n",
      "[119]\tvalidation_0-logloss:0.45188\n",
      "[120]\tvalidation_0-logloss:0.45100\n",
      "[121]\tvalidation_0-logloss:0.45089\n",
      "[122]\tvalidation_0-logloss:0.45010\n",
      "[123]\tvalidation_0-logloss:0.44936\n",
      "[124]\tvalidation_0-logloss:0.44897\n",
      "[125]\tvalidation_0-logloss:0.44799\n",
      "[126]\tvalidation_0-logloss:0.44697\n",
      "[127]\tvalidation_0-logloss:0.44693\n",
      "[128]\tvalidation_0-logloss:0.44635\n",
      "[129]\tvalidation_0-logloss:0.44578\n",
      "[130]\tvalidation_0-logloss:0.44494\n",
      "[131]\tvalidation_0-logloss:0.44394\n",
      "[132]\tvalidation_0-logloss:0.44366\n",
      "[133]\tvalidation_0-logloss:0.44315\n",
      "[134]\tvalidation_0-logloss:0.44285\n",
      "[135]\tvalidation_0-logloss:0.44265\n",
      "[136]\tvalidation_0-logloss:0.44206\n",
      "[137]\tvalidation_0-logloss:0.44153\n",
      "[138]\tvalidation_0-logloss:0.44090\n",
      "[139]\tvalidation_0-logloss:0.44064\n",
      "[140]\tvalidation_0-logloss:0.43959\n",
      "[141]\tvalidation_0-logloss:0.43917\n",
      "[142]\tvalidation_0-logloss:0.43895\n",
      "[143]\tvalidation_0-logloss:0.43866\n",
      "[144]\tvalidation_0-logloss:0.43856\n",
      "[145]\tvalidation_0-logloss:0.43814\n",
      "[146]\tvalidation_0-logloss:0.43747\n",
      "[147]\tvalidation_0-logloss:0.43705\n",
      "[148]\tvalidation_0-logloss:0.43699\n",
      "[149]\tvalidation_0-logloss:0.43713\n",
      "[150]\tvalidation_0-logloss:0.43664\n",
      "[151]\tvalidation_0-logloss:0.43636\n",
      "[152]\tvalidation_0-logloss:0.43648\n",
      "[153]\tvalidation_0-logloss:0.43615\n",
      "[154]\tvalidation_0-logloss:0.43628\n",
      "[155]\tvalidation_0-logloss:0.43584\n",
      "[156]\tvalidation_0-logloss:0.43523\n",
      "[157]\tvalidation_0-logloss:0.43454\n",
      "[158]\tvalidation_0-logloss:0.43407\n",
      "[159]\tvalidation_0-logloss:0.43403\n",
      "[160]\tvalidation_0-logloss:0.43381\n",
      "[161]\tvalidation_0-logloss:0.43288\n",
      "[162]\tvalidation_0-logloss:0.43237\n",
      "[163]\tvalidation_0-logloss:0.43178\n",
      "[164]\tvalidation_0-logloss:0.43164\n",
      "[165]\tvalidation_0-logloss:0.43133\n",
      "[166]\tvalidation_0-logloss:0.43108\n",
      "[167]\tvalidation_0-logloss:0.43099\n",
      "[168]\tvalidation_0-logloss:0.43025\n",
      "[169]\tvalidation_0-logloss:0.42989\n",
      "[170]\tvalidation_0-logloss:0.42956\n",
      "[171]\tvalidation_0-logloss:0.42950\n",
      "[172]\tvalidation_0-logloss:0.42969\n",
      "[173]\tvalidation_0-logloss:0.42939\n",
      "[174]\tvalidation_0-logloss:0.42964\n",
      "[175]\tvalidation_0-logloss:0.42936\n",
      "[176]\tvalidation_0-logloss:0.42908\n",
      "[177]\tvalidation_0-logloss:0.42892\n",
      "[178]\tvalidation_0-logloss:0.42848\n",
      "[179]\tvalidation_0-logloss:0.42833\n",
      "[180]\tvalidation_0-logloss:0.42812\n",
      "[181]\tvalidation_0-logloss:0.42835\n",
      "[182]\tvalidation_0-logloss:0.42820\n",
      "[183]\tvalidation_0-logloss:0.42789\n",
      "[184]\tvalidation_0-logloss:0.42783\n",
      "[185]\tvalidation_0-logloss:0.42716\n",
      "[186]\tvalidation_0-logloss:0.42672\n",
      "[187]\tvalidation_0-logloss:0.42659\n",
      "[188]\tvalidation_0-logloss:0.42673\n",
      "[189]\tvalidation_0-logloss:0.42671\n",
      "[190]\tvalidation_0-logloss:0.42627\n",
      "[191]\tvalidation_0-logloss:0.42611\n",
      "[192]\tvalidation_0-logloss:0.42630\n",
      "[193]\tvalidation_0-logloss:0.42554\n",
      "[194]\tvalidation_0-logloss:0.42529\n",
      "[195]\tvalidation_0-logloss:0.42505\n",
      "[196]\tvalidation_0-logloss:0.42459\n",
      "[197]\tvalidation_0-logloss:0.42477\n",
      "[198]\tvalidation_0-logloss:0.42507\n",
      "[199]\tvalidation_0-logloss:0.42486\n",
      "[200]\tvalidation_0-logloss:0.42500\n",
      "[201]\tvalidation_0-logloss:0.42500\n",
      "[202]\tvalidation_0-logloss:0.42490\n",
      "[203]\tvalidation_0-logloss:0.42455\n",
      "[204]\tvalidation_0-logloss:0.42433\n",
      "[205]\tvalidation_0-logloss:0.42425\n",
      "[206]\tvalidation_0-logloss:0.42430\n",
      "[207]\tvalidation_0-logloss:0.42408\n",
      "[208]\tvalidation_0-logloss:0.42417\n",
      "[209]\tvalidation_0-logloss:0.42434\n",
      "[210]\tvalidation_0-logloss:0.42429\n",
      "[211]\tvalidation_0-logloss:0.42421\n",
      "[212]\tvalidation_0-logloss:0.42441\n",
      "[213]\tvalidation_0-logloss:0.42415\n",
      "[214]\tvalidation_0-logloss:0.42386\n",
      "[215]\tvalidation_0-logloss:0.42400\n",
      "[216]\tvalidation_0-logloss:0.42357\n",
      "[217]\tvalidation_0-logloss:0.42317\n",
      "[218]\tvalidation_0-logloss:0.42315\n",
      "[219]\tvalidation_0-logloss:0.42324\n",
      "[220]\tvalidation_0-logloss:0.42331\n",
      "[221]\tvalidation_0-logloss:0.42317\n",
      "[222]\tvalidation_0-logloss:0.42282\n",
      "[223]\tvalidation_0-logloss:0.42295\n",
      "[224]\tvalidation_0-logloss:0.42320\n",
      "[225]\tvalidation_0-logloss:0.42325\n",
      "[226]\tvalidation_0-logloss:0.42307\n",
      "[227]\tvalidation_0-logloss:0.42297\n",
      "[228]\tvalidation_0-logloss:0.42262\n",
      "[229]\tvalidation_0-logloss:0.42254\n",
      "[230]\tvalidation_0-logloss:0.42253\n",
      "[231]\tvalidation_0-logloss:0.42237\n",
      "[232]\tvalidation_0-logloss:0.42260\n",
      "[233]\tvalidation_0-logloss:0.42246\n",
      "[234]\tvalidation_0-logloss:0.42240\n",
      "[235]\tvalidation_0-logloss:0.42267\n",
      "[236]\tvalidation_0-logloss:0.42263\n",
      "[237]\tvalidation_0-logloss:0.42278\n",
      "[238]\tvalidation_0-logloss:0.42303\n",
      "[239]\tvalidation_0-logloss:0.42333\n",
      "[240]\tvalidation_0-logloss:0.42330\n",
      "[241]\tvalidation_0-logloss:0.42323\n",
      "[242]\tvalidation_0-logloss:0.42306\n",
      "[243]\tvalidation_0-logloss:0.42283\n",
      "[244]\tvalidation_0-logloss:0.42267\n",
      "[245]\tvalidation_0-logloss:0.42227\n",
      "[246]\tvalidation_0-logloss:0.42181\n",
      "[247]\tvalidation_0-logloss:0.42191\n",
      "[248]\tvalidation_0-logloss:0.42186\n",
      "[249]\tvalidation_0-logloss:0.42196\n",
      "[250]\tvalidation_0-logloss:0.42207\n",
      "[251]\tvalidation_0-logloss:0.42210\n",
      "[252]\tvalidation_0-logloss:0.42215\n",
      "[253]\tvalidation_0-logloss:0.42176\n",
      "[254]\tvalidation_0-logloss:0.42212\n",
      "[255]\tvalidation_0-logloss:0.42225\n",
      "[256]\tvalidation_0-logloss:0.42240\n",
      "[257]\tvalidation_0-logloss:0.42257\n",
      "[258]\tvalidation_0-logloss:0.42230\n",
      "[259]\tvalidation_0-logloss:0.42222\n",
      "[260]\tvalidation_0-logloss:0.42260\n",
      "[261]\tvalidation_0-logloss:0.42272\n",
      "[262]\tvalidation_0-logloss:0.42290\n",
      "[263]\tvalidation_0-logloss:0.42347\n",
      "[264]\tvalidation_0-logloss:0.42383\n",
      "[265]\tvalidation_0-logloss:0.42375\n",
      "[266]\tvalidation_0-logloss:0.42346\n",
      "[267]\tvalidation_0-logloss:0.42343\n",
      "[268]\tvalidation_0-logloss:0.42325\n",
      "[269]\tvalidation_0-logloss:0.42342\n",
      "[270]\tvalidation_0-logloss:0.42306\n",
      "[271]\tvalidation_0-logloss:0.42273\n",
      "[272]\tvalidation_0-logloss:0.42271\n",
      "[273]\tvalidation_0-logloss:0.42281\n",
      "[274]\tvalidation_0-logloss:0.42275\n",
      "[275]\tvalidation_0-logloss:0.42311\n",
      "[276]\tvalidation_0-logloss:0.42352\n",
      "[277]\tvalidation_0-logloss:0.42378\n",
      "[278]\tvalidation_0-logloss:0.42407\n",
      "[279]\tvalidation_0-logloss:0.42395\n",
      "[280]\tvalidation_0-logloss:0.42388\n",
      "[281]\tvalidation_0-logloss:0.42376\n",
      "[282]\tvalidation_0-logloss:0.42373\n",
      "[283]\tvalidation_0-logloss:0.42355\n",
      "[284]\tvalidation_0-logloss:0.42399\n",
      "[285]\tvalidation_0-logloss:0.42419\n",
      "[286]\tvalidation_0-logloss:0.42410\n",
      "[287]\tvalidation_0-logloss:0.42471\n",
      "[288]\tvalidation_0-logloss:0.42455\n",
      "[289]\tvalidation_0-logloss:0.42438\n",
      "[290]\tvalidation_0-logloss:0.42464\n",
      "[291]\tvalidation_0-logloss:0.42498\n",
      "[292]\tvalidation_0-logloss:0.42509\n",
      "[293]\tvalidation_0-logloss:0.42494\n",
      "[294]\tvalidation_0-logloss:0.42479\n",
      "[295]\tvalidation_0-logloss:0.42468\n",
      "[296]\tvalidation_0-logloss:0.42454\n",
      "[297]\tvalidation_0-logloss:0.42453\n",
      "[298]\tvalidation_0-logloss:0.42423\n",
      "[299]\tvalidation_0-logloss:0.42423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "# best_pretrain_params = grid_search.best_params_\n",
    "\n",
    "for param, value in best_pretrain_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create and train fresh model\n",
    "xgb_pretrain = xgb.XGBClassifier(\n",
    "    **best_pretrain_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_pretrain.fit(\n",
    "    X_pretrain_train_res,\n",
    "    y_pretrain_train_res,\n",
    "    eval_set=[(X_pretrain_val, y_pretrain_val)],\n",
    "    verbose=1  # Show progress every 100 trees\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0502320a-0a6e-4474-9a85-d5ba30124a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Test Accuracy on Source domain: 80.65%\n",
      "Pretraining Test F1 on Source domain: 85.00%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 91.89%\n",
      "Pretraining Test Specificity on Source domain: 64.00%\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED MODEL EVALUATION ON A-TEST\n",
    "Dataset_A_Pretrain = xgb_pretrain.predict(X_pretrain_test)\n",
    "\n",
    "#Calculate and print metrics on source domain's test set\n",
    "Dataset_A_Pretrain_acc = accuracy_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "Dataset_A_Pretrain_f1  = f1_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "\n",
    "cm_A = confusion_matrix(y_pretrain_test, Dataset_A_Pretrain)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A.ravel()\n",
    "\n",
    "\n",
    "recall_A = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A = TN_A / (TN_A + FP_A) * 100\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {Dataset_A_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {Dataset_A_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_A:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_A:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6f04989-11e6-4193-a3b7-c9861654f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Accuracy on target domain's test Set: 70.97%\n",
      "Pretraining F1 on target domain's test Set: 70.97%\n",
      "Pretraining Recall (Sensitivity) on target domain's test Set: 78.57%\n",
      "Pretraining Specificity on target domain's test Set: 64.71%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain = xgb_pretrain.predict(X_finetune_test)\n",
    "\n",
    "#Calculate and print metrics on target domain's test set\n",
    "Dataset_B_Pretrain_acc = accuracy_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "Dataset_B_Pretrain_f1 = f1_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "cm_B = confusion_matrix(y_finetune_test, Dataset_B_Pretrain)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B.ravel()\n",
    "recall_B = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pretraining Accuracy on target domain's test Set: {Dataset_B_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining F1 on target domain's test Set: {Dataset_B_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Recall (Sensitivity) on target domain's test Set: {recall_B:.2f}%\")\n",
    "print(f\"Pretraining Specificity on target domain's test Set: {specificity_B:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdaffd-5589-4825-a70c-53c2d7f5562f",
   "metadata": {},
   "source": [
    "### Finetuning on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bddce10f-fb66-44ac-8ecf-754a03f87809",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_finetune_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.009,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 1.5, \n",
    "    'subsample': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc73f4df-52f0-45e6-b742-9ada28c944aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.009\n",
      "  max_depth: 6\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 1.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.22764\n",
      "[1]\tvalidation_0-logloss:0.22634\n",
      "[2]\tvalidation_0-logloss:0.22628\n",
      "[3]\tvalidation_0-logloss:0.22595\n",
      "[4]\tvalidation_0-logloss:0.22495\n",
      "[5]\tvalidation_0-logloss:0.22421\n",
      "[6]\tvalidation_0-logloss:0.22345\n",
      "[7]\tvalidation_0-logloss:0.22341\n",
      "[8]\tvalidation_0-logloss:0.22315\n",
      "[9]\tvalidation_0-logloss:0.22315\n",
      "[10]\tvalidation_0-logloss:0.22257\n",
      "[11]\tvalidation_0-logloss:0.22214\n",
      "[12]\tvalidation_0-logloss:0.22122\n",
      "[13]\tvalidation_0-logloss:0.22029\n",
      "[14]\tvalidation_0-logloss:0.22033\n",
      "[15]\tvalidation_0-logloss:0.22006\n",
      "[16]\tvalidation_0-logloss:0.21944\n",
      "[17]\tvalidation_0-logloss:0.21898\n",
      "[18]\tvalidation_0-logloss:0.21880\n",
      "[19]\tvalidation_0-logloss:0.21869\n",
      "[20]\tvalidation_0-logloss:0.21826\n",
      "[21]\tvalidation_0-logloss:0.21740\n",
      "[22]\tvalidation_0-logloss:0.21649\n",
      "[23]\tvalidation_0-logloss:0.21597\n",
      "[24]\tvalidation_0-logloss:0.21545\n",
      "[25]\tvalidation_0-logloss:0.21481\n",
      "[26]\tvalidation_0-logloss:0.21475\n",
      "[27]\tvalidation_0-logloss:0.21425\n",
      "[28]\tvalidation_0-logloss:0.21365\n",
      "[29]\tvalidation_0-logloss:0.21314\n",
      "[30]\tvalidation_0-logloss:0.21259\n",
      "[31]\tvalidation_0-logloss:0.21201\n",
      "[32]\tvalidation_0-logloss:0.21121\n",
      "[33]\tvalidation_0-logloss:0.21054\n",
      "[34]\tvalidation_0-logloss:0.21017\n",
      "[35]\tvalidation_0-logloss:0.21022\n",
      "[36]\tvalidation_0-logloss:0.21011\n",
      "[37]\tvalidation_0-logloss:0.20995\n",
      "[38]\tvalidation_0-logloss:0.20967\n",
      "[39]\tvalidation_0-logloss:0.20951\n",
      "[40]\tvalidation_0-logloss:0.20923\n",
      "[41]\tvalidation_0-logloss:0.20890\n",
      "[42]\tvalidation_0-logloss:0.20825\n",
      "[43]\tvalidation_0-logloss:0.20793\n",
      "[44]\tvalidation_0-logloss:0.20694\n",
      "[45]\tvalidation_0-logloss:0.20613\n",
      "[46]\tvalidation_0-logloss:0.20567\n",
      "[47]\tvalidation_0-logloss:0.20536\n",
      "[48]\tvalidation_0-logloss:0.20506\n",
      "[49]\tvalidation_0-logloss:0.20407\n",
      "[50]\tvalidation_0-logloss:0.20353\n",
      "[51]\tvalidation_0-logloss:0.20298\n",
      "[52]\tvalidation_0-logloss:0.20274\n",
      "[53]\tvalidation_0-logloss:0.20249\n",
      "[54]\tvalidation_0-logloss:0.20201\n",
      "[55]\tvalidation_0-logloss:0.20179\n",
      "[56]\tvalidation_0-logloss:0.20166\n",
      "[57]\tvalidation_0-logloss:0.20113\n",
      "[58]\tvalidation_0-logloss:0.20106\n",
      "[59]\tvalidation_0-logloss:0.20087\n",
      "[60]\tvalidation_0-logloss:0.20065\n",
      "[61]\tvalidation_0-logloss:0.20059\n",
      "[62]\tvalidation_0-logloss:0.20035\n",
      "[63]\tvalidation_0-logloss:0.19993\n",
      "[64]\tvalidation_0-logloss:0.19968\n",
      "[65]\tvalidation_0-logloss:0.19954\n",
      "[66]\tvalidation_0-logloss:0.19895\n",
      "[67]\tvalidation_0-logloss:0.19891\n",
      "[68]\tvalidation_0-logloss:0.19872\n",
      "[69]\tvalidation_0-logloss:0.19852\n",
      "[70]\tvalidation_0-logloss:0.19801\n",
      "[71]\tvalidation_0-logloss:0.19713\n",
      "[72]\tvalidation_0-logloss:0.19678\n",
      "[73]\tvalidation_0-logloss:0.19669\n",
      "[74]\tvalidation_0-logloss:0.19631\n",
      "[75]\tvalidation_0-logloss:0.19596\n",
      "[76]\tvalidation_0-logloss:0.19553\n",
      "[77]\tvalidation_0-logloss:0.19525\n",
      "[78]\tvalidation_0-logloss:0.19493\n",
      "[79]\tvalidation_0-logloss:0.19460\n",
      "[80]\tvalidation_0-logloss:0.19465\n",
      "[81]\tvalidation_0-logloss:0.19400\n",
      "[82]\tvalidation_0-logloss:0.19394\n",
      "[83]\tvalidation_0-logloss:0.19351\n",
      "[84]\tvalidation_0-logloss:0.19262\n",
      "[85]\tvalidation_0-logloss:0.19246\n",
      "[86]\tvalidation_0-logloss:0.19217\n",
      "[87]\tvalidation_0-logloss:0.19203\n",
      "[88]\tvalidation_0-logloss:0.19192\n",
      "[89]\tvalidation_0-logloss:0.19191\n",
      "[90]\tvalidation_0-logloss:0.19174\n",
      "[91]\tvalidation_0-logloss:0.19169\n",
      "[92]\tvalidation_0-logloss:0.19126\n",
      "[93]\tvalidation_0-logloss:0.19105\n",
      "[94]\tvalidation_0-logloss:0.19119\n",
      "[95]\tvalidation_0-logloss:0.19120\n",
      "[96]\tvalidation_0-logloss:0.19073\n",
      "[97]\tvalidation_0-logloss:0.19056\n",
      "[98]\tvalidation_0-logloss:0.19040\n",
      "[99]\tvalidation_0-logloss:0.18990\n",
      "[100]\tvalidation_0-logloss:0.18978\n",
      "[101]\tvalidation_0-logloss:0.18930\n",
      "[102]\tvalidation_0-logloss:0.18939\n",
      "[103]\tvalidation_0-logloss:0.18945\n",
      "[104]\tvalidation_0-logloss:0.18932\n",
      "[105]\tvalidation_0-logloss:0.18889\n",
      "[106]\tvalidation_0-logloss:0.18853\n",
      "[107]\tvalidation_0-logloss:0.18836\n",
      "[108]\tvalidation_0-logloss:0.18820\n",
      "[109]\tvalidation_0-logloss:0.18802\n",
      "[110]\tvalidation_0-logloss:0.18815\n",
      "[111]\tvalidation_0-logloss:0.18757\n",
      "[112]\tvalidation_0-logloss:0.18730\n",
      "[113]\tvalidation_0-logloss:0.18702\n",
      "[114]\tvalidation_0-logloss:0.18683\n",
      "[115]\tvalidation_0-logloss:0.18669\n",
      "[116]\tvalidation_0-logloss:0.18631\n",
      "[117]\tvalidation_0-logloss:0.18591\n",
      "[118]\tvalidation_0-logloss:0.18518\n",
      "[119]\tvalidation_0-logloss:0.18506\n",
      "[120]\tvalidation_0-logloss:0.18463\n",
      "[121]\tvalidation_0-logloss:0.18449\n",
      "[122]\tvalidation_0-logloss:0.18456\n",
      "[123]\tvalidation_0-logloss:0.18410\n",
      "[124]\tvalidation_0-logloss:0.18412\n",
      "[125]\tvalidation_0-logloss:0.18396\n",
      "[126]\tvalidation_0-logloss:0.18360\n",
      "[127]\tvalidation_0-logloss:0.18368\n",
      "[128]\tvalidation_0-logloss:0.18353\n",
      "[129]\tvalidation_0-logloss:0.18369\n",
      "[130]\tvalidation_0-logloss:0.18333\n",
      "[131]\tvalidation_0-logloss:0.18318\n",
      "[132]\tvalidation_0-logloss:0.18296\n",
      "[133]\tvalidation_0-logloss:0.18290\n",
      "[134]\tvalidation_0-logloss:0.18262\n",
      "[135]\tvalidation_0-logloss:0.18241\n",
      "[136]\tvalidation_0-logloss:0.18254\n",
      "[137]\tvalidation_0-logloss:0.18196\n",
      "[138]\tvalidation_0-logloss:0.18204\n",
      "[139]\tvalidation_0-logloss:0.18212\n",
      "[140]\tvalidation_0-logloss:0.18154\n",
      "[141]\tvalidation_0-logloss:0.18128\n",
      "[142]\tvalidation_0-logloss:0.18104\n",
      "[143]\tvalidation_0-logloss:0.18104\n",
      "[144]\tvalidation_0-logloss:0.18052\n",
      "[145]\tvalidation_0-logloss:0.18036\n",
      "[146]\tvalidation_0-logloss:0.18004\n",
      "[147]\tvalidation_0-logloss:0.17997\n",
      "[148]\tvalidation_0-logloss:0.17963\n",
      "[149]\tvalidation_0-logloss:0.17937\n",
      "[150]\tvalidation_0-logloss:0.17917\n",
      "[151]\tvalidation_0-logloss:0.17944\n",
      "[152]\tvalidation_0-logloss:0.17889\n",
      "[153]\tvalidation_0-logloss:0.17855\n",
      "[154]\tvalidation_0-logloss:0.17823\n",
      "[155]\tvalidation_0-logloss:0.17792\n",
      "[156]\tvalidation_0-logloss:0.17809\n",
      "[157]\tvalidation_0-logloss:0.17772\n",
      "[158]\tvalidation_0-logloss:0.17736\n",
      "[159]\tvalidation_0-logloss:0.17721\n",
      "[160]\tvalidation_0-logloss:0.17736\n",
      "[161]\tvalidation_0-logloss:0.17755\n",
      "[162]\tvalidation_0-logloss:0.17755\n",
      "[163]\tvalidation_0-logloss:0.17726\n",
      "[164]\tvalidation_0-logloss:0.17701\n",
      "[165]\tvalidation_0-logloss:0.17650\n",
      "[166]\tvalidation_0-logloss:0.17605\n",
      "[167]\tvalidation_0-logloss:0.17596\n",
      "[168]\tvalidation_0-logloss:0.17544\n",
      "[169]\tvalidation_0-logloss:0.17513\n",
      "[170]\tvalidation_0-logloss:0.17490\n",
      "[171]\tvalidation_0-logloss:0.17462\n",
      "[172]\tvalidation_0-logloss:0.17460\n",
      "[173]\tvalidation_0-logloss:0.17454\n",
      "[174]\tvalidation_0-logloss:0.17425\n",
      "[175]\tvalidation_0-logloss:0.17402\n",
      "[176]\tvalidation_0-logloss:0.17394\n",
      "[177]\tvalidation_0-logloss:0.17363\n",
      "[178]\tvalidation_0-logloss:0.17316\n",
      "[179]\tvalidation_0-logloss:0.17331\n",
      "[180]\tvalidation_0-logloss:0.17302\n",
      "[181]\tvalidation_0-logloss:0.17266\n",
      "[182]\tvalidation_0-logloss:0.17226\n",
      "[183]\tvalidation_0-logloss:0.17214\n",
      "[184]\tvalidation_0-logloss:0.17210\n",
      "[185]\tvalidation_0-logloss:0.17171\n",
      "[186]\tvalidation_0-logloss:0.17188\n",
      "[187]\tvalidation_0-logloss:0.17184\n",
      "[188]\tvalidation_0-logloss:0.17180\n",
      "[189]\tvalidation_0-logloss:0.17187\n",
      "[190]\tvalidation_0-logloss:0.17202\n",
      "[191]\tvalidation_0-logloss:0.17205\n",
      "[192]\tvalidation_0-logloss:0.17184\n",
      "[193]\tvalidation_0-logloss:0.17151\n",
      "[194]\tvalidation_0-logloss:0.17153\n",
      "[195]\tvalidation_0-logloss:0.17163\n",
      "[196]\tvalidation_0-logloss:0.17141\n",
      "[197]\tvalidation_0-logloss:0.17129\n",
      "[198]\tvalidation_0-logloss:0.17137\n",
      "[199]\tvalidation_0-logloss:0.17123\n",
      "[200]\tvalidation_0-logloss:0.17121\n",
      "[201]\tvalidation_0-logloss:0.17104\n",
      "[202]\tvalidation_0-logloss:0.17103\n",
      "[203]\tvalidation_0-logloss:0.17084\n",
      "[204]\tvalidation_0-logloss:0.17076\n",
      "[205]\tvalidation_0-logloss:0.17073\n",
      "[206]\tvalidation_0-logloss:0.17050\n",
      "[207]\tvalidation_0-logloss:0.17055\n",
      "[208]\tvalidation_0-logloss:0.17054\n",
      "[209]\tvalidation_0-logloss:0.17037\n",
      "[210]\tvalidation_0-logloss:0.17013\n",
      "[211]\tvalidation_0-logloss:0.16985\n",
      "[212]\tvalidation_0-logloss:0.16959\n",
      "[213]\tvalidation_0-logloss:0.16943\n",
      "[214]\tvalidation_0-logloss:0.16925\n",
      "[215]\tvalidation_0-logloss:0.16920\n",
      "[216]\tvalidation_0-logloss:0.16903\n",
      "[217]\tvalidation_0-logloss:0.16878\n",
      "[218]\tvalidation_0-logloss:0.16867\n",
      "[219]\tvalidation_0-logloss:0.16855\n",
      "[220]\tvalidation_0-logloss:0.16865\n",
      "[221]\tvalidation_0-logloss:0.16847\n",
      "[222]\tvalidation_0-logloss:0.16856\n",
      "[223]\tvalidation_0-logloss:0.16861\n",
      "[224]\tvalidation_0-logloss:0.16836\n",
      "[225]\tvalidation_0-logloss:0.16816\n",
      "[226]\tvalidation_0-logloss:0.16787\n",
      "[227]\tvalidation_0-logloss:0.16787\n",
      "[228]\tvalidation_0-logloss:0.16777\n",
      "[229]\tvalidation_0-logloss:0.16765\n",
      "[230]\tvalidation_0-logloss:0.16752\n",
      "[231]\tvalidation_0-logloss:0.16752\n",
      "[232]\tvalidation_0-logloss:0.16743\n",
      "[233]\tvalidation_0-logloss:0.16744\n",
      "[234]\tvalidation_0-logloss:0.16733\n",
      "[235]\tvalidation_0-logloss:0.16723\n",
      "[236]\tvalidation_0-logloss:0.16740\n",
      "[237]\tvalidation_0-logloss:0.16704\n",
      "[238]\tvalidation_0-logloss:0.16694\n",
      "[239]\tvalidation_0-logloss:0.16672\n",
      "[240]\tvalidation_0-logloss:0.16663\n",
      "[241]\tvalidation_0-logloss:0.16648\n",
      "[242]\tvalidation_0-logloss:0.16628\n",
      "[243]\tvalidation_0-logloss:0.16623\n",
      "[244]\tvalidation_0-logloss:0.16576\n",
      "[245]\tvalidation_0-logloss:0.16550\n",
      "[246]\tvalidation_0-logloss:0.16564\n",
      "[247]\tvalidation_0-logloss:0.16543\n",
      "[248]\tvalidation_0-logloss:0.16542\n",
      "[249]\tvalidation_0-logloss:0.16530\n",
      "[250]\tvalidation_0-logloss:0.16541\n",
      "[251]\tvalidation_0-logloss:0.16523\n",
      "[252]\tvalidation_0-logloss:0.16496\n",
      "[253]\tvalidation_0-logloss:0.16495\n",
      "[254]\tvalidation_0-logloss:0.16474\n",
      "[255]\tvalidation_0-logloss:0.16441\n",
      "[256]\tvalidation_0-logloss:0.16430\n",
      "[257]\tvalidation_0-logloss:0.16432\n",
      "[258]\tvalidation_0-logloss:0.16414\n",
      "[259]\tvalidation_0-logloss:0.16404\n",
      "[260]\tvalidation_0-logloss:0.16403\n",
      "[261]\tvalidation_0-logloss:0.16395\n",
      "[262]\tvalidation_0-logloss:0.16376\n",
      "[263]\tvalidation_0-logloss:0.16349\n",
      "[264]\tvalidation_0-logloss:0.16323\n",
      "[265]\tvalidation_0-logloss:0.16327\n",
      "[266]\tvalidation_0-logloss:0.16337\n",
      "[267]\tvalidation_0-logloss:0.16337\n",
      "[268]\tvalidation_0-logloss:0.16337\n",
      "[269]\tvalidation_0-logloss:0.16335\n",
      "[270]\tvalidation_0-logloss:0.16328\n",
      "[271]\tvalidation_0-logloss:0.16327\n",
      "[272]\tvalidation_0-logloss:0.16318\n",
      "[273]\tvalidation_0-logloss:0.16307\n",
      "[274]\tvalidation_0-logloss:0.16307\n",
      "[275]\tvalidation_0-logloss:0.16302\n",
      "[276]\tvalidation_0-logloss:0.16274\n",
      "[277]\tvalidation_0-logloss:0.16264\n",
      "[278]\tvalidation_0-logloss:0.16240\n",
      "[279]\tvalidation_0-logloss:0.16247\n",
      "[280]\tvalidation_0-logloss:0.16222\n",
      "[281]\tvalidation_0-logloss:0.16213\n",
      "[282]\tvalidation_0-logloss:0.16191\n",
      "[283]\tvalidation_0-logloss:0.16170\n",
      "[284]\tvalidation_0-logloss:0.16170\n",
      "[285]\tvalidation_0-logloss:0.16146\n",
      "[286]\tvalidation_0-logloss:0.16136\n",
      "[287]\tvalidation_0-logloss:0.16122\n",
      "[288]\tvalidation_0-logloss:0.16094\n",
      "[289]\tvalidation_0-logloss:0.16077\n",
      "[290]\tvalidation_0-logloss:0.16078\n",
      "[291]\tvalidation_0-logloss:0.16059\n",
      "[292]\tvalidation_0-logloss:0.16037\n",
      "[293]\tvalidation_0-logloss:0.16027\n",
      "[294]\tvalidation_0-logloss:0.16030\n",
      "[295]\tvalidation_0-logloss:0.15996\n",
      "[296]\tvalidation_0-logloss:0.15964\n",
      "[297]\tvalidation_0-logloss:0.15964\n",
      "[298]\tvalidation_0-logloss:0.15955\n",
      "[299]\tvalidation_0-logloss:0.15941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters from fine-tuning grid search\n",
    "# best_finetune_params = grid_search_finetune.best_params_\n",
    "\n",
    "for param, value in best_finetune_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "xgb_finetune = xgb.XGBClassifier(\n",
    "    **best_finetune_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_finetune.fit(\n",
    "    X_finetune_train_res,\n",
    "    y_finetune_train_res, \n",
    "    eval_set=[(X_finetune_val, y_finetune_val)], \n",
    "    xgb_model=xgb_pretrain.get_booster(),\n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b386de1-f1cb-4ba2-ad3c-dd10c4138c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test Accuracy on Source domain: 80.65%\n",
      "Fine-Tuning Test F1 on Source domain: 85.37%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Source domain: 94.59%\n",
      "Fine-Tuning Test Specificity on Source domain: 60.00%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON A-TEST (Checking for Catastrophic Forgetting)\n",
    "Dataset_A_Finetune = xgb_finetune.predict(X_pretrain_test) # Using the fine-tuned model on A's test set\n",
    "\n",
    "# Calculate and print metrics on source domain's test set\n",
    "acc_A_Finetune = accuracy_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "f1_A_Finetune = f1_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "\n",
    "cm_A_Finetune = confusion_matrix(y_pretrain_test, Dataset_A_Finetune)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune.ravel()\n",
    "\n",
    "recall_A_Finetune = TP_A_F / (TP_A_F + FN_A_F) * 100\n",
    "specificity_A_Finetune = TN_A_F / (TN_A_F + FP_A_F) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test Accuracy on Source domain: {acc_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Source domain: {f1_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Source domain: {recall_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Source domain: {specificity_A_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afac6e80-0424-49c3-abc1-27ce75b57a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test ROC-AUC on Target domain (B): 81.72%\n",
      "Fine-Tuning Test Accuracy on Target domain (B): 80.65%\n",
      "Fine-Tuning Test F1 on Target domain (B): 81.25%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Target domain (B): 92.86%\n",
      "Fine-Tuning Test Specificity on Target domain (B): 70.59%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON B-TEST (Final Transfer Learning Performance)\n",
    "Dataset_B_Finetune = xgb_finetune.predict(X_finetune_test) # Using the fine-tuned model on B's test set\n",
    "\n",
    "# Calculate and print metrics on target domain's test set\n",
    "acc_B_Finetune = accuracy_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1_B_Finetune = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "cm_B_Finetune = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "TN_B_F, FP_B_F, FN_B_F, TP_B_F = cm_B_Finetune.ravel()\n",
    "\n",
    "recall_B_Finetune = TP_B_F / (TP_B_F + FN_B_F) * 100\n",
    "specificity_B_Finetune = TN_B_F / (TN_B_F + FP_B_F) * 100\n",
    "roc_auc_B_Finetune = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test ROC-AUC on Target domain (B): {roc_auc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Accuracy on Target domain (B): {acc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Target domain (B): {f1_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Target domain (B): {recall_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Target domain (B): {specificity_B_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66408ef9-e5a5-41ea-9707-7417a382bb75",
   "metadata": {},
   "source": [
    "#### SHAP figure from the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f9d46-d7cd-4c36-acf5-464f9c42e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# Create SHAP explainer for XGBoost model\n",
    "explainer = shap.TreeExplainer(xgb_finetune)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_finetune_test)\n",
    "\n",
    "# Create a larger figure\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Generate summary plot with custom settings, no caption\n",
    "shap.summary_plot(shap_values, X_finetune_test, \n",
    "                  max_display=20,  # Show top 20 features\n",
    "                  show=False)\n",
    "\n",
    "# Customize the plot\n",
    "plt.gcf().axes[-1].set_aspect(100)\n",
    "plt.gcf().axes[-1].set_box_aspect(100)\n",
    "\n",
    "# Save the plot as an image with high resolution and no caption\n",
    "plt.savefig('shap_summary_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2010a-5856-4e2c-962f-158e8df937bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Confusion matrix and ROC-AUC curve for the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba10ea4-ab9b-4d57-914a-c4f843778d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "# plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Assuming y_finetune_test and Dataset_B_Finetune are already defined\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.invert_yaxis()  # You can uncomment this if you want to invert the Y-axis\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        # Set the text in Times New Roman\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c790849-940f-44e0-b416-6e65f4e90ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "recall = recall_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1 = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate') # Changed back to match the image axis label\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a481e-9936-409b-972e-3021ab1952b7",
   "metadata": {},
   "source": [
    "### XGBoost with no Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44636e68-a03d-4dca-ae99-4163c450919b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.69271\n",
      "[1]\tvalidation_0-logloss:0.69228\n",
      "[2]\tvalidation_0-logloss:0.69180\n",
      "[3]\tvalidation_0-logloss:0.69139\n",
      "[4]\tvalidation_0-logloss:0.69091\n",
      "[5]\tvalidation_0-logloss:0.69049\n",
      "[6]\tvalidation_0-logloss:0.69009\n",
      "[7]\tvalidation_0-logloss:0.68963\n",
      "[8]\tvalidation_0-logloss:0.68915\n",
      "[9]\tvalidation_0-logloss:0.68876\n",
      "[10]\tvalidation_0-logloss:0.68833\n",
      "[11]\tvalidation_0-logloss:0.68782\n",
      "[12]\tvalidation_0-logloss:0.68733\n",
      "[13]\tvalidation_0-logloss:0.68685\n",
      "[14]\tvalidation_0-logloss:0.68639\n",
      "[15]\tvalidation_0-logloss:0.68603\n",
      "[16]\tvalidation_0-logloss:0.68556\n",
      "[17]\tvalidation_0-logloss:0.68511\n",
      "[18]\tvalidation_0-logloss:0.68474\n",
      "[19]\tvalidation_0-logloss:0.68424\n",
      "[20]\tvalidation_0-logloss:0.68380\n",
      "[21]\tvalidation_0-logloss:0.68332\n",
      "[22]\tvalidation_0-logloss:0.68282\n",
      "[23]\tvalidation_0-logloss:0.68233\n",
      "[24]\tvalidation_0-logloss:0.68185\n",
      "[25]\tvalidation_0-logloss:0.68141\n",
      "[26]\tvalidation_0-logloss:0.68100\n",
      "[27]\tvalidation_0-logloss:0.68055\n",
      "[28]\tvalidation_0-logloss:0.68015\n",
      "[29]\tvalidation_0-logloss:0.67978\n",
      "[30]\tvalidation_0-logloss:0.67933\n",
      "[31]\tvalidation_0-logloss:0.67892\n",
      "[32]\tvalidation_0-logloss:0.67854\n",
      "[33]\tvalidation_0-logloss:0.67809\n",
      "[34]\tvalidation_0-logloss:0.67774\n",
      "[35]\tvalidation_0-logloss:0.67734\n",
      "[36]\tvalidation_0-logloss:0.67691\n",
      "[37]\tvalidation_0-logloss:0.67654\n",
      "[38]\tvalidation_0-logloss:0.67605\n",
      "[39]\tvalidation_0-logloss:0.67560\n",
      "[40]\tvalidation_0-logloss:0.67515\n",
      "[41]\tvalidation_0-logloss:0.67475\n",
      "[42]\tvalidation_0-logloss:0.67437\n",
      "[43]\tvalidation_0-logloss:0.67397\n",
      "[44]\tvalidation_0-logloss:0.67350\n",
      "[45]\tvalidation_0-logloss:0.67306\n",
      "[46]\tvalidation_0-logloss:0.67273\n",
      "[47]\tvalidation_0-logloss:0.67226\n",
      "[48]\tvalidation_0-logloss:0.67183\n",
      "[49]\tvalidation_0-logloss:0.67140\n",
      "[50]\tvalidation_0-logloss:0.67095\n",
      "[51]\tvalidation_0-logloss:0.67053\n",
      "[52]\tvalidation_0-logloss:0.67009\n",
      "[53]\tvalidation_0-logloss:0.66977\n",
      "[54]\tvalidation_0-logloss:0.66935\n",
      "[55]\tvalidation_0-logloss:0.66910\n",
      "[56]\tvalidation_0-logloss:0.66866\n",
      "[57]\tvalidation_0-logloss:0.66820\n",
      "[58]\tvalidation_0-logloss:0.66778\n",
      "[59]\tvalidation_0-logloss:0.66739\n",
      "[60]\tvalidation_0-logloss:0.66698\n",
      "[61]\tvalidation_0-logloss:0.66662\n",
      "[62]\tvalidation_0-logloss:0.66619\n",
      "[63]\tvalidation_0-logloss:0.66572\n",
      "[64]\tvalidation_0-logloss:0.66538\n",
      "[65]\tvalidation_0-logloss:0.66494\n",
      "[66]\tvalidation_0-logloss:0.66452\n",
      "[67]\tvalidation_0-logloss:0.66421\n",
      "[68]\tvalidation_0-logloss:0.66380\n",
      "[69]\tvalidation_0-logloss:0.66337\n",
      "[70]\tvalidation_0-logloss:0.66295\n",
      "[71]\tvalidation_0-logloss:0.66252\n",
      "[72]\tvalidation_0-logloss:0.66213\n",
      "[73]\tvalidation_0-logloss:0.66167\n",
      "[74]\tvalidation_0-logloss:0.66136\n",
      "[75]\tvalidation_0-logloss:0.66103\n",
      "[76]\tvalidation_0-logloss:0.66071\n",
      "[77]\tvalidation_0-logloss:0.66040\n",
      "[78]\tvalidation_0-logloss:0.66000\n",
      "[79]\tvalidation_0-logloss:0.65964\n",
      "[80]\tvalidation_0-logloss:0.65930\n",
      "[81]\tvalidation_0-logloss:0.65897\n",
      "[82]\tvalidation_0-logloss:0.65852\n",
      "[83]\tvalidation_0-logloss:0.65812\n",
      "[84]\tvalidation_0-logloss:0.65767\n",
      "[85]\tvalidation_0-logloss:0.65725\n",
      "[86]\tvalidation_0-logloss:0.65686\n",
      "[87]\tvalidation_0-logloss:0.65643\n",
      "[88]\tvalidation_0-logloss:0.65598\n",
      "[89]\tvalidation_0-logloss:0.65559\n",
      "[90]\tvalidation_0-logloss:0.65514\n",
      "[91]\tvalidation_0-logloss:0.65474\n",
      "[92]\tvalidation_0-logloss:0.65438\n",
      "[93]\tvalidation_0-logloss:0.65397\n",
      "[94]\tvalidation_0-logloss:0.65352\n",
      "[95]\tvalidation_0-logloss:0.65309\n",
      "[96]\tvalidation_0-logloss:0.65264\n",
      "[97]\tvalidation_0-logloss:0.65226\n",
      "[98]\tvalidation_0-logloss:0.65196\n",
      "[99]\tvalidation_0-logloss:0.65152\n",
      "[100]\tvalidation_0-logloss:0.65112\n",
      "[101]\tvalidation_0-logloss:0.65071\n",
      "[102]\tvalidation_0-logloss:0.65036\n",
      "[103]\tvalidation_0-logloss:0.64999\n",
      "[104]\tvalidation_0-logloss:0.64961\n",
      "[105]\tvalidation_0-logloss:0.64920\n",
      "[106]\tvalidation_0-logloss:0.64878\n",
      "[107]\tvalidation_0-logloss:0.64835\n",
      "[108]\tvalidation_0-logloss:0.64797\n",
      "[109]\tvalidation_0-logloss:0.64754\n",
      "[110]\tvalidation_0-logloss:0.64710\n",
      "[111]\tvalidation_0-logloss:0.64672\n",
      "[112]\tvalidation_0-logloss:0.64630\n",
      "[113]\tvalidation_0-logloss:0.64599\n",
      "[114]\tvalidation_0-logloss:0.64567\n",
      "[115]\tvalidation_0-logloss:0.64529\n",
      "[116]\tvalidation_0-logloss:0.64499\n",
      "[117]\tvalidation_0-logloss:0.64463\n",
      "[118]\tvalidation_0-logloss:0.64420\n",
      "[119]\tvalidation_0-logloss:0.64379\n",
      "[120]\tvalidation_0-logloss:0.64339\n",
      "[121]\tvalidation_0-logloss:0.64299\n",
      "[122]\tvalidation_0-logloss:0.64262\n",
      "[123]\tvalidation_0-logloss:0.64220\n",
      "[124]\tvalidation_0-logloss:0.64180\n",
      "[125]\tvalidation_0-logloss:0.64141\n",
      "[126]\tvalidation_0-logloss:0.64097\n",
      "[127]\tvalidation_0-logloss:0.64061\n",
      "[128]\tvalidation_0-logloss:0.64027\n",
      "[129]\tvalidation_0-logloss:0.63989\n",
      "[130]\tvalidation_0-logloss:0.63951\n",
      "[131]\tvalidation_0-logloss:0.63911\n",
      "[132]\tvalidation_0-logloss:0.63884\n",
      "[133]\tvalidation_0-logloss:0.63847\n",
      "[134]\tvalidation_0-logloss:0.63818\n",
      "[135]\tvalidation_0-logloss:0.63781\n",
      "[136]\tvalidation_0-logloss:0.63743\n",
      "[137]\tvalidation_0-logloss:0.63703\n",
      "[138]\tvalidation_0-logloss:0.63664\n",
      "[139]\tvalidation_0-logloss:0.63647\n",
      "[140]\tvalidation_0-logloss:0.63609\n",
      "[141]\tvalidation_0-logloss:0.63571\n",
      "[142]\tvalidation_0-logloss:0.63538\n",
      "[143]\tvalidation_0-logloss:0.63499\n",
      "[144]\tvalidation_0-logloss:0.63459\n",
      "[145]\tvalidation_0-logloss:0.63424\n",
      "[146]\tvalidation_0-logloss:0.63381\n",
      "[147]\tvalidation_0-logloss:0.63346\n",
      "[148]\tvalidation_0-logloss:0.63310\n",
      "[149]\tvalidation_0-logloss:0.63284\n",
      "[150]\tvalidation_0-logloss:0.63246\n",
      "[151]\tvalidation_0-logloss:0.63207\n",
      "[152]\tvalidation_0-logloss:0.63178\n",
      "[153]\tvalidation_0-logloss:0.63137\n",
      "[154]\tvalidation_0-logloss:0.63100\n",
      "[155]\tvalidation_0-logloss:0.63062\n",
      "[156]\tvalidation_0-logloss:0.63031\n",
      "[157]\tvalidation_0-logloss:0.62989\n",
      "[158]\tvalidation_0-logloss:0.62956\n",
      "[159]\tvalidation_0-logloss:0.62917\n",
      "[160]\tvalidation_0-logloss:0.62883\n",
      "[161]\tvalidation_0-logloss:0.62844\n",
      "[162]\tvalidation_0-logloss:0.62806\n",
      "[163]\tvalidation_0-logloss:0.62765\n",
      "[164]\tvalidation_0-logloss:0.62732\n",
      "[165]\tvalidation_0-logloss:0.62693\n",
      "[166]\tvalidation_0-logloss:0.62660\n",
      "[167]\tvalidation_0-logloss:0.62627\n",
      "[168]\tvalidation_0-logloss:0.62597\n",
      "[169]\tvalidation_0-logloss:0.62556\n",
      "[170]\tvalidation_0-logloss:0.62519\n",
      "[171]\tvalidation_0-logloss:0.62491\n",
      "[172]\tvalidation_0-logloss:0.62454\n",
      "[173]\tvalidation_0-logloss:0.62421\n",
      "[174]\tvalidation_0-logloss:0.62383\n",
      "[175]\tvalidation_0-logloss:0.62355\n",
      "[176]\tvalidation_0-logloss:0.62328\n",
      "[177]\tvalidation_0-logloss:0.62292\n",
      "[178]\tvalidation_0-logloss:0.62257\n",
      "[179]\tvalidation_0-logloss:0.62226\n",
      "[180]\tvalidation_0-logloss:0.62190\n",
      "[181]\tvalidation_0-logloss:0.62154\n",
      "[182]\tvalidation_0-logloss:0.62127\n",
      "[183]\tvalidation_0-logloss:0.62089\n",
      "[184]\tvalidation_0-logloss:0.62058\n",
      "[185]\tvalidation_0-logloss:0.62021\n",
      "[186]\tvalidation_0-logloss:0.61995\n",
      "[187]\tvalidation_0-logloss:0.61966\n",
      "[188]\tvalidation_0-logloss:0.61940\n",
      "[189]\tvalidation_0-logloss:0.61913\n",
      "[190]\tvalidation_0-logloss:0.61883\n",
      "[191]\tvalidation_0-logloss:0.61857\n",
      "[192]\tvalidation_0-logloss:0.61830\n",
      "[193]\tvalidation_0-logloss:0.61791\n",
      "[194]\tvalidation_0-logloss:0.61754\n",
      "[195]\tvalidation_0-logloss:0.61730\n",
      "[196]\tvalidation_0-logloss:0.61696\n",
      "[197]\tvalidation_0-logloss:0.61666\n",
      "[198]\tvalidation_0-logloss:0.61640\n",
      "[199]\tvalidation_0-logloss:0.61608\n",
      "[200]\tvalidation_0-logloss:0.61582\n",
      "[201]\tvalidation_0-logloss:0.61544\n",
      "[202]\tvalidation_0-logloss:0.61511\n",
      "[203]\tvalidation_0-logloss:0.61475\n",
      "[204]\tvalidation_0-logloss:0.61436\n",
      "[205]\tvalidation_0-logloss:0.61399\n",
      "[206]\tvalidation_0-logloss:0.61368\n",
      "[207]\tvalidation_0-logloss:0.61332\n",
      "[208]\tvalidation_0-logloss:0.61310\n",
      "[209]\tvalidation_0-logloss:0.61273\n",
      "[210]\tvalidation_0-logloss:0.61237\n",
      "[211]\tvalidation_0-logloss:0.61199\n",
      "[212]\tvalidation_0-logloss:0.61169\n",
      "[213]\tvalidation_0-logloss:0.61133\n",
      "[214]\tvalidation_0-logloss:0.61106\n",
      "[215]\tvalidation_0-logloss:0.61071\n",
      "[216]\tvalidation_0-logloss:0.61045\n",
      "[217]\tvalidation_0-logloss:0.61017\n",
      "[218]\tvalidation_0-logloss:0.60983\n",
      "[219]\tvalidation_0-logloss:0.60950\n",
      "[220]\tvalidation_0-logloss:0.60921\n",
      "[221]\tvalidation_0-logloss:0.60889\n",
      "[222]\tvalidation_0-logloss:0.60871\n",
      "[223]\tvalidation_0-logloss:0.60836\n",
      "[224]\tvalidation_0-logloss:0.60799\n",
      "[225]\tvalidation_0-logloss:0.60759\n",
      "[226]\tvalidation_0-logloss:0.60723\n",
      "[227]\tvalidation_0-logloss:0.60698\n",
      "[228]\tvalidation_0-logloss:0.60668\n",
      "[229]\tvalidation_0-logloss:0.60641\n",
      "[230]\tvalidation_0-logloss:0.60605\n",
      "[231]\tvalidation_0-logloss:0.60564\n",
      "[232]\tvalidation_0-logloss:0.60530\n",
      "[233]\tvalidation_0-logloss:0.60498\n",
      "[234]\tvalidation_0-logloss:0.60461\n",
      "[235]\tvalidation_0-logloss:0.60427\n",
      "[236]\tvalidation_0-logloss:0.60394\n",
      "[237]\tvalidation_0-logloss:0.60363\n",
      "[238]\tvalidation_0-logloss:0.60338\n",
      "[239]\tvalidation_0-logloss:0.60302\n",
      "[240]\tvalidation_0-logloss:0.60270\n",
      "[241]\tvalidation_0-logloss:0.60246\n",
      "[242]\tvalidation_0-logloss:0.60221\n",
      "[243]\tvalidation_0-logloss:0.60186\n",
      "[244]\tvalidation_0-logloss:0.60154\n",
      "[245]\tvalidation_0-logloss:0.60115\n",
      "[246]\tvalidation_0-logloss:0.60079\n",
      "[247]\tvalidation_0-logloss:0.60046\n",
      "[248]\tvalidation_0-logloss:0.60008\n",
      "[249]\tvalidation_0-logloss:0.59981\n",
      "[250]\tvalidation_0-logloss:0.59950\n",
      "[251]\tvalidation_0-logloss:0.59923\n",
      "[252]\tvalidation_0-logloss:0.59892\n",
      "[253]\tvalidation_0-logloss:0.59866\n",
      "[254]\tvalidation_0-logloss:0.59845\n",
      "[255]\tvalidation_0-logloss:0.59825\n",
      "[256]\tvalidation_0-logloss:0.59783\n",
      "[257]\tvalidation_0-logloss:0.59747\n",
      "[258]\tvalidation_0-logloss:0.59715\n",
      "[259]\tvalidation_0-logloss:0.59678\n",
      "[260]\tvalidation_0-logloss:0.59648\n",
      "[261]\tvalidation_0-logloss:0.59623\n",
      "[262]\tvalidation_0-logloss:0.59589\n",
      "[263]\tvalidation_0-logloss:0.59562\n",
      "[264]\tvalidation_0-logloss:0.59528\n",
      "[265]\tvalidation_0-logloss:0.59501\n",
      "[266]\tvalidation_0-logloss:0.59469\n",
      "[267]\tvalidation_0-logloss:0.59433\n",
      "[268]\tvalidation_0-logloss:0.59408\n",
      "[269]\tvalidation_0-logloss:0.59380\n",
      "[270]\tvalidation_0-logloss:0.59345\n",
      "[271]\tvalidation_0-logloss:0.59323\n",
      "[272]\tvalidation_0-logloss:0.59289\n",
      "[273]\tvalidation_0-logloss:0.59250\n",
      "[274]\tvalidation_0-logloss:0.59216\n",
      "[275]\tvalidation_0-logloss:0.59182\n",
      "[276]\tvalidation_0-logloss:0.59158\n",
      "[277]\tvalidation_0-logloss:0.59124\n",
      "[278]\tvalidation_0-logloss:0.59093\n",
      "[279]\tvalidation_0-logloss:0.59059\n",
      "[280]\tvalidation_0-logloss:0.59028\n",
      "[281]\tvalidation_0-logloss:0.58990\n",
      "[282]\tvalidation_0-logloss:0.58956\n",
      "[283]\tvalidation_0-logloss:0.58930\n",
      "[284]\tvalidation_0-logloss:0.58903\n",
      "[285]\tvalidation_0-logloss:0.58866\n",
      "[286]\tvalidation_0-logloss:0.58840\n",
      "[287]\tvalidation_0-logloss:0.58815\n",
      "[288]\tvalidation_0-logloss:0.58775\n",
      "[289]\tvalidation_0-logloss:0.58749\n",
      "[290]\tvalidation_0-logloss:0.58719\n",
      "[291]\tvalidation_0-logloss:0.58688\n",
      "[292]\tvalidation_0-logloss:0.58657\n",
      "[293]\tvalidation_0-logloss:0.58619\n",
      "[294]\tvalidation_0-logloss:0.58591\n",
      "[295]\tvalidation_0-logloss:0.58552\n",
      "[296]\tvalidation_0-logloss:0.58522\n",
      "[297]\tvalidation_0-logloss:0.58490\n",
      "[298]\tvalidation_0-logloss:0.58456\n",
      "[299]\tvalidation_0-logloss:0.58424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = XGBClassifier(\n",
    "    # 'colsample_bytree': 0.7,\n",
    "    # 'learning_rate': 0.009,\n",
    "    # 'max_depth': 6,\n",
    "    # 'n_estimators': 300,\n",
    "    # 'reg_alpha': 0.1, \n",
    "    # 'reg_lambda': 1.5, \n",
    "    # 'subsample': 1.0\n",
    "    n_estimators=300,            \n",
    "    max_depth=10,\n",
    "    learning_rate=0.001,          # slightly higher for adaptation\n",
    "    subsample=1.0,\n",
    "    seed=42,\n",
    "    colsample_bytree=0.7,\n",
    "    eval_metric='logloss',\n",
    "    reg_lambda = 1.5,\n",
    "    reg_alpha = 0.1,\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train using only Dataset B (resampled training set)\n",
    "baseline_model.fit(\n",
    "    X_finetune_train_res,\n",
    "    y_finetune_train_res,\n",
    "    eval_set=[(X_finetune_val, y_finetune_val)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bab295b0-00fb-44d5-be89-b0a3367bbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (Dataset B): 83.87%\n",
      "Baseline F1-score (Dataset B): 82.76%\n",
      "Baseline Recall (Sensitivity): 85.71%\n",
      "Baseline Specificity: 82.35%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Dataset B test set\n",
    "y_pred_baseline = baseline_model.predict(X_finetune_test)\n",
    "\n",
    "baseline_acc = accuracy_score(y_finetune_test, y_pred_baseline) * 100\n",
    "baseline_f1  = f1_score(y_finetune_test, y_pred_baseline) * 100\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, y_pred_baseline)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "recall_score_calc = TP / (TP + FN) * 100\n",
    "specificity_score_calc = TN / (TN + FP) * 100\n",
    "\n",
    "\n",
    "print(f\"Baseline Accuracy (Dataset B): {baseline_acc:.2f}%\")\n",
    "print(f\"Baseline F1-score (Dataset B): {baseline_f1:.2f}%\")\n",
    "print(f\"Baseline Recall (Sensitivity): {recall_score_calc:.2f}%\")\n",
    "print(f\"Baseline Specificity: {specificity_score_calc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ada6c-57c4-4083-b15b-4a9f32ce3e7d",
   "metadata": {},
   "source": [
    "## 5. Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce404869-1c59-4adf-af80-11c0431b1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2baf0ab6-9b0b-462b-9157-66d45fdc5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training, validation, and test datasets for the source domain\n",
    "X_A_train = X_pretrain_train_res.values  # Features for training on the source domain (pre-training phase)\n",
    "y_A_train = y_pretrain_train_res.values  # Target labels for training on the source domain\n",
    "\n",
    "X_A_val   = X_pretrain_val.values  # Features for validation on the source domain\n",
    "y_A_val   = y_pretrain_val.values  # Target labels for validation on the source domain\n",
    "\n",
    "X_A_test  = X_pretrain_test.values  # Features for testing on the source domain\n",
    "y_A_test  = y_pretrain_test.values  # Target labels for testing on the source domain\n",
    "\n",
    "# Defining the training, validation, and test datasets for the target domain\n",
    "X_B_train = X_finetune_train_res.values  # Features for training on the target domain (fine-tuning phase)\n",
    "y_B_train = y_finetune_train_res.values  # Target labels for training on the target domain\n",
    "\n",
    "X_B_val   = X_finetune_val.values  # Features for validation on the target domain\n",
    "y_B_val   = y_finetune_val.values  # Target labels for validation on the target domain\n",
    "\n",
    "X_B_test  = X_finetune_test.values  # Features for testing on the target domain\n",
    "y_B_test  = y_finetune_test.values  # Target labels for testing on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "71aa0290-a98b-4f3c-916e-427ebc557794",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_A_train = scaler.fit_transform(X_A_train).astype(np.float32)  # Fit scaler on source train set, transform it\n",
    "X_A_val = scaler.transform(X_A_val).astype(np.float32)          # Transform source validation set\n",
    "X_A_test = scaler.transform(X_A_test).astype(np.float32)        # Transform source test set\n",
    "\n",
    "y_A_train = y_A_train.astype(np.int64)  # Convert source train labels to int64\n",
    "y_A_val = y_A_val.astype(np.int64)      # Convert source validation labels\n",
    "y_A_test = y_A_test.astype(np.int64)    # Convert source test labels\n",
    "\n",
    "X_B_train = scaler.transform(X_B_train).astype(np.float32)      # Apply source-domain scaling to target train set\n",
    "X_B_val = scaler.transform(X_B_val).astype(np.float32)          # Apply scaling to target validation set\n",
    "X_B_test = scaler.transform(X_B_test).astype(np.float32)        # Apply scaling to target test set\n",
    "\n",
    "y_B_train = y_B_train.astype(np.int64)  # Convert target train labels to int64\n",
    "y_B_val = y_B_val.astype(np.int64)      # Convert target validation labels\n",
    "y_B_test = y_B_test.astype(np.int64)    # Convert target test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79f43b5b-4246-48f2-bf12-642d16222412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_d_a: 16\n",
      "n_steps: 9\n",
      "gamma: 1.7899467948557366\n",
      "lambda_sparse: 4.387608964907318e-05\n",
      "lr: 0.003074702431245894\n",
      "momentum: 0.22\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 40\n",
      "scheduler_gamma: 0.9464940708357479\n"
     ]
    }
   ],
   "source": [
    "best_pretrain_params = {\n",
    "    \"n_d_a\": 16,\n",
    "    \"n_steps\": 9,\n",
    "    \"gamma\": 1.7899467948557366,\n",
    "    \"lambda_sparse\": 4.387608964907318e-05,\n",
    "    \"lr\": 0.003074702431245894,\n",
    "    \"momentum\": 0.22,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 40,\n",
    "    \"scheduler_gamma\": 0.9464940708357479,\n",
    "}\n",
    "for key, value in best_pretrain_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e6cf23c-94a0-4d00-b5b7-94b8f78973a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.16694 | val_logloss: 0.74158 |  0:00:02s\n",
      "epoch 1  | loss: 0.92645 | val_logloss: 0.94902 |  0:00:04s\n",
      "epoch 2  | loss: 0.79617 | val_logloss: 1.00994 |  0:00:06s\n",
      "epoch 3  | loss: 0.67142 | val_logloss: 0.98805 |  0:00:09s\n",
      "epoch 4  | loss: 0.68459 | val_logloss: 0.84035 |  0:00:11s\n",
      "epoch 5  | loss: 0.62471 | val_logloss: 0.76031 |  0:00:13s\n",
      "epoch 6  | loss: 0.6147  | val_logloss: 0.49297 |  0:00:15s\n",
      "epoch 7  | loss: 0.54348 | val_logloss: 0.51283 |  0:00:17s\n",
      "epoch 8  | loss: 0.54178 | val_logloss: 0.50558 |  0:00:19s\n",
      "epoch 9  | loss: 0.52117 | val_logloss: 0.73838 |  0:00:21s\n",
      "epoch 10 | loss: 0.49794 | val_logloss: 0.62136 |  0:00:23s\n",
      "epoch 11 | loss: 0.52632 | val_logloss: 0.49918 |  0:00:25s\n",
      "epoch 12 | loss: 0.46889 | val_logloss: 0.57853 |  0:00:27s\n",
      "epoch 13 | loss: 0.47349 | val_logloss: 0.86039 |  0:00:30s\n",
      "epoch 14 | loss: 0.49648 | val_logloss: 0.70906 |  0:00:32s\n",
      "epoch 15 | loss: 0.51096 | val_logloss: 0.581   |  0:00:34s\n",
      "epoch 16 | loss: 0.52296 | val_logloss: 0.5489  |  0:00:36s\n",
      "epoch 17 | loss: 0.49577 | val_logloss: 0.70018 |  0:00:38s\n",
      "epoch 18 | loss: 0.46142 | val_logloss: 0.79098 |  0:00:40s\n",
      "epoch 19 | loss: 0.42235 | val_logloss: 0.6718  |  0:00:42s\n",
      "epoch 20 | loss: 0.52002 | val_logloss: 0.60399 |  0:00:44s\n",
      "epoch 21 | loss: 0.44657 | val_logloss: 0.65299 |  0:00:46s\n",
      "epoch 22 | loss: 0.45459 | val_logloss: 0.69953 |  0:00:48s\n",
      "epoch 23 | loss: 0.40734 | val_logloss: 0.60959 |  0:00:51s\n",
      "epoch 24 | loss: 0.42229 | val_logloss: 0.63425 |  0:00:53s\n",
      "epoch 25 | loss: 0.43274 | val_logloss: 0.62151 |  0:00:55s\n",
      "epoch 26 | loss: 0.46974 | val_logloss: 0.6771  |  0:00:57s\n",
      "epoch 27 | loss: 0.4141  | val_logloss: 0.51405 |  0:00:59s\n",
      "epoch 28 | loss: 0.46071 | val_logloss: 0.45715 |  0:01:01s\n",
      "epoch 29 | loss: 0.39503 | val_logloss: 0.46445 |  0:01:03s\n",
      "epoch 30 | loss: 0.41293 | val_logloss: 0.42888 |  0:01:05s\n",
      "epoch 31 | loss: 0.38161 | val_logloss: 0.43092 |  0:01:08s\n",
      "epoch 32 | loss: 0.40574 | val_logloss: 0.56293 |  0:01:10s\n",
      "epoch 33 | loss: 0.35546 | val_logloss: 0.62548 |  0:01:12s\n",
      "epoch 34 | loss: 0.38934 | val_logloss: 0.56837 |  0:01:14s\n",
      "epoch 35 | loss: 0.37202 | val_logloss: 0.53414 |  0:01:17s\n",
      "epoch 36 | loss: 0.3399  | val_logloss: 0.46101 |  0:01:19s\n",
      "epoch 37 | loss: 0.36954 | val_logloss: 0.41492 |  0:01:21s\n",
      "epoch 38 | loss: 0.38318 | val_logloss: 0.4407  |  0:01:23s\n",
      "epoch 39 | loss: 0.31319 | val_logloss: 0.49207 |  0:01:25s\n",
      "epoch 40 | loss: 0.3512  | val_logloss: 0.39587 |  0:01:27s\n",
      "epoch 41 | loss: 0.38278 | val_logloss: 0.45132 |  0:01:29s\n",
      "epoch 42 | loss: 0.36813 | val_logloss: 0.52228 |  0:01:31s\n",
      "epoch 43 | loss: 0.3387  | val_logloss: 0.42637 |  0:01:33s\n",
      "epoch 44 | loss: 0.36797 | val_logloss: 0.61915 |  0:01:35s\n",
      "epoch 45 | loss: 0.32566 | val_logloss: 0.49906 |  0:01:37s\n",
      "epoch 46 | loss: 0.33947 | val_logloss: 0.40491 |  0:01:40s\n",
      "epoch 47 | loss: 0.36779 | val_logloss: 0.66652 |  0:01:42s\n",
      "epoch 48 | loss: 0.37221 | val_logloss: 0.62389 |  0:01:44s\n",
      "epoch 49 | loss: 0.37749 | val_logloss: 0.61345 |  0:01:46s\n",
      "epoch 50 | loss: 0.33816 | val_logloss: 0.5814  |  0:01:48s\n",
      "epoch 51 | loss: 0.35731 | val_logloss: 0.53971 |  0:01:49s\n",
      "epoch 52 | loss: 0.3563  | val_logloss: 0.57275 |  0:01:51s\n",
      "epoch 53 | loss: 0.33327 | val_logloss: 0.42076 |  0:01:53s\n",
      "epoch 54 | loss: 0.33221 | val_logloss: 0.42581 |  0:01:55s\n",
      "epoch 55 | loss: 0.34446 | val_logloss: 0.38221 |  0:01:56s\n",
      "epoch 56 | loss: 0.38381 | val_logloss: 0.53949 |  0:01:58s\n",
      "epoch 57 | loss: 0.38547 | val_logloss: 0.61314 |  0:02:00s\n",
      "epoch 58 | loss: 0.37499 | val_logloss: 0.49956 |  0:02:02s\n",
      "epoch 59 | loss: 0.34417 | val_logloss: 0.49237 |  0:02:04s\n",
      "epoch 60 | loss: 0.32322 | val_logloss: 0.45583 |  0:02:06s\n",
      "epoch 61 | loss: 0.34061 | val_logloss: 0.44695 |  0:02:09s\n",
      "epoch 62 | loss: 0.35655 | val_logloss: 0.47741 |  0:02:10s\n",
      "epoch 63 | loss: 0.33699 | val_logloss: 0.57475 |  0:02:12s\n",
      "epoch 64 | loss: 0.32934 | val_logloss: 0.62758 |  0:02:14s\n",
      "epoch 65 | loss: 0.30358 | val_logloss: 0.53505 |  0:02:16s\n",
      "epoch 66 | loss: 0.34596 | val_logloss: 0.52206 |  0:02:18s\n",
      "epoch 67 | loss: 0.31449 | val_logloss: 0.54247 |  0:02:20s\n",
      "epoch 68 | loss: 0.33337 | val_logloss: 0.51565 |  0:02:21s\n",
      "epoch 69 | loss: 0.32676 | val_logloss: 0.50276 |  0:02:23s\n",
      "epoch 70 | loss: 0.37372 | val_logloss: 0.44644 |  0:02:25s\n",
      "epoch 71 | loss: 0.30717 | val_logloss: 0.53158 |  0:02:27s\n",
      "epoch 72 | loss: 0.32677 | val_logloss: 0.50301 |  0:02:29s\n",
      "epoch 73 | loss: 0.38029 | val_logloss: 0.52658 |  0:02:30s\n",
      "epoch 74 | loss: 0.34055 | val_logloss: 0.5419  |  0:02:32s\n",
      "epoch 75 | loss: 0.3545  | val_logloss: 0.51303 |  0:02:34s\n",
      "epoch 76 | loss: 0.34605 | val_logloss: 0.42506 |  0:02:36s\n",
      "epoch 77 | loss: 0.34448 | val_logloss: 0.60237 |  0:02:37s\n",
      "epoch 78 | loss: 0.32452 | val_logloss: 0.53141 |  0:02:39s\n",
      "epoch 79 | loss: 0.33348 | val_logloss: 0.47102 |  0:02:41s\n",
      "epoch 80 | loss: 0.34318 | val_logloss: 0.41752 |  0:02:42s\n",
      "epoch 81 | loss: 0.31339 | val_logloss: 0.47551 |  0:02:44s\n",
      "epoch 82 | loss: 0.30535 | val_logloss: 0.47478 |  0:02:46s\n",
      "epoch 83 | loss: 0.31107 | val_logloss: 0.45855 |  0:02:48s\n",
      "epoch 84 | loss: 0.34248 | val_logloss: 0.52323 |  0:02:50s\n",
      "epoch 85 | loss: 0.32867 | val_logloss: 0.41453 |  0:02:52s\n",
      "\n",
      "Early stopping occurred at epoch 85 with best_epoch = 55 and best_val_logloss = 0.38221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at tabnet_pretrain_model.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tabnet_pretrain_model.zip'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_pretrain_params = study_scratch.best_params\n",
    "\n",
    "tabnet_pretrain = TabNetClassifier(\n",
    "    n_d=best_pretrain_params['n_d_a'],           # split n_d_a into n_d\n",
    "    n_a=best_pretrain_params['n_d_a'],           # and n_a\n",
    "    n_steps=best_pretrain_params['n_steps'],\n",
    "    gamma=best_pretrain_params['gamma'],\n",
    "    lambda_sparse=best_pretrain_params['lambda_sparse'],\n",
    "    momentum=best_pretrain_params['momentum'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={'lr': best_pretrain_params['lr']},\n",
    "    mask_type='sparsemax',\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_pretrain_params['step_size'], 'gamma': best_pretrain_params['scheduler_gamma']},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# Train the final model\n",
    "tabnet_pretrain.fit(\n",
    "    X_train=X_A_train,\n",
    "    y_train=y_A_train,\n",
    "    eval_set=[(X_A_val, y_A_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"logloss\"],\n",
    "    max_epochs=150,\n",
    "    patience=30,\n",
    "    batch_size=best_pretrain_params['batch_size'],\n",
    "    virtual_batch_size=best_pretrain_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "tabnet_pretrain.save_model(\"tabnet_pretrain_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8244220-7390-4797-a19a-4d7e158111ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset A, Test Accuracy: 79.03%\n",
      "Pre-training, test on Dataset A, Test F1-score: 83.12%\n",
      "Pre-training, test on Dataset A, Test Recall (Sensitivity): 86.49%\n",
      "Pre-training, test on Dataset A, Test Specificity: 68.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Pretrain_TNet = tabnet_pretrain.predict(X_A_test)\n",
    "\n",
    "cm_A_TNet = confusion_matrix(y_A_test, Dataset_A_Pretrain_TNet)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A_TNet.ravel()\n",
    "\n",
    "# Calculate Metrics for TabNet on Dataset A\n",
    "acc_A_TNet = accuracy_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "f1_A_TNet = f1_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "recall_A_TNet = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A_TNet = TN_A / (TN_A + FP_A) * 100\n",
    "\n",
    "\n",
    "print(f\"Pre-training, test on Dataset A, Test Accuracy: {acc_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test F1-score: {f1_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Recall (Sensitivity): {recall_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Specificity: {specificity_A_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c40aac0-e457-447b-8a49-bca02c5b9a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset B, Accuracy: 77.42%\n",
      "Pre-training, test on Dataset B, F1-score: 75.86%\n",
      "Pre-training, test on Dataset B, Recall (Sensitivity): 78.57%\n",
      "Pre-training, test on Dataset B, Specificity: 76.47%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain_TNet = tabnet_pretrain.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_TNet = confusion_matrix(y_B_test, Dataset_B_Pretrain_TNet)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_TNet = accuracy_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "f1_B_TNet = f1_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_TNet = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B_TNet = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pre-training, test on Dataset B, Accuracy: {acc_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, F1-score: {f1_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Recall (Sensitivity): {recall_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Specificity: {specificity_B_TNet:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08c2ea6a-c6c8-4ca0-80aa-dea7c5ee0780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 1.8676698399014517\n",
      "lambda_sparse: 0.0042824862550021525\n",
      "lr: 0.0013627631079900057\n",
      "momentum: 0.92\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 10\n",
      "scheduler_gamma: 0.8296240533908424\n"
     ]
    }
   ],
   "source": [
    "best_finetune_params = {\n",
    "    \"gamma\": 1.8676698399014517,\n",
    "    \"lambda_sparse\": 0.0042824862550021525,\n",
    "    \"lr\": 0.0013627631079900058,\n",
    "    \"momentum\": 0.92,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 10,\n",
    "    \"scheduler_gamma\": 0.8296240533908424,\n",
    "}\n",
    "for key, value in best_finetune_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60a1ed99-b4e0-49c3-b7f3-3e48f2446be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_a changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_d changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_steps changed from 3 to 9\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72489 | val_logloss: 0.40464 |  0:00:00s\n",
      "epoch 1  | loss: 0.6506  | val_logloss: 0.43675 |  0:00:01s\n",
      "epoch 2  | loss: 0.69976 | val_logloss: 0.38073 |  0:00:02s\n",
      "epoch 3  | loss: 0.60403 | val_logloss: 0.31219 |  0:00:03s\n",
      "epoch 4  | loss: 0.56598 | val_logloss: 0.35777 |  0:00:04s\n",
      "epoch 5  | loss: 0.50526 | val_logloss: 0.38746 |  0:00:05s\n",
      "epoch 6  | loss: 0.51571 | val_logloss: 0.39502 |  0:00:06s\n",
      "epoch 7  | loss: 0.49269 | val_logloss: 0.4067  |  0:00:06s\n",
      "epoch 8  | loss: 0.55003 | val_logloss: 0.33063 |  0:00:07s\n",
      "epoch 9  | loss: 0.54201 | val_logloss: 0.34524 |  0:00:08s\n",
      "epoch 10 | loss: 0.52249 | val_logloss: 0.26496 |  0:00:09s\n",
      "epoch 11 | loss: 0.4713  | val_logloss: 0.42578 |  0:00:10s\n",
      "epoch 12 | loss: 0.53671 | val_logloss: 0.39776 |  0:00:11s\n",
      "epoch 13 | loss: 0.50691 | val_logloss: 0.44467 |  0:00:12s\n",
      "epoch 14 | loss: 0.50709 | val_logloss: 0.42855 |  0:00:12s\n",
      "epoch 15 | loss: 0.46436 | val_logloss: 0.39333 |  0:00:13s\n",
      "epoch 16 | loss: 0.47137 | val_logloss: 0.33967 |  0:00:14s\n",
      "epoch 17 | loss: 0.44265 | val_logloss: 0.34767 |  0:00:15s\n",
      "epoch 18 | loss: 0.47078 | val_logloss: 0.32374 |  0:00:16s\n",
      "epoch 19 | loss: 0.49943 | val_logloss: 0.28898 |  0:00:17s\n",
      "epoch 20 | loss: 0.51568 | val_logloss: 0.39117 |  0:00:17s\n",
      "epoch 21 | loss: 0.49345 | val_logloss: 0.35823 |  0:00:18s\n",
      "epoch 22 | loss: 0.49353 | val_logloss: 0.3595  |  0:00:19s\n",
      "epoch 23 | loss: 0.41856 | val_logloss: 0.34265 |  0:00:20s\n",
      "epoch 24 | loss: 0.39472 | val_logloss: 0.29371 |  0:00:21s\n",
      "epoch 25 | loss: 0.48955 | val_logloss: 0.29377 |  0:00:22s\n",
      "epoch 26 | loss: 0.49233 | val_logloss: 0.32342 |  0:00:23s\n",
      "epoch 27 | loss: 0.48682 | val_logloss: 0.25566 |  0:00:24s\n",
      "epoch 28 | loss: 0.48737 | val_logloss: 0.28437 |  0:00:25s\n",
      "epoch 29 | loss: 0.44621 | val_logloss: 0.33755 |  0:00:25s\n",
      "epoch 30 | loss: 0.51171 | val_logloss: 0.35506 |  0:00:26s\n",
      "epoch 31 | loss: 0.44781 | val_logloss: 0.31321 |  0:00:27s\n",
      "epoch 32 | loss: 0.44963 | val_logloss: 0.33282 |  0:00:28s\n",
      "epoch 33 | loss: 0.45859 | val_logloss: 0.29375 |  0:00:29s\n",
      "epoch 34 | loss: 0.4896  | val_logloss: 0.31625 |  0:00:30s\n",
      "epoch 35 | loss: 0.46572 | val_logloss: 0.32035 |  0:00:31s\n",
      "epoch 36 | loss: 0.47132 | val_logloss: 0.335   |  0:00:32s\n",
      "epoch 37 | loss: 0.4583  | val_logloss: 0.36119 |  0:00:33s\n",
      "epoch 38 | loss: 0.42925 | val_logloss: 0.41465 |  0:00:34s\n",
      "epoch 39 | loss: 0.43855 | val_logloss: 0.36178 |  0:00:35s\n",
      "epoch 40 | loss: 0.39594 | val_logloss: 0.3391  |  0:00:36s\n",
      "epoch 41 | loss: 0.49375 | val_logloss: 0.3534  |  0:00:36s\n",
      "epoch 42 | loss: 0.42493 | val_logloss: 0.32977 |  0:00:37s\n",
      "epoch 43 | loss: 0.45343 | val_logloss: 0.2863  |  0:00:38s\n",
      "epoch 44 | loss: 0.42002 | val_logloss: 0.30214 |  0:00:39s\n",
      "epoch 45 | loss: 0.44924 | val_logloss: 0.23162 |  0:00:40s\n",
      "epoch 46 | loss: 0.42679 | val_logloss: 0.23126 |  0:00:41s\n",
      "epoch 47 | loss: 0.43095 | val_logloss: 0.22923 |  0:00:42s\n",
      "epoch 48 | loss: 0.43217 | val_logloss: 0.28133 |  0:00:43s\n",
      "epoch 49 | loss: 0.48332 | val_logloss: 0.31082 |  0:00:44s\n",
      "epoch 50 | loss: 0.4454  | val_logloss: 0.32431 |  0:00:44s\n",
      "epoch 51 | loss: 0.48969 | val_logloss: 0.30566 |  0:00:45s\n",
      "epoch 52 | loss: 0.41178 | val_logloss: 0.33723 |  0:00:46s\n",
      "epoch 53 | loss: 0.40422 | val_logloss: 0.37187 |  0:00:47s\n",
      "epoch 54 | loss: 0.44867 | val_logloss: 0.38672 |  0:00:48s\n",
      "epoch 55 | loss: 0.43097 | val_logloss: 0.33417 |  0:00:49s\n",
      "epoch 56 | loss: 0.40976 | val_logloss: 0.37394 |  0:00:50s\n",
      "epoch 57 | loss: 0.44414 | val_logloss: 0.38592 |  0:00:50s\n",
      "epoch 58 | loss: 0.43083 | val_logloss: 0.34575 |  0:00:51s\n",
      "epoch 59 | loss: 0.45581 | val_logloss: 0.40524 |  0:00:52s\n",
      "epoch 60 | loss: 0.40188 | val_logloss: 0.37099 |  0:00:53s\n",
      "epoch 61 | loss: 0.44844 | val_logloss: 0.36899 |  0:00:54s\n",
      "epoch 62 | loss: 0.42397 | val_logloss: 0.35004 |  0:00:54s\n",
      "epoch 63 | loss: 0.43848 | val_logloss: 0.34202 |  0:00:55s\n",
      "epoch 64 | loss: 0.4329  | val_logloss: 0.34936 |  0:00:56s\n",
      "epoch 65 | loss: 0.42046 | val_logloss: 0.3443  |  0:00:57s\n",
      "epoch 66 | loss: 0.44537 | val_logloss: 0.32425 |  0:00:57s\n",
      "epoch 67 | loss: 0.41143 | val_logloss: 0.3189  |  0:00:58s\n",
      "epoch 68 | loss: 0.37618 | val_logloss: 0.31685 |  0:00:59s\n",
      "epoch 69 | loss: 0.4472  | val_logloss: 0.33681 |  0:01:00s\n",
      "epoch 70 | loss: 0.39328 | val_logloss: 0.33036 |  0:01:01s\n",
      "epoch 71 | loss: 0.39308 | val_logloss: 0.30391 |  0:01:01s\n",
      "epoch 72 | loss: 0.3671  | val_logloss: 0.38979 |  0:01:02s\n",
      "epoch 73 | loss: 0.4198  | val_logloss: 0.43192 |  0:01:03s\n",
      "epoch 74 | loss: 0.42751 | val_logloss: 0.39969 |  0:01:04s\n",
      "epoch 75 | loss: 0.39381 | val_logloss: 0.40287 |  0:01:05s\n",
      "epoch 76 | loss: 0.44475 | val_logloss: 0.40415 |  0:01:05s\n",
      "epoch 77 | loss: 0.41469 | val_logloss: 0.41018 |  0:01:06s\n",
      "epoch 78 | loss: 0.45186 | val_logloss: 0.36986 |  0:01:07s\n",
      "epoch 79 | loss: 0.43995 | val_logloss: 0.36155 |  0:01:08s\n",
      "epoch 80 | loss: 0.42925 | val_logloss: 0.37843 |  0:01:09s\n",
      "epoch 81 | loss: 0.43034 | val_logloss: 0.36966 |  0:01:10s\n",
      "epoch 82 | loss: 0.4148  | val_logloss: 0.39498 |  0:01:10s\n",
      "epoch 83 | loss: 0.40933 | val_logloss: 0.36935 |  0:01:11s\n",
      "epoch 84 | loss: 0.42512 | val_logloss: 0.35625 |  0:01:12s\n",
      "epoch 85 | loss: 0.41559 | val_logloss: 0.34703 |  0:01:13s\n",
      "epoch 86 | loss: 0.40209 | val_logloss: 0.33481 |  0:01:14s\n",
      "epoch 87 | loss: 0.41988 | val_logloss: 0.31427 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 47 and best_val_logloss = 0.22923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# best_finetune_params = study_finetune.best_params\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "tabnet_finetuned = TabNetClassifier(\n",
    "    n_d=8,\n",
    "    n_a=8,\n",
    "    n_steps=3,\n",
    "    gamma=best_finetune_params['gamma'],\n",
    "    lambda_sparse=best_finetune_params['lambda_sparse'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={\n",
    "        'lr': best_finetune_params['lr']\n",
    "    },\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_finetune_params['step_size'], 'gamma': best_finetune_params['scheduler_gamma']},\n",
    "    seed=42,\n",
    "    verbose=1,\n",
    "    device_name='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "tabnet_finetuned.fit(\n",
    "    X_train=X_B_train,\n",
    "    y_train=y_B_train,           \n",
    "    eval_set=[(X_B_val, y_B_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=['logloss'],\n",
    "    max_epochs=100,\n",
    "    patience=40,\n",
    "    batch_size=best_finetune_params['batch_size'],\n",
    "    virtual_batch_size=best_finetune_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # Initialize with pre-trained weights\n",
    "    from_unsupervised=tabnet_pretrain  # Transfer learning!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcb0603e-8399-4861-9f00-b943aeff7fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset A, Test Accuracy: 79.03%\n",
      "Fine-tuned, test on Dataset A, Test F1-score: 82.19%\n",
      "Fine-tuned, test on Dataset A, Test Recall (Sensitivity): 81.08%\n",
      "Fine-tuned, test on Dataset A, Test Specificity: 76.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Finetune_TNet = tabnet_finetuned.predict(X_A_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset A\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_A_Finetune_TNet = confusion_matrix(y_A_test, Dataset_A_Finetune_TNet)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_A_Finetune_TNet = accuracy_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "f1_A_Finetune_TNet = f1_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_A_Finetune_TNet = TP_A_F / (TP_A_F + FN_A_F) * 100 if (TP_A_F + FN_A_F) > 0 else 0\n",
    "specificity_A_Finetune_TNet = TN_A_F / (TN_A_F + FP_A_F) * 100 if (TN_A_F + FP_A_F) > 0 else 0\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Accuracy: {acc_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test F1-score: {f1_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Recall (Sensitivity): {recall_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Specificity: {specificity_A_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "357c6039-9f26-4de1-a9da-1f10dcda17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset B, Accuracy: 80.65%\n",
      "Fine-tuned, test on Dataset B, F1-score: 80.00%\n",
      "Fine-tuned, test on Dataset B, Recall (Sensitivity): 85.71%\n",
      "Fine-tuned, test on Dataset B, Specificity: 76.47%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Finetune_TNet = tabnet_finetuned.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_Finetune_TNet = confusion_matrix(y_B_test, Dataset_B_Finetune_TNet)\n",
    "TN_F, FP_F, FN_F, TP_F = cm_B_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_Finetune_TNet = accuracy_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "f1_B_Finetune_TNet = f1_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_Finetune_TNet = TP_F / (TP_F + FN_F) * 100\n",
    "specificity_B_Finetune_TNet = TN_F / (TN_F + FP_F) * 100\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset B, Accuracy: {acc_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, F1-score: {f1_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Recall (Sensitivity): {recall_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Specificity: {specificity_B_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81509e62-8502-4cb6-a7e1-d6c997fb4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Create the plot with a specific size\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Display confusion matrix as an image with the 'Blues' color map\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "# Set color bar ticks based on the max value of the matrix\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# Remove title as per request (You can uncomment the next line if you want to add a title)\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "# Label the axes\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Normalize the color range based on the confusion matrix values\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "# Iterate through the matrix to add text inside each cell\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))  # Get the color of the cell based on the value\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]  # Calculate luminance\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'  # Choose white or black text based on luminance\n",
    "        \n",
    "        # Add the text inside the cell with bold and Times New Roman font\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image with high resolution\n",
    "plt.savefig('confusion_matrix_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26f9b1-2251-4300-90ca-eca153ba1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Times New Roman font is used in all plots\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '20'})\n",
    "\n",
    "# Get predictions for TabNet model\n",
    "y_pred = tabnet_finetuned.predict(X_B_test)  # Get the class predictions for target domain\n",
    "y_pred_prob = tabnet_finetuned.predict_proba(X_B_test)[:, 1]  # Probabilities for the positive class (ROC)\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_B_test, y_pred) * 100\n",
    "recall = recall_score(y_B_test, y_pred) * 100\n",
    "f1 = f1_score(y_B_test, y_pred) * 100\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1-Score: {f1:.2f}%\")\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "tn, fp, fn, tp = confusion_matrix(y_B_test, y_pred).ravel()\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "print(f\"Specificity: {specificity:.2f}%\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_B_test, y_pred_prob) * 100\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_B_test, y_pred_prob)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()  # Display the plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d28fe7-74ba-41e7-8fef-2b8d2b0f3303",
   "metadata": {},
   "source": [
    "## 6. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1df4cc-4459-498a-a4e1-6bc8757c079b",
   "metadata": {},
   "source": [
    "### Pretraining phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6deece6-fe3b-4e0e-beed-38de643fc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'learning_rate' : 0.01,\n",
    "    'l2_reg' : 0.0001,\n",
    "    'neurons_l1' : 128,\n",
    "    'dropout_rate' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90ed9878-a295-4f60-b9fb-cc2c0715e139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m1,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_mlp_model(input_shape, best_params):\n",
    "    neurons_l1 = best_params['neurons_l1']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    l2_reg = best_params['l2_reg']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(neurons_l1, activation='relu', name='feature_layer_1', kernel_regularizer=keras.regularizers.l2(l2_reg))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/2), activation='relu', name='feature_layer_2', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/4), activation='relu', name='feature_layer_3', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_dim = X_pretrain_train_res.shape[1]\n",
    "mlp_pretrain = create_mlp_model(input_dim, best_params)\n",
    "mlp_pretrain.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "654d4553-dfdd-48c9-a387-9d970de06b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5644 - auc: 0.5983 - loss: 6.6898 - val_accuracy: 0.3934 - val_auc: 0.6633 - val_loss: 1.3126\n",
      "Epoch 2/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5729 - auc: 0.5213 - loss: 0.9031 - val_accuracy: 0.3934 - val_auc: 0.5884 - val_loss: 0.7474\n",
      "Epoch 3/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4847 - auc: 0.4799 - loss: 0.7791 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7074\n",
      "Epoch 4/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4983 - auc: 0.5104 - loss: 0.7088 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7089\n",
      "Epoch 5/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.4966 - loss: 0.7096 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7093\n",
      "Epoch 6/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5254 - auc: 0.4400 - loss: 0.7106 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7098\n",
      "Epoch 7/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5136 - auc: 0.4893 - loss: 0.7257 - val_accuracy: 0.6066 - val_auc: 0.6605 - val_loss: 0.6991\n",
      "Epoch 8/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - auc: 0.3816 - loss: 0.7110 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7126\n",
      "Epoch 9/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.3409 - loss: 0.7057 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7124\n",
      "Epoch 10/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5017 - auc: 0.3569 - loss: 0.7051 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7120\n",
      "Epoch 11/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4949 - auc: 0.3918 - loss: 0.7076 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7116\n",
      "Epoch 12/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4966 - auc: 0.3820 - loss: 0.7101 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7112\n",
      "Epoch 13/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.4339 - loss: 0.7064 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7107\n",
      "Epoch 14/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4966 - auc: 0.4999 - loss: 0.7127 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7104\n",
      "Epoch 15/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4983 - auc: 0.4933 - loss: 0.7060 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7102\n",
      "Epoch 16/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4983 - auc: 0.5017 - loss: 0.7050 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7100\n",
      "Epoch 17/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5017 - auc: 0.4983 - loss: 0.7047 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7099\n",
      "Epoch 18/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - auc: 0.4409 - loss: 0.7050 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7097\n",
      "Epoch 19/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.4492 - loss: 0.7046 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7096\n",
      "Epoch 20/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - auc: 0.3939 - loss: 0.7050 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7095\n",
      "Epoch 21/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3923 - loss: 0.7048 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7093\n",
      "Epoch 22/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3502 - loss: 0.7050 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7092\n",
      "Epoch 23/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3542 - loss: 0.7043 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7091\n",
      "Epoch 24/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4983 - auc: 0.3525 - loss: 0.7033 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7089\n",
      "Epoch 25/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - auc: 0.3552 - loss: 0.7042 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7088\n",
      "Epoch 26/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5017 - auc: 0.3619 - loss: 0.7046 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7087\n",
      "Epoch 27/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3542 - loss: 0.7040 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7087\n",
      "Epoch 28/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3525 - loss: 0.7039 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7086\n",
      "Epoch 29/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5017 - auc: 0.3565 - loss: 0.7035 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7085\n",
      "Epoch 30/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - auc: 0.3508 - loss: 0.7039 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7085\n",
      "Epoch 31/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.3660 - loss: 0.7028 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7084\n",
      "Epoch 32/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - auc: 0.3400 - loss: 0.7034 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7082\n",
      "Epoch 33/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3412 - loss: 0.7036 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7079\n",
      "Epoch 34/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5017 - auc: 0.3414 - loss: 0.7033 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7079\n",
      "Epoch 35/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.3487 - loss: 0.7024 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7078\n",
      "Epoch 36/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5017 - auc: 0.3475 - loss: 0.7034 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7077\n",
      "Epoch 37/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4983 - auc: 0.3395 - loss: 0.7065 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7076\n",
      "Epoch 38/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.3407 - loss: 0.7031 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7076\n",
      "Epoch 39/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - auc: 0.3454 - loss: 0.7026 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7076\n",
      "Epoch 40/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - auc: 0.3396 - loss: 0.7025 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7076\n",
      "Epoch 41/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - auc: 0.3627 - loss: 0.7054 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7078\n",
      "Epoch 42/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5051 - auc: 0.4581 - loss: 0.7008 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7080\n",
      "Epoch 43/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - auc: 0.3986 - loss: 0.7026 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7078\n",
      "Epoch 44/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5017 - auc: 0.3575 - loss: 0.7023 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7076\n",
      "Epoch 45/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3333 - loss: 0.7018 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7073\n",
      "Epoch 46/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5017 - auc: 0.3300 - loss: 0.7028 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7072\n",
      "Epoch 47/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - auc: 0.3397 - loss: 0.7020 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7073\n",
      "Epoch 48/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6034 - auc: 0.6862 - loss: 0.6837 - val_accuracy: 0.3934 - val_auc: 0.5490 - val_loss: 0.7107\n",
      "Epoch 49/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5119 - auc: 0.4669 - loss: 0.7139 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7150\n",
      "Epoch 50/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3424 - loss: 0.7079 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7145\n",
      "Epoch 51/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5034 - auc: 0.3751 - loss: 0.7038 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7133\n",
      "Epoch 52/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3306 - loss: 0.7044 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7121\n",
      "Epoch 53/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3524 - loss: 0.7034 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7111\n",
      "Epoch 54/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4949 - auc: 0.3764 - loss: 0.7044 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7103\n",
      "Epoch 55/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4983 - auc: 0.3936 - loss: 0.7032 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7097\n",
      "Epoch 56/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3482 - loss: 0.7025 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7091\n",
      "Epoch 57/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3660 - loss: 0.7017 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7086\n",
      "Epoch 58/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3927 - loss: 0.7025 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7082\n",
      "Epoch 59/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3817 - loss: 0.7022 - val_accuracy: 0.3934 - val_auc: 0.5000 - val_loss: 0.7079\n"
     ]
    }
   ],
   "source": [
    "pretrain_history = mlp_pretrain.fit(\n",
    "    X_pretrain_train_res, \n",
    "    y_pretrain_train_res,\n",
    "    epochs=150, # Start with a reasonable number of epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_pretrain_val, y_pretrain_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=52, restore_best_weights=True)\n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the pre-trained weights using the required extension\n",
    "mlp_pretrain.save_weights('mlp_pretrain.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d505ca53-a0de-4398-87c6-ccfe472c3f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.4850\n",
      "Max F1 Score at this threshold: 0.6364\n"
     ]
    }
   ],
   "source": [
    "# Use the fine-tune validation set (X_finetune_val) to find the threshold\n",
    "y_val_proba = mlp_pretrain.predict(X_finetune_val).ravel()\n",
    "precision, recall, thresholds = precision_recall_curve(y_finetune_val, y_val_proba)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6) # Added 1e-6 to prevent division by zero\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")\n",
    "\n",
    "# Now, use best_threshold instead of 0.5 for final testing (e.g., y_pred = (y_pred_proba > best_threshold).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cf444f1-dd04-40e2-9648-f1314e5065f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Pretraining Test Accuracy on Source domain: 59.68%\n",
      "Pretraining Test F1 on Source domain: 59.02%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 48.65%\n",
      "Pretraining Test Specificity on Source domain: 76.00%\n",
      "Pretraining Test ROC-AUC on Source domain: 0.63%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\")\n",
    "\n",
    "y_pred_proba_a = mlp_pretrain.predict(X_pretrain_test).ravel()\n",
    "\n",
    "\n",
    "y_pred_a = (y_pred_proba_a > best_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a = accuracy_score(y_pretrain_test, y_pred_a) * 100\n",
    "f1_a = f1_score(y_pretrain_test, y_pred_a) * 100\n",
    "roc_auc_a = roc_auc_score(y_pretrain_test, y_pred_proba_a) * 100\n",
    "recall_a = recall_score(y_pretrain_test, y_pred_a) * 100\n",
    "precision_a = precision_score(y_pretrain_test, y_pred_a) * 100\n",
    "specificity_a = recall_score(y_pretrain_test, y_pred_a, pos_label=0) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {accuracy_a:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {f1_a:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_a:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_a:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on Source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b01219ae-3d2a-4660-88f5-84ef12d70ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Pretraining Test Accuracy on target domain: 54.84%\n",
      "Pretraining Test F1 on target domain: 0.00%\n",
      "Pretraining Test Recall (Sensitivity) on target domain: 0.00%\n",
      "Pretraining Test Specificity on target domain: 100.00%\n",
      "Pretraining Test ROC-AUC on target domain: 0.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\")\n",
    "\n",
    "# Get raw probability predictions\n",
    "y_pred_proba_b = mlp_pretrain.predict(X_finetune_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_b = (y_pred_proba_b > best_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b = accuracy_score(y_finetune_test, y_pred_b) * 100\n",
    "f1_b = f1_score(y_finetune_test, y_pred_b) * 100\n",
    "roc_auc_b = roc_auc_score(y_finetune_test, y_pred_proba_b) * 100\n",
    "recall_b = recall_score(y_finetune_test, y_pred_b) * 100\n",
    "precision_b = precision_score(y_finetune_test, y_pred_b) * 100\n",
    "specificity_b = recall_score(y_finetune_test, y_pred_b, pos_label=0) * 100\n",
    "\n",
    "print(f\"Pretraining Test Accuracy on target domain: {accuracy_b:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on target domain: {f1_b:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on target domain: {recall_b:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on target domain: {specificity_b:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on target domain: {roc_auc_score(y_finetune_test, y_pred_proba_b):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e01e12-434e-48a8-bd31-fe2a5ae61bbf",
   "metadata": {},
   "source": [
    "### Finetuning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cdd7167-26dd-4d0c-9a56-ca4e44086c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m1,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,369</span> (40.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,369\u001b[0m (40.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def setup_fine_tuning(input_shape, pretrain_weights_path, best_params, fine_tune_lr=1e-1):\n",
    "    # Create the model with exactly the same architecture as pre-training\n",
    "    model_ft = create_mlp_model(input_shape, best_params)\n",
    "    \n",
    "    # Load pre-trained weights\n",
    "    model_ft.load_weights(pretrain_weights_path)\n",
    "\n",
    "    # Freeze layers for fine-tuning\n",
    "    model_ft.get_layer('feature_layer_1').trainable = False\n",
    "    model_ft.get_layer('feature_layer_2').trainable = True\n",
    "    model_ft.get_layer('feature_layer_3').trainable = True\n",
    "    \n",
    "    # Recompile with lower learning rate for fine-tuning\n",
    "    model_ft.compile(\n",
    "        optimizer=Adam(learning_rate=fine_tune_lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "\n",
    "    )\n",
    "    \n",
    "    finetune_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return model_ft, finetune_scheduler\n",
    "\n",
    "\n",
    "mlp_finetune, finetune_scheduler = setup_fine_tuning(\n",
    "    input_shape=input_dim,  # Use the input dimension from Dataset B\n",
    "    pretrain_weights_path='mlp_pretrain.weights.h5', \n",
    "    best_params=best_params,  # Add best_trial here\n",
    "    fine_tune_lr=0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Save the fine-tuned model weights (optional)\n",
    "mlp_finetune.save_weights('mlp_finetune_weights.weights.h5')\n",
    "\n",
    "# Check the model summary to ensure layers are frozen correctly\n",
    "mlp_finetune.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fc5d9c6-5dbc-425f-b6e0-5d5891ec0c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.5992 - auc: 0.5823 - loss: 2.4821 - val_accuracy: 0.4667 - val_auc: 0.3371 - val_loss: 0.7640\n",
      "Epoch 2/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4427 - auc: 0.4688 - loss: 0.7437 - val_accuracy: 0.4667 - val_auc: 0.3571 - val_loss: 0.7356\n",
      "Epoch 3/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4656 - auc: 0.4668 - loss: 0.7511 - val_accuracy: 0.5333 - val_auc: 0.5000 - val_loss: 0.7170\n",
      "Epoch 4/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.6008 - loss: 0.7147 - val_accuracy: 0.5333 - val_auc: 0.5000 - val_loss: 0.7121\n",
      "Epoch 5/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5153 - auc: 0.5612 - loss: 0.7127 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7151\n",
      "Epoch 6/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3784 - loss: 0.7151 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7152\n",
      "Epoch 7/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3803 - loss: 0.7149 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7138\n",
      "Epoch 8/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.4034 - loss: 0.7138 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7126\n",
      "Epoch 9/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7129 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7118\n",
      "Epoch 10/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3796 - loss: 0.7122 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7113\n",
      "Epoch 11/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3796 - loss: 0.7116 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7107\n",
      "Epoch 12/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7111 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7102\n",
      "Epoch 13/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7107 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7097\n",
      "Epoch 14/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7102 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7093\n",
      "Epoch 15/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7098 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7089\n",
      "Epoch 16/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7094 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7085\n",
      "Epoch 17/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7090 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7081\n",
      "Epoch 18/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3726 - loss: 0.7086 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7077\n",
      "Epoch 19/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7083 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7074\n",
      "Epoch 20/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7079 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7070\n",
      "Epoch 21/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7076 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7067\n",
      "Epoch 22/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7073 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7064\n",
      "Epoch 23/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7070 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7061\n",
      "Epoch 24/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7067 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7058\n",
      "Epoch 25/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7064 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7056\n",
      "Epoch 26/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7062 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7053\n",
      "Epoch 27/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7059 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7051\n",
      "Epoch 28/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7057 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7048\n",
      "Epoch 29/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7054 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7046\n",
      "Epoch 30/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7052 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7044\n",
      "Epoch 31/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7050 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7041\n",
      "Epoch 32/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7048 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7039\n",
      "Epoch 33/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7046 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7037\n",
      "Epoch 34/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7044 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7035\n",
      "Epoch 35/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7042 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7033\n",
      "Epoch 36/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7040 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7032\n",
      "Epoch 37/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7038 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7030\n",
      "Epoch 38/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7037 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7028\n",
      "Epoch 39/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7035 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7026\n",
      "Epoch 40/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7033 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7025\n",
      "Epoch 41/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7032 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7023\n",
      "Epoch 42/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7030 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7022\n",
      "Epoch 43/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7029 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7020\n",
      "Epoch 44/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7027 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7019\n",
      "Epoch 45/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7026 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7017\n",
      "Epoch 46/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7024 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7016\n",
      "Epoch 47/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7023 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7015\n",
      "Epoch 48/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7022 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7013\n",
      "Epoch 49/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7020 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7012\n",
      "Epoch 50/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7019 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7011\n",
      "Epoch 51/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7018 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7010\n",
      "Epoch 52/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7017 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7008\n",
      "Epoch 53/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7016 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7007\n",
      "Epoch 54/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7014 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7006\n",
      "Epoch 55/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7013 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7005\n",
      "Epoch 56/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7012 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7004\n",
      "Epoch 57/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7011 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7003\n",
      "Epoch 58/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7010 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7002\n",
      "Epoch 59/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7009 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7001\n",
      "Epoch 60/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7008 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.7000\n",
      "Epoch 61/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7007 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6999\n",
      "Epoch 62/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7006 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6998\n",
      "Epoch 63/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7005 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6997\n",
      "Epoch 64/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7005 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6996\n",
      "Epoch 65/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7004 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6996\n",
      "Epoch 66/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7003 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6995\n",
      "Epoch 67/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7002 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6994\n",
      "Epoch 68/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7001 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6993\n",
      "Epoch 69/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7001 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6992\n",
      "Epoch 70/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.7000 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6992\n",
      "Epoch 71/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6999 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6991\n",
      "Epoch 72/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6998 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6990\n",
      "Epoch 73/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6998 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6989\n",
      "Epoch 74/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6997 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6989\n",
      "Epoch 75/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6996 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6988\n",
      "Epoch 76/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6996 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6987\n",
      "Epoch 77/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6995 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6987\n",
      "Epoch 78/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6994 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6986\n",
      "Epoch 79/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6994 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6986\n",
      "Epoch 80/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6993 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6985\n",
      "Epoch 81/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6993 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6984\n",
      "Epoch 82/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6992 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6984\n",
      "Epoch 83/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6991 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6983\n",
      "Epoch 84/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6991 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6983\n",
      "Epoch 85/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6990 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6982\n",
      "Epoch 86/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6990 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6982\n",
      "Epoch 87/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6989 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6981\n",
      "Epoch 88/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6989 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6981\n",
      "Epoch 89/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6988 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6980\n",
      "Epoch 90/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6988 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6980\n",
      "Epoch 91/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6987 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6979\n",
      "Epoch 92/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6987 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6979\n",
      "Epoch 93/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6986 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6978\n",
      "Epoch 94/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6986 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6978\n",
      "Epoch 95/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6985 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6977\n",
      "Epoch 96/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6985 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6977\n",
      "Epoch 97/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6985 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6977\n",
      "Epoch 98/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6984 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6976\n",
      "Epoch 99/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6984 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6976\n",
      "Epoch 100/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6983 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6975\n",
      "Epoch 101/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6983 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6975\n",
      "Epoch 102/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6983 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6975\n",
      "Epoch 103/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6982 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6974\n",
      "Epoch 104/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6982 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6974\n",
      "Epoch 105/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6982 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6974\n",
      "Epoch 106/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6981 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6973\n",
      "Epoch 107/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6981 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6973\n",
      "Epoch 108/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6981 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6973\n",
      "Epoch 109/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6980 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6972\n",
      "Epoch 110/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6980 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6972\n",
      "Epoch 111/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6980 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6972\n",
      "Epoch 112/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6979 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6971\n",
      "Epoch 113/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6979 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6971\n",
      "Epoch 114/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6979 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6971\n",
      "Epoch 115/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6978 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6970\n",
      "Epoch 116/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6978 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6970\n",
      "Epoch 117/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6978 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6970\n",
      "Epoch 118/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6978 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6970\n",
      "Epoch 119/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6977 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6969\n",
      "Epoch 120/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6977 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6969\n",
      "Epoch 121/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6977 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6969\n",
      "Epoch 122/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6977 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6969\n",
      "Epoch 123/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6976 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6968\n",
      "Epoch 124/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6976 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6968\n",
      "Epoch 125/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6976 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6968\n",
      "Epoch 126/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6976 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6968\n",
      "Epoch 127/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6975 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6967\n",
      "Epoch 128/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6975 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6967\n",
      "Epoch 129/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6975 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6967\n",
      "Epoch 130/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6975 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6967\n",
      "Epoch 131/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6975 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6967\n",
      "Epoch 132/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6974 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6966\n",
      "Epoch 133/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6974 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6966\n",
      "Epoch 134/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6974 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6966\n",
      "Epoch 135/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6974 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6966\n",
      "Epoch 136/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6974 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6966\n",
      "Epoch 137/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6973 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6965\n",
      "Epoch 138/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6973 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6965\n",
      "Epoch 139/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6973 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6965\n",
      "Epoch 140/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6973 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6965\n",
      "Epoch 141/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6973 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6965\n",
      "Epoch 142/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6973 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6965\n",
      "Epoch 143/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6972 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 144/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6972 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 145/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6972 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 146/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6972 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 147/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6972 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 148/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6972 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 149/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6964\n",
      "Epoch 150/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 151/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 152/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 153/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 154/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 155/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6971 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 156/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6963\n",
      "Epoch 157/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 158/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 159/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 160/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 161/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 162/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 163/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 164/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6970 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 165/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6962\n",
      "Epoch 166/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 167/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 168/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 169/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 170/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 171/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 172/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 173/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 174/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6969 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 175/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6961\n",
      "Epoch 176/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 177/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 178/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 179/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 180/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 181/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 182/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 183/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 184/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 185/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 186/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6968 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 187/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 188/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6960\n",
      "Epoch 189/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 190/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 191/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 192/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 193/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 194/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 195/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 196/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 197/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 198/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 199/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 200/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 201/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 202/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6967 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 203/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 204/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6959\n",
      "Epoch 205/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 206/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 207/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 208/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 209/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 210/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 211/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 212/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 213/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 214/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 215/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 216/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 217/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 218/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 219/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 220/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 221/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 222/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 223/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 224/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6966 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 225/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 226/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6958\n",
      "Epoch 227/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 228/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 229/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 230/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 231/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 232/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 233/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 234/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 235/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 236/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 237/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 238/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 239/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 240/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 241/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 242/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 243/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 244/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 245/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 246/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 247/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 248/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 249/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 250/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 251/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 252/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 253/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 254/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 255/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 256/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6965 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 257/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 258/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 259/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 260/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 261/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6957\n",
      "Epoch 262/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 263/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 264/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 265/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 266/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 267/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 268/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 269/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 270/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 271/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 272/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 273/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 274/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 275/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 276/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 277/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 278/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 279/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 280/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 281/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 282/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 283/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 284/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 285/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 286/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 287/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 288/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 289/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 290/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 291/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 292/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 293/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 294/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 295/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 296/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 297/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 298/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 299/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Epoch 300/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - auc: 0.3829 - loss: 0.6964 - val_accuracy: 0.4667 - val_auc: 0.5000 - val_loss: 0.6956\n",
      "Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\n"
     ]
    }
   ],
   "source": [
    "history_finetune = mlp_finetune.fit(\n",
    "    X_finetune_train_res, \n",
    "    y_finetune_train_res,\n",
    "    epochs=300, # Fewer epochs are usually needed for fine-tuning\n",
    "    batch_size=16, # Smaller batch size often works better for smaller datasets\n",
    "    validation_data=(X_finetune_val, y_finetune_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True), \n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03afe4a2-81e2-4c23-8d80-0081becbce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.5145\n",
      "Max F1 Score at this threshold: 0.6364\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Use the fine-tune validation set (X_finetune_val) to find the optimal threshold ---\n",
    "y_val_proba_ft = mlp_finetune.predict(X_finetune_val).ravel()  # Raw probability predictions\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_finetune_val, y_val_proba_ft)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6)  # Adding 1e-6 to prevent division by zero\n",
    "\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_finetune_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_finetune_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f96e9a9-99dc-4097-9b40-12d0919b4b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step \n",
      "Finetune Test Accuracy on source domain: 40.32%\n",
      "Finetune Test F1 on source domain: 0.00%\n",
      "Finetune Test Recall (Sensitivity) on source domain: 0.00%\n",
      "Finetune Test Specificity on source domain: 100.00%\n",
      "Finetune Test ROC-AUC on source domain: 0.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get raw probability predictions\n",
    "y_pred_proba_a_ft = mlp_finetune.predict(X_pretrain_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_a_ft = (y_pred_proba_a_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a_ft = accuracy_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "f1_a_ft = f1_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "roc_auc_a_ft = roc_auc_score(y_pretrain_test, y_pred_proba_a_ft) * 100\n",
    "recall_a_ft = recall_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "precision_a_ft = precision_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "specificity_a_ft = recall_score(y_pretrain_test, y_pred_a_ft, pos_label=0) * 100\n",
    "\n",
    "print(f\"Finetune Test Accuracy on source domain: {accuracy_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on source domain: {f1_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on source domain: {recall_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on source domain: {specificity_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a_ft):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cab0016-9400-41f5-a52c-f41a284ef14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Finetune Test Accuracy on target domain: 54.84%\n",
      "Finetune Test F1 on target domain: 0.00%\n",
      "Finetune Test Recall (Sensitivity) on target domain: 0.00%\n",
      "Finetune Test Specificity on target domain: 100.00%\n",
      "Finetune Test ROC-AUC on target domain:0.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_b_ft = mlp_finetune.predict(X_finetune_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions using a 0.5 threshold\n",
    "y_pred_b_ft = (y_pred_proba_b_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b_ft = accuracy_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "f1_b_ft = f1_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "roc_auc_b_ft = roc_auc_score(y_finetune_test, y_pred_proba_b_ft) * 100\n",
    "recall_b_ft = recall_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "precision_b_ft = precision_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "specificity_b_ft = recall_score(y_finetune_test, y_pred_b_ft, pos_label=0) * 100\n",
    "\n",
    "\n",
    "print(f\"Finetune Test Accuracy on target domain: {accuracy_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on target domain: {f1_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on target domain: {recall_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on target domain: {specificity_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on target domain:{roc_auc_score(y_finetune_test, y_pred_proba_b_ft):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41a579-48bb-43e7-a376-f650c63a5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Confusion matrix\n",
    "cm_mlp = confusion_matrix(y_finetune_test, y_pred_b_ft)\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm_mlp.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm_mlp, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm_mlp.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['Disease', 'No Disease'])\n",
    "# Set Y-axis labels (Actual: Disease then No Disease)\n",
    "plt.yticks([0, 1], ['No Disease', 'Disease'], rotation=90)  # Horizontal labels\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm_mlp.min(), vmax=cm_mlp.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm_mlp[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_mlp.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8075ea8-bc65-4ba4-ac42-11a3da38929e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03ed7f-4771-44e8-8c83-f0f239c44aab",
   "metadata": {},
   "source": [
    "## 8. Decision Curve Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844cb082-d33c-41e3-bf4e-f97f4c4fb786",
   "metadata": {},
   "source": [
    "## 9. Combined models ROC-AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "13e93627-3128-4f21-a053-1e4f5f70dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tabnet_finetuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred_prob_mlp \u001b[38;5;241m=\u001b[39m mlp_finetune\u001b[38;5;241m.\u001b[39mpredict(X_finetune_test)\n\u001b[1;32m----> 2\u001b[0m y_pred_prob_tabnet \u001b[38;5;241m=\u001b[39m tabnet_finetuned\u001b[38;5;241m.\u001b[39mpredict(X_B_test)\n\u001b[0;32m      3\u001b[0m y_pred_prob_xgb \u001b[38;5;241m=\u001b[39m xgb_finetune\u001b[38;5;241m.\u001b[39mpredict_proba(X_finetune_test)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tabnet_finetuned' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_prob_mlp = mlp_finetune.predict(X_finetune_test)\n",
    "y_pred_prob_tabnet = tabnet_finetuned.predict(X_B_test)\n",
    "y_pred_prob_xgb = xgb_finetune.predict_proba(X_finetune_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f0f19-fcd3-4444-b6ee-8111823392c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size': 18})\n",
    "\n",
    "# Get predicted probabilities for each model\n",
    "y_pred_prob_mlp = mlp_finetune.predict(X_finetune_test)\n",
    "y_pred_prob_tabnet = tabnet_finetuned.predict(X_B_test)  # Probabilities for the positive class (ROC)\n",
    "y_pred_proba_xgb = xgb_finetune.predict(X_finetune_test) \n",
    "\n",
    "# Calculate ROC curve and AUC for each model\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_finetune_test, y_pred_prob_mlp)\n",
    "fpr_tabnet, tpr_tabnet, _ = roc_curve(y_B_test, y_pred_prob_tabnet)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Calculate AUC for each model\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "roc_auc_tabnet = auc(fpr_tabnet, tpr_tabnet)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Also calculate using roc_auc_score for verification\n",
    "roc_auc_score_mlp = roc_auc_score(y_B_test, y_pred_prob_mlp)\n",
    "roc_auc_score_tabnet = roc_auc_score(y_B_test, y_pred_prob_tabnet)\n",
    "roc_auc_score_xgb = roc_auc_score(y_B_test, y_pred_proba_xgb)\n",
    "\n",
    "print(f\"MLP AUC (auc function): {roc_auc_mlp:.4f}\")\n",
    "print(f\"MLP AUC (roc_auc_score): {roc_auc_score_mlp:.4f}\")\n",
    "print(f\"TabNet AUC: {roc_auc_tabnet:.4f}\")\n",
    "print(f\"XGBoost AUC: {roc_auc_xgb:.4f}\")\n",
    "\n",
    "# Plot combined ROC curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot each ROC curve\n",
    "plt.plot(fpr_mlp, tpr_mlp, color='red', lw=2, label=f'MLP (AUC = {roc_auc_mlp:.2f})')\n",
    "plt.plot(fpr_tabnet, tpr_tabnet, color='green', lw=2, label=f'TabNet (AUC = {roc_auc_tabnet:.2f})')\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='orange', lw=2, label=f'XGBoost (AUC = {roc_auc_xgb:.2f})')\n",
    "\n",
    "# Diagonal line for random classifier\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Adjust plot settings\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('Combined ROC Curve for Fine-Tuned Models')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Save the combined ROC curve\n",
    "plt.savefig('roc_curve_combined.png', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f768dd-9508-4dc0-81b2-d060810cb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from your table\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "# Model performance data\n",
    "xgboost = {\n",
    "    \"Accuracy\": [85.48, 88.71, 90.32, 83.87],\n",
    "    \"F1-Score\": [84.85, 88.37, 89.66, 83.87],\n",
    "    \"Sensitivity\": [85.71, 92.86, 92.86, 92.86],\n",
    "    \"Specificity\": [85.29, 85.29, 88.24, 76.47]\n",
    "}\n",
    "\n",
    "tabnet = {\n",
    "    \"Accuracy\": [80.65, 82.26, 83.87, 77.42],\n",
    "    \"F1-Score\": [82.76, 83.33, 84.85, 78.79],\n",
    "    \"Sensitivity\": [92.86, 100.00, 100.00, 85.71],\n",
    "    \"Specificity\": [70.59, 70.59, 70.59, 70.59]\n",
    "}\n",
    "\n",
    "mlp = {\n",
    "    \"Accuracy\": [83.87, 85.48, 87.10, 79.03],\n",
    "    \"F1-Score\": [82.76, 84.21, 85.71, 78.13],\n",
    "    \"Sensitivity\": [85.71, 85.71, 85.71, 78.57],\n",
    "    \"Specificity\": [82.35, 85.29, 88.24, 79.41]\n",
    "}\n",
    "\n",
    "resnet = {\n",
    "    \"Accuracy\": [85.48, 87.10, 88.71, 83.87],\n",
    "    \"F1-Score\": [85.71, 87.18, 88.37, 84.21],\n",
    "    \"Sensitivity\": [92.86, 92.86, 92.86, 92.86],\n",
    "    \"Specificity\": [79.41, 82.35, 85.29, 76.47]\n",
    "}\n",
    "\n",
    "# List of models for iteration\n",
    "models = ['XGBoost', 'TabNet', 'MLP', 'ResNet']\n",
    "metrics = ['Accuracy', 'F1-Score', 'Sensitivity', 'Specificity']\n",
    "\n",
    "# Plotting graphs for each model and metric\n",
    "for model, data in zip(models, [xgboost, tabnet, mlp, resnet]):\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(learning_rates, data[metric], marker='P', linestyle='-', label=f'{model} - {metric}')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{model} - {metric} vs Learning Rate')\n",
    "        plt.xscale('log')  # Log scale for better visualization if needed\n",
    "        plt.xticks(learning_rates)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        # Save the image\n",
    "        plt.savefig(f'{model}_{metric}_vs_learning_rate.png')\n",
    "        plt.close()  # Close the plot to prevent overlapping with the next one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de987cf3-400e-4aae-a75e-f89021b617ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
