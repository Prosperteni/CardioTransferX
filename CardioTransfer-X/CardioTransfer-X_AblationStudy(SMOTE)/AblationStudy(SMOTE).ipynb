{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bcfb71-06cb-4875-a056-d0c6e7a1e03f",
   "metadata": {},
   "source": [
    "# <font size=5> <strong>Heart Disease Prediction\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f549498-ec6a-486b-a9fa-8bc07bd6aa5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d3eb7e-461a-4535-821a-ef64396d461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import(accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
    "                            auc, confusion_matrix, classification_report, make_scorer)\n",
    "\n",
    "# Modeling – XGBoost and TabNet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b206114-e6e3-4019-81d2-2341db5e6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a94f5b-532a-4c85-b045-0754856c43e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed5e14-1c39-4cd1-b6a0-f7175bdf4f3d",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cae88cdd-d479-4855-837e-85e887c863f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_csv(\"Cleveland+Hungary+VA_long_beach+Switzerland.csv\") # Source domain = multi-hospital dataset\n",
    "df_B = pd.read_csv(\"Heart_disease_cleveland.csv\")                     # Target domain = original Cleveland dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4042b1b-b974-4412-9a46-ad17daa5779f",
   "metadata": {},
   "source": [
    "### Exploring and Inspecting Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154cc2bf-576d-4b87-9108-5892e1736f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 919 entries, 0 to 918\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        919 non-null    int64  \n",
      " 1   age       919 non-null    int64  \n",
      " 2   sex       919 non-null    object \n",
      " 3   dataset   919 non-null    object \n",
      " 4   cp        919 non-null    object \n",
      " 5   trestbps  919 non-null    float64\n",
      " 6   chol      919 non-null    float64\n",
      " 7   fbs       919 non-null    bool   \n",
      " 8   restecg   919 non-null    object \n",
      " 9   thalch    919 non-null    float64\n",
      " 10  exang     919 non-null    bool   \n",
      " 11  oldpeak   919 non-null    float64\n",
      " 12  slope     919 non-null    object \n",
      " 13  ca        919 non-null    float64\n",
      " 14  thal      919 non-null    object \n",
      " 15  num       919 non-null    int64  \n",
      "dtypes: bool(2), float64(5), int64(3), object(6)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_A.info() # Displays concise summary of DataFrame A: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4569bfa4-2b5a-4e51-b930-0695fb312a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_B.info() # Displays concise summary of DataFrame B: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2df8ede-ec12-435d-96b3-69ea3f3ba6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Cleveland data from df_A before pretraining\n",
    "df_A = df_A[df_A['dataset'] != 'Cleveland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f871dd-ca19-4a0c-a2f0-5bf65455002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
      "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
      "      dtype='object')\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_A.columns) # Prints the list of column names in DataFrame A.\n",
    "print(df_B.columns) # Prints the list of column names in DataFrame B."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edb2754-fbd5-44da-a9a9-310d6f34d472",
   "metadata": {},
   "source": [
    "1. We inspected the datasets using df.info(), df.columns, and df.head().\n",
    "#    Observations from Dataset A (combined multi-hospital dataset):\n",
    "- Many categorical columns (sex, cp, fbs, restecg, slope, thal, exang) are strings/booleans.\n",
    "- Some numeric columns have missing values (trestbps, chol, thalach, oldpeak, ca).\n",
    "- Column names differ from Dataset B (e.g., 'thalch' vs 'thalach', 'num' vs 'target').\n",
    "- Extra columns exist (e.g., 'id', 'dataset') that are irrelevant for modeling.\n",
    "- The target column uses 0–4 scale instead of 0/1 like Dataset B.\n",
    "\n",
    "#    Observations from Dataset B (Cleveland dataset):\n",
    "- All categorical columns are already numeric (int64), matching expected encoding.\n",
    "- No missing values.\n",
    "- Target column is binary (0=no disease, 1=disease).\n",
    "\n",
    "2. Based on these observations, the following harmonization steps are necessary:\n",
    "- Rename columns in Dataset A to match Dataset B.\n",
    "- Drop irrelevant columns in Dataset A (id, dataset).\n",
    "- Map all categorical strings/booleans in Dataset A to numeric codes matching Dataset B.\n",
    "- Fill missing values: \n",
    "#           • Categorical → mode of column\n",
    "#           • Numeric → median of column\n",
    "- Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "- Align features so both datasets have identical column names and encodings.\n",
    "\n",
    "3. Purpose:\n",
    "- Ensure that Dataset A (pretraining) and Dataset B (fine-tuning) are fully compatible.\n",
    "- Prevent encoding mismatches that would break transfer learning.\n",
    "- Guarantee that the XGBoost model receives numeric input for all features.\n",
    "- Maintain consistency for feature importance and SHAP explainability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856b1cf3-d252-4c47-a02e-1450c084d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.rename(columns={'thalch': 'thalach','num': 'target'}) #Rename columns in Dataset A to match Dataset B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0bc1c1-cea8-40ab-b12e-5e694f524027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.drop(columns=['id', 'dataset']) #Drop irrelevant columns in Dataset A (id, dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1915aeb1-8cdf-4f58-a0a6-20c303b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "df_A['target'] = df_A['target'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae38850-7e49-4efc-b2e2-ccb20ca3da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all categorical strings/booleans in Dataset A to numeric codes matching the target domain.\n",
    "sex_map = {'Male': 1, 'Female': 0}\n",
    "\n",
    "cp_map = {\n",
    "    'typical angina': 0,\n",
    "    'atypical angina': 1,\n",
    "    'non-anginal': 2,\n",
    "    'asymptomatic': 3\n",
    "}\n",
    "\n",
    "fbs_map = {True: 1, False: 0}\n",
    "\n",
    "restecg_map = {\n",
    "    'normal': 0,\n",
    "    'st-t abnormality': 1,\n",
    "    'lv hypertrophy': 2\n",
    "}\n",
    "\n",
    "exang_map = {True: 1, False: 0}\n",
    "\n",
    "slope_map = {\n",
    "    'upsloping': 0,\n",
    "    'flat': 1,\n",
    "    'downsloping': 2\n",
    "}\n",
    "\n",
    "thal_map = {\n",
    "    'normal': 1,\n",
    "    'fixed defect': 2,\n",
    "    'reversable defect': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2ac638-c3d6-4ad2-b138-6de8b87454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features so both datasets have identical column names and encodings.\n",
    "df_A['sex'] = df_A['sex'].map(sex_map)\n",
    "df_A['cp'] = df_A['cp'].map(cp_map)\n",
    "df_A['fbs'] = df_A['fbs'].map(fbs_map)\n",
    "df_A['restecg'] = df_A['restecg'].map(restecg_map)\n",
    "df_A['exang'] = df_A['exang'].map(exang_map)\n",
    "df_A['slope'] = df_A['slope'].map(slope_map)\n",
    "df_A['thal'] = df_A['thal'].map(thal_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e875d2bd-fdd7-4f55-98d3-b73e4b58589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Check (Both should return zero missing values.)\n",
    "print(df_A.isnull().sum())\n",
    "print(df_B.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed95ab7-b7dd-4f15-be3c-fb4b6bf2c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       615 non-null    int64  \n",
      " 1   sex       615 non-null    int64  \n",
      " 2   cp        615 non-null    int64  \n",
      " 3   trestbps  615 non-null    float64\n",
      " 4   chol      615 non-null    float64\n",
      " 5   fbs       615 non-null    int64  \n",
      " 6   restecg   615 non-null    int64  \n",
      " 7   thalach   615 non-null    float64\n",
      " 8   exang     615 non-null    int64  \n",
      " 9   oldpeak   615 non-null    float64\n",
      " 10  slope     615 non-null    int64  \n",
      " 11  ca        615 non-null    float64\n",
      " 12  thal      615 non-null    int64  \n",
      " 13  target    615 non-null    int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 72.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the target domain to ensure all columns are non-null.\n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bd4404-68aa-497c-8c21-7b57d80c56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the source domain to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d65ebbf-ecdc-4821-9ae1-fd383ac64e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets after preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m            304     305    306\n",
      "age        29.0   29.00   30.0\n",
      "sex         1.0    1.00    0.0\n",
      "cp          1.0    1.00    0.0\n",
      "trestbps  120.0  140.00  170.0\n",
      "chol      243.0  240.48  237.0\n",
      "fbs         0.0    0.00    0.0\n",
      "restecg     0.0    0.00    1.0\n",
      "thalach   160.0  170.00  170.0\n",
      "exang       0.0    0.00    0.0\n",
      "oldpeak     0.0    0.00    0.0\n",
      "slope       0.0    0.00    0.0\n",
      "ca          0.0    0.00    0.0\n",
      "thal        1.0    1.00    2.0\n",
      "target      0.0    0.00    0.0\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "age        63.0   67.0   67.0\n",
      "sex         1.0    1.0    1.0\n",
      "cp          0.0    3.0    3.0\n",
      "trestbps  145.0  160.0  120.0\n",
      "chol      233.0  286.0  229.0\n",
      "fbs         1.0    0.0    0.0\n",
      "restecg     2.0    2.0    2.0\n",
      "thalach   150.0  108.0  129.0\n",
      "exang       0.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "slope       2.0    1.0    1.0\n",
      "ca          0.0    3.0    2.0\n",
      "thal        2.0    1.0    3.0\n",
      "target      0.0    1.0    1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets after preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159229f-e4d9-4664-8d8f-e1580b957da5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d69b4881-6507-4e0d-97c5-f4669664b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain = df_A.drop('target', axis=1) \n",
    "y_pretrain = df_A['target']               \n",
    "\n",
    "# Split the source domain into 80% train and 20% temp (for val+test)\n",
    "X_pretrain_train, X_pretrain_temp, y_pretrain_train, y_pretrain_temp = train_test_split(\n",
    "    X_pretrain, y_pretrain,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test)\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test → each 10% of total\n",
    "X_pretrain_val, X_pretrain_test, y_pretrain_val, y_pretrain_test = train_test_split(\n",
    "    X_pretrain_temp, y_pretrain_temp,\n",
    "    test_size=0.5,          # half of temp = 10% of total\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain_temp\n",
    ")\n",
    "\n",
    "# Target domain: Cleveland dataset for FINE-TUNING and evaluation\n",
    "X_finetune = df_B.drop('target', axis=1)\n",
    "y_finetune = df_B['target']\n",
    "\n",
    "\n",
    "# Split target domain into 80% train and 20% temp (for val+test)\n",
    "X_finetune_train, X_finetune_temp, y_finetune_train, y_finetune_temp = train_test_split(\n",
    "    X_finetune, y_finetune,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test) \n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune     # preserve class distribution\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test → each 10% of total\n",
    "X_finetune_val, X_finetune_test, y_finetune_val, y_finetune_test = train_test_split(\n",
    "    X_finetune_temp, y_finetune_temp,\n",
    "    test_size=0.5,          # 20% of training data will be used as the validation set\n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune_temp  # preserve class distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969b614-5aed-4a91-8584-7309764272e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Feature selection(Only to training subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b6b773-fed8-4de1-ba04-349f3ad7de80",
   "metadata": {},
   "source": [
    "What to Look For:\n",
    "\n",
    "Similar Feature Correlations: If the correlations between the target variable and the features are similar in both datasets, that suggests that the features carry similar predictive power in both datasets. This means that the pre-trained model could transfer knowledge effectively to the Cleveland dataset during fine-tuning.\n",
    "\n",
    "Discrepant Feature Correlations: If the correlations are significantly different between the two datasets, it may indicate that the relationship between the features and the target is dataset-specific, which could make transfer learning less effective. For example, a feature with a strong correlation with the target in Dataset A but weak or no correlation in Dataset B may not transfer well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269983ef-ad21-408e-afb9-74fd3ea78539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation (Source domain – training only):\n",
      "cp          0.507301\n",
      "ca          0.498332\n",
      "exang       0.463155\n",
      "slope       0.453537\n",
      "thal        0.446200\n",
      "oldpeak     0.377454\n",
      "thalach     0.368993\n",
      "age         0.348638\n",
      "sex         0.320523\n",
      "chol        0.268397\n",
      "fbs         0.154707\n",
      "trestbps    0.147888\n",
      "restecg     0.045622\n",
      "Name: target, dtype: float64\n",
      "Correlation (Target domain – training only):\n",
      "thal        0.541295\n",
      "ca          0.447965\n",
      "exang       0.420280\n",
      "thalach     0.409475\n",
      "cp          0.400620\n",
      "oldpeak     0.392151\n",
      "slope       0.323349\n",
      "sex         0.308342\n",
      "age         0.209664\n",
      "restecg     0.160363\n",
      "trestbps    0.136085\n",
      "chol        0.077191\n",
      "fbs         0.045889\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Combine resampled training features and target\n",
    "df_pretrain_fs = X_pretrain_train.copy()\n",
    "df_pretrain_fs[\"target\"] = y_pretrain_train.values\n",
    "\n",
    "# Correlation with target (absolute value)\n",
    "corr_A = (df_pretrain_fs.corr()[\"target\"].drop(\"target\").abs().sort_values(ascending=False))\n",
    "\n",
    "print(\"Correlation (Source domain – training only):\")\n",
    "print(corr_A)\n",
    "\n",
    "df_finetune_fs = X_finetune_train.copy()\n",
    "df_finetune_fs[\"target\"] = y_finetune_train.values\n",
    "\n",
    "corr_B = (df_finetune_fs.corr()[\"target\"].drop(\"target\").abs().sort_values(ascending=False))\n",
    "\n",
    "print(\"Correlation (Target domain – training only):\")\n",
    "print(corr_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df2c792b-75b2-47e3-aab3-59eefc90386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features (training-only): ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n"
     ]
    }
   ],
   "source": [
    "# Compute *signed* correlations\n",
    "corr_A = (df_pretrain_fs.corr()[\"target\"].drop(\"target\").abs().sort_values(ascending=False))\n",
    "corr_B = (df_finetune_fs.corr()[\"target\"].drop(\"target\").abs().sort_values(ascending=False))\n",
    "\n",
    "\n",
    "corr_diff_threshold = 0.1\n",
    "high_corr_threshold = 0.3\n",
    "\n",
    "similar_features = []\n",
    "\n",
    "# Consistency across domains\n",
    "for feature in corr_A.index:\n",
    "    if feature in corr_B.index:\n",
    "        diff = abs(corr_A[feature] - corr_B[feature])\n",
    "        if diff < corr_diff_threshold:\n",
    "            similar_features.append(feature)\n",
    "\n",
    "# Strong predictors in either domain\n",
    "for feature in set(corr_A.index).union(corr_B.index):\n",
    "    if feature in corr_A.index and abs(corr_A[feature]) >= high_corr_threshold:\n",
    "        similar_features.append(feature)\n",
    "    if feature in corr_B.index and abs(corr_B[feature]) >= high_corr_threshold:\n",
    "        similar_features.append(feature)\n",
    "\n",
    "similar_features = list(set(similar_features))\n",
    "\n",
    "print(\"Selected features (training-only):\", similar_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d14002f9-41d8-42b8-9f68-c653ca92d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature mask to all datasets\n",
    "\n",
    "# Source domain\n",
    "X_pretrain_train = X_pretrain_train[similar_features]\n",
    "X_pretrain_val   = X_pretrain_val[similar_features]\n",
    "X_pretrain_test  = X_pretrain_test[similar_features]\n",
    "\n",
    "# Target domain\n",
    "X_finetune_train = X_finetune_train[similar_features]\n",
    "X_finetune_val   = X_finetune_val[similar_features]\n",
    "X_finetune_test  = X_finetune_test[similar_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b54ddb-166b-44e6-bb0a-3ea5fdf1a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source train features: ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n",
      "Source val features:   ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n",
      "Source test features:  ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n",
      "Target train features: ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n",
      "Target val features:   ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n",
      "Target test features:  ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n"
     ]
    }
   ],
   "source": [
    "print(\"Source train features:\", X_pretrain_train.columns.tolist())\n",
    "print(\"Source val features:  \", X_pretrain_val.columns.tolist())\n",
    "print(\"Source test features: \", X_pretrain_test.columns.tolist())\n",
    "\n",
    "print(\"Target train features:\", X_finetune_train.columns.tolist())\n",
    "print(\"Target val features:  \", X_finetune_val.columns.tolist())\n",
    "print(\"Target test features: \", X_finetune_test.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daf8d3d3-ed35-433e-a0d5-b4e4eaf71968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source train shape: (492, 10)\n",
      "Source val shape:   (61, 10)\n",
      "Source test shape:  (62, 10)\n",
      "Target train shape: (242, 10)\n",
      "Target val shape:   (30, 10)\n",
      "Target test shape:  (31, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source train shape:\", X_pretrain_train.shape)\n",
    "print(\"Source val shape:  \", X_pretrain_val.shape)\n",
    "print(\"Source test shape: \", X_pretrain_test.shape)\n",
    "\n",
    "print(\"Target train shape:\", X_finetune_train.shape)\n",
    "print(\"Target val shape:  \", X_finetune_val.shape)\n",
    "print(\"Target test shape: \", X_finetune_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21018af5-37a7-4e67-878e-39dfb70cb439",
   "metadata": {},
   "source": [
    "## 5. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a6b5e-ed72-44d9-afb4-d1c9a756ceb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c54eed7-39a9-4f06-b602-a9d87b20ce50",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dba63425-db18-4657-a165-ae6c1274011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13824 candidates, totalling 69120 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 1.5],\n",
    "}\n",
    "\n",
    "# Create XGBoost with balanced class weight\n",
    "xgb_pretrain_base = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50,\n",
    "    n_jobs=1,                 # single-threaded = deterministic\n",
    "    scale_pos_weight=1\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_pretrain_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=1,                 # ALSO single-threaded\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(\n",
    "    X_pretrain_train,\n",
    "    y_pretrain_train,\n",
    "    eval_set=[(X_pretrain_val, y_pretrain_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Use best estimator \n",
    "xgb_pretrain_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92489723-5656-47ea-b9bd-ad1951e3e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for pretraining: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 200, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
      "Best F1-score: 0.8965\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBest parameters for pretraining: {grid_search.best_params_}\")\n",
    "print(f\"Best F1-score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# UPDATED\n",
    "# Best parameters for pretraining: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100,\n",
    "#                                   'reg_alpha': 0, 'reg_lambda': 0.5, 'subsample': 0.8}\n",
    "# Best F1-score: 0.8994"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6c852-ebe7-41bf-a42d-43da34fc8e2a",
   "metadata": {},
   "source": [
    "#### Pre-training on the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb972dad-3d65-4aa5-9a35-17ef70094585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best parameters found during the Grid Search for pretraining on Dataset A......DO NOT RUN THIS CODE IF YOU DO HYPERPARAMETER TUNING\n",
    "best_pretrain_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 0.5, \n",
    "    'subsample': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ff71334-005f-4c43-85e7-ad7ef8d86ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.01\n",
      "  max_depth: 8\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 0.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.68962\n",
      "[1]\tvalidation_0-logloss:0.68509\n",
      "[2]\tvalidation_0-logloss:0.68114\n",
      "[3]\tvalidation_0-logloss:0.67682\n",
      "[4]\tvalidation_0-logloss:0.67239\n",
      "[5]\tvalidation_0-logloss:0.66902\n",
      "[6]\tvalidation_0-logloss:0.66489\n",
      "[7]\tvalidation_0-logloss:0.66074\n",
      "[8]\tvalidation_0-logloss:0.65727\n",
      "[9]\tvalidation_0-logloss:0.65349\n",
      "[10]\tvalidation_0-logloss:0.64910\n",
      "[11]\tvalidation_0-logloss:0.64457\n",
      "[12]\tvalidation_0-logloss:0.64099\n",
      "[13]\tvalidation_0-logloss:0.63783\n",
      "[14]\tvalidation_0-logloss:0.63401\n",
      "[15]\tvalidation_0-logloss:0.63069\n",
      "[16]\tvalidation_0-logloss:0.62735\n",
      "[17]\tvalidation_0-logloss:0.62396\n",
      "[18]\tvalidation_0-logloss:0.62049\n",
      "[19]\tvalidation_0-logloss:0.61672\n",
      "[20]\tvalidation_0-logloss:0.61361\n",
      "[21]\tvalidation_0-logloss:0.61123\n",
      "[22]\tvalidation_0-logloss:0.60757\n",
      "[23]\tvalidation_0-logloss:0.60468\n",
      "[24]\tvalidation_0-logloss:0.60166\n",
      "[25]\tvalidation_0-logloss:0.59836\n",
      "[26]\tvalidation_0-logloss:0.59571\n",
      "[27]\tvalidation_0-logloss:0.59241\n",
      "[28]\tvalidation_0-logloss:0.59012\n",
      "[29]\tvalidation_0-logloss:0.58731\n",
      "[30]\tvalidation_0-logloss:0.58469\n",
      "[31]\tvalidation_0-logloss:0.58194\n",
      "[32]\tvalidation_0-logloss:0.57916\n",
      "[33]\tvalidation_0-logloss:0.57642\n",
      "[34]\tvalidation_0-logloss:0.57369\n",
      "[35]\tvalidation_0-logloss:0.57082\n",
      "[36]\tvalidation_0-logloss:0.56811\n",
      "[37]\tvalidation_0-logloss:0.56509\n",
      "[38]\tvalidation_0-logloss:0.56261\n",
      "[39]\tvalidation_0-logloss:0.55991\n",
      "[40]\tvalidation_0-logloss:0.55735\n",
      "[41]\tvalidation_0-logloss:0.55482\n",
      "[42]\tvalidation_0-logloss:0.55323\n",
      "[43]\tvalidation_0-logloss:0.55112\n",
      "[44]\tvalidation_0-logloss:0.54887\n",
      "[45]\tvalidation_0-logloss:0.54704\n",
      "[46]\tvalidation_0-logloss:0.54499\n",
      "[47]\tvalidation_0-logloss:0.54306\n",
      "[48]\tvalidation_0-logloss:0.54112\n",
      "[49]\tvalidation_0-logloss:0.53850\n",
      "[50]\tvalidation_0-logloss:0.53663\n",
      "[51]\tvalidation_0-logloss:0.53425\n",
      "[52]\tvalidation_0-logloss:0.53203\n",
      "[53]\tvalidation_0-logloss:0.52991\n",
      "[54]\tvalidation_0-logloss:0.52794\n",
      "[55]\tvalidation_0-logloss:0.52623\n",
      "[56]\tvalidation_0-logloss:0.52426\n",
      "[57]\tvalidation_0-logloss:0.52253\n",
      "[58]\tvalidation_0-logloss:0.52044\n",
      "[59]\tvalidation_0-logloss:0.51848\n",
      "[60]\tvalidation_0-logloss:0.51684\n",
      "[61]\tvalidation_0-logloss:0.51456\n",
      "[62]\tvalidation_0-logloss:0.51305\n",
      "[63]\tvalidation_0-logloss:0.51142\n",
      "[64]\tvalidation_0-logloss:0.50971\n",
      "[65]\tvalidation_0-logloss:0.50772\n",
      "[66]\tvalidation_0-logloss:0.50669\n",
      "[67]\tvalidation_0-logloss:0.50526\n",
      "[68]\tvalidation_0-logloss:0.50375\n",
      "[69]\tvalidation_0-logloss:0.50268\n",
      "[70]\tvalidation_0-logloss:0.50059\n",
      "[71]\tvalidation_0-logloss:0.49898\n",
      "[72]\tvalidation_0-logloss:0.49716\n",
      "[73]\tvalidation_0-logloss:0.49536\n",
      "[74]\tvalidation_0-logloss:0.49402\n",
      "[75]\tvalidation_0-logloss:0.49258\n",
      "[76]\tvalidation_0-logloss:0.49137\n",
      "[77]\tvalidation_0-logloss:0.48926\n",
      "[78]\tvalidation_0-logloss:0.48815\n",
      "[79]\tvalidation_0-logloss:0.48679\n",
      "[80]\tvalidation_0-logloss:0.48514\n",
      "[81]\tvalidation_0-logloss:0.48359\n",
      "[82]\tvalidation_0-logloss:0.48226\n",
      "[83]\tvalidation_0-logloss:0.48124\n",
      "[84]\tvalidation_0-logloss:0.48005\n",
      "[85]\tvalidation_0-logloss:0.47890\n",
      "[86]\tvalidation_0-logloss:0.47833\n",
      "[87]\tvalidation_0-logloss:0.47714\n",
      "[88]\tvalidation_0-logloss:0.47613\n",
      "[89]\tvalidation_0-logloss:0.47511\n",
      "[90]\tvalidation_0-logloss:0.47395\n",
      "[91]\tvalidation_0-logloss:0.47249\n",
      "[92]\tvalidation_0-logloss:0.47169\n",
      "[93]\tvalidation_0-logloss:0.47087\n",
      "[94]\tvalidation_0-logloss:0.47000\n",
      "[95]\tvalidation_0-logloss:0.46881\n",
      "[96]\tvalidation_0-logloss:0.46754\n",
      "[97]\tvalidation_0-logloss:0.46648\n",
      "[98]\tvalidation_0-logloss:0.46593\n",
      "[99]\tvalidation_0-logloss:0.46420\n",
      "[100]\tvalidation_0-logloss:0.46373\n",
      "[101]\tvalidation_0-logloss:0.46273\n",
      "[102]\tvalidation_0-logloss:0.46164\n",
      "[103]\tvalidation_0-logloss:0.46132\n",
      "[104]\tvalidation_0-logloss:0.46070\n",
      "[105]\tvalidation_0-logloss:0.45985\n",
      "[106]\tvalidation_0-logloss:0.45901\n",
      "[107]\tvalidation_0-logloss:0.45797\n",
      "[108]\tvalidation_0-logloss:0.45739\n",
      "[109]\tvalidation_0-logloss:0.45666\n",
      "[110]\tvalidation_0-logloss:0.45560\n",
      "[111]\tvalidation_0-logloss:0.45471\n",
      "[112]\tvalidation_0-logloss:0.45390\n",
      "[113]\tvalidation_0-logloss:0.45335\n",
      "[114]\tvalidation_0-logloss:0.45253\n",
      "[115]\tvalidation_0-logloss:0.45126\n",
      "[116]\tvalidation_0-logloss:0.45065\n",
      "[117]\tvalidation_0-logloss:0.45009\n",
      "[118]\tvalidation_0-logloss:0.44902\n",
      "[119]\tvalidation_0-logloss:0.44828\n",
      "[120]\tvalidation_0-logloss:0.44775\n",
      "[121]\tvalidation_0-logloss:0.44691\n",
      "[122]\tvalidation_0-logloss:0.44623\n",
      "[123]\tvalidation_0-logloss:0.44536\n",
      "[124]\tvalidation_0-logloss:0.44501\n",
      "[125]\tvalidation_0-logloss:0.44431\n",
      "[126]\tvalidation_0-logloss:0.44342\n",
      "[127]\tvalidation_0-logloss:0.44299\n",
      "[128]\tvalidation_0-logloss:0.44258\n",
      "[129]\tvalidation_0-logloss:0.44139\n",
      "[130]\tvalidation_0-logloss:0.44073\n",
      "[131]\tvalidation_0-logloss:0.43956\n",
      "[132]\tvalidation_0-logloss:0.43908\n",
      "[133]\tvalidation_0-logloss:0.43831\n",
      "[134]\tvalidation_0-logloss:0.43794\n",
      "[135]\tvalidation_0-logloss:0.43738\n",
      "[136]\tvalidation_0-logloss:0.43720\n",
      "[137]\tvalidation_0-logloss:0.43674\n",
      "[138]\tvalidation_0-logloss:0.43580\n",
      "[139]\tvalidation_0-logloss:0.43527\n",
      "[140]\tvalidation_0-logloss:0.43514\n",
      "[141]\tvalidation_0-logloss:0.43450\n",
      "[142]\tvalidation_0-logloss:0.43417\n",
      "[143]\tvalidation_0-logloss:0.43356\n",
      "[144]\tvalidation_0-logloss:0.43259\n",
      "[145]\tvalidation_0-logloss:0.43204\n",
      "[146]\tvalidation_0-logloss:0.43123\n",
      "[147]\tvalidation_0-logloss:0.43108\n",
      "[148]\tvalidation_0-logloss:0.43029\n",
      "[149]\tvalidation_0-logloss:0.42973\n",
      "[150]\tvalidation_0-logloss:0.42953\n",
      "[151]\tvalidation_0-logloss:0.42830\n",
      "[152]\tvalidation_0-logloss:0.42785\n",
      "[153]\tvalidation_0-logloss:0.42733\n",
      "[154]\tvalidation_0-logloss:0.42696\n",
      "[155]\tvalidation_0-logloss:0.42642\n",
      "[156]\tvalidation_0-logloss:0.42545\n",
      "[157]\tvalidation_0-logloss:0.42475\n",
      "[158]\tvalidation_0-logloss:0.42437\n",
      "[159]\tvalidation_0-logloss:0.42424\n",
      "[160]\tvalidation_0-logloss:0.42347\n",
      "[161]\tvalidation_0-logloss:0.42290\n",
      "[162]\tvalidation_0-logloss:0.42229\n",
      "[163]\tvalidation_0-logloss:0.42212\n",
      "[164]\tvalidation_0-logloss:0.42175\n",
      "[165]\tvalidation_0-logloss:0.42140\n",
      "[166]\tvalidation_0-logloss:0.42115\n",
      "[167]\tvalidation_0-logloss:0.42053\n",
      "[168]\tvalidation_0-logloss:0.42022\n",
      "[169]\tvalidation_0-logloss:0.41973\n",
      "[170]\tvalidation_0-logloss:0.41983\n",
      "[171]\tvalidation_0-logloss:0.41978\n",
      "[172]\tvalidation_0-logloss:0.41928\n",
      "[173]\tvalidation_0-logloss:0.41902\n",
      "[174]\tvalidation_0-logloss:0.41857\n",
      "[175]\tvalidation_0-logloss:0.41854\n",
      "[176]\tvalidation_0-logloss:0.41845\n",
      "[177]\tvalidation_0-logloss:0.41816\n",
      "[178]\tvalidation_0-logloss:0.41793\n",
      "[179]\tvalidation_0-logloss:0.41738\n",
      "[180]\tvalidation_0-logloss:0.41717\n",
      "[181]\tvalidation_0-logloss:0.41659\n",
      "[182]\tvalidation_0-logloss:0.41656\n",
      "[183]\tvalidation_0-logloss:0.41626\n",
      "[184]\tvalidation_0-logloss:0.41587\n",
      "[185]\tvalidation_0-logloss:0.41536\n",
      "[186]\tvalidation_0-logloss:0.41512\n",
      "[187]\tvalidation_0-logloss:0.41515\n",
      "[188]\tvalidation_0-logloss:0.41497\n",
      "[189]\tvalidation_0-logloss:0.41467\n",
      "[190]\tvalidation_0-logloss:0.41457\n",
      "[191]\tvalidation_0-logloss:0.41462\n",
      "[192]\tvalidation_0-logloss:0.41429\n",
      "[193]\tvalidation_0-logloss:0.41405\n",
      "[194]\tvalidation_0-logloss:0.41440\n",
      "[195]\tvalidation_0-logloss:0.41410\n",
      "[196]\tvalidation_0-logloss:0.41427\n",
      "[197]\tvalidation_0-logloss:0.41402\n",
      "[198]\tvalidation_0-logloss:0.41402\n",
      "[199]\tvalidation_0-logloss:0.41422\n",
      "[200]\tvalidation_0-logloss:0.41407\n",
      "[201]\tvalidation_0-logloss:0.41400\n",
      "[202]\tvalidation_0-logloss:0.41381\n",
      "[203]\tvalidation_0-logloss:0.41377\n",
      "[204]\tvalidation_0-logloss:0.41358\n",
      "[205]\tvalidation_0-logloss:0.41335\n",
      "[206]\tvalidation_0-logloss:0.41305\n",
      "[207]\tvalidation_0-logloss:0.41277\n",
      "[208]\tvalidation_0-logloss:0.41275\n",
      "[209]\tvalidation_0-logloss:0.41236\n",
      "[210]\tvalidation_0-logloss:0.41264\n",
      "[211]\tvalidation_0-logloss:0.41244\n",
      "[212]\tvalidation_0-logloss:0.41274\n",
      "[213]\tvalidation_0-logloss:0.41255\n",
      "[214]\tvalidation_0-logloss:0.41212\n",
      "[215]\tvalidation_0-logloss:0.41161\n",
      "[216]\tvalidation_0-logloss:0.41191\n",
      "[217]\tvalidation_0-logloss:0.41150\n",
      "[218]\tvalidation_0-logloss:0.41104\n",
      "[219]\tvalidation_0-logloss:0.41079\n",
      "[220]\tvalidation_0-logloss:0.41107\n",
      "[221]\tvalidation_0-logloss:0.41059\n",
      "[222]\tvalidation_0-logloss:0.41017\n",
      "[223]\tvalidation_0-logloss:0.41008\n",
      "[224]\tvalidation_0-logloss:0.40993\n",
      "[225]\tvalidation_0-logloss:0.40995\n",
      "[226]\tvalidation_0-logloss:0.41016\n",
      "[227]\tvalidation_0-logloss:0.40994\n",
      "[228]\tvalidation_0-logloss:0.41010\n",
      "[229]\tvalidation_0-logloss:0.40999\n",
      "[230]\tvalidation_0-logloss:0.40961\n",
      "[231]\tvalidation_0-logloss:0.40935\n",
      "[232]\tvalidation_0-logloss:0.40889\n",
      "[233]\tvalidation_0-logloss:0.40839\n",
      "[234]\tvalidation_0-logloss:0.40825\n",
      "[235]\tvalidation_0-logloss:0.40806\n",
      "[236]\tvalidation_0-logloss:0.40805\n",
      "[237]\tvalidation_0-logloss:0.40769\n",
      "[238]\tvalidation_0-logloss:0.40765\n",
      "[239]\tvalidation_0-logloss:0.40758\n",
      "[240]\tvalidation_0-logloss:0.40709\n",
      "[241]\tvalidation_0-logloss:0.40742\n",
      "[242]\tvalidation_0-logloss:0.40774\n",
      "[243]\tvalidation_0-logloss:0.40763\n",
      "[244]\tvalidation_0-logloss:0.40762\n",
      "[245]\tvalidation_0-logloss:0.40736\n",
      "[246]\tvalidation_0-logloss:0.40706\n",
      "[247]\tvalidation_0-logloss:0.40711\n",
      "[248]\tvalidation_0-logloss:0.40707\n",
      "[249]\tvalidation_0-logloss:0.40753\n",
      "[250]\tvalidation_0-logloss:0.40729\n",
      "[251]\tvalidation_0-logloss:0.40697\n",
      "[252]\tvalidation_0-logloss:0.40632\n",
      "[253]\tvalidation_0-logloss:0.40568\n",
      "[254]\tvalidation_0-logloss:0.40587\n",
      "[255]\tvalidation_0-logloss:0.40524\n",
      "[256]\tvalidation_0-logloss:0.40536\n",
      "[257]\tvalidation_0-logloss:0.40557\n",
      "[258]\tvalidation_0-logloss:0.40588\n",
      "[259]\tvalidation_0-logloss:0.40584\n",
      "[260]\tvalidation_0-logloss:0.40586\n",
      "[261]\tvalidation_0-logloss:0.40606\n",
      "[262]\tvalidation_0-logloss:0.40594\n",
      "[263]\tvalidation_0-logloss:0.40530\n",
      "[264]\tvalidation_0-logloss:0.40543\n",
      "[265]\tvalidation_0-logloss:0.40510\n",
      "[266]\tvalidation_0-logloss:0.40506\n",
      "[267]\tvalidation_0-logloss:0.40470\n",
      "[268]\tvalidation_0-logloss:0.40476\n",
      "[269]\tvalidation_0-logloss:0.40509\n",
      "[270]\tvalidation_0-logloss:0.40448\n",
      "[271]\tvalidation_0-logloss:0.40455\n",
      "[272]\tvalidation_0-logloss:0.40418\n",
      "[273]\tvalidation_0-logloss:0.40439\n",
      "[274]\tvalidation_0-logloss:0.40423\n",
      "[275]\tvalidation_0-logloss:0.40383\n",
      "[276]\tvalidation_0-logloss:0.40400\n",
      "[277]\tvalidation_0-logloss:0.40411\n",
      "[278]\tvalidation_0-logloss:0.40448\n",
      "[279]\tvalidation_0-logloss:0.40439\n",
      "[280]\tvalidation_0-logloss:0.40418\n",
      "[281]\tvalidation_0-logloss:0.40381\n",
      "[282]\tvalidation_0-logloss:0.40370\n",
      "[283]\tvalidation_0-logloss:0.40365\n",
      "[284]\tvalidation_0-logloss:0.40357\n",
      "[285]\tvalidation_0-logloss:0.40354\n",
      "[286]\tvalidation_0-logloss:0.40344\n",
      "[287]\tvalidation_0-logloss:0.40355\n",
      "[288]\tvalidation_0-logloss:0.40374\n",
      "[289]\tvalidation_0-logloss:0.40389\n",
      "[290]\tvalidation_0-logloss:0.40413\n",
      "[291]\tvalidation_0-logloss:0.40394\n",
      "[292]\tvalidation_0-logloss:0.40384\n",
      "[293]\tvalidation_0-logloss:0.40402\n",
      "[294]\tvalidation_0-logloss:0.40406\n",
      "[295]\tvalidation_0-logloss:0.40439\n",
      "[296]\tvalidation_0-logloss:0.40424\n",
      "[297]\tvalidation_0-logloss:0.40451\n",
      "[298]\tvalidation_0-logloss:0.40460\n",
      "[299]\tvalidation_0-logloss:0.40425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters....UNCOMMENT THE LINE BELOW IF YOU DO HYPERPARAMETER TUNING\n",
    "# best_pretrain_params = grid_search.best_params_\n",
    "\n",
    "for param, value in best_pretrain_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create and train fresh model\n",
    "xgb_pretrain = xgb.XGBClassifier(\n",
    "    **best_pretrain_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,   \n",
    "    early_stopping_rounds=50,\n",
    "    n_jobs=1             \n",
    ")\n",
    "\n",
    "xgb_pretrain.fit(\n",
    "    X_pretrain_train,\n",
    "    y_pretrain_train,\n",
    "    eval_set=[(X_pretrain_val, y_pretrain_val)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0502320a-0a6e-4474-9a85-d5ba30124a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Test Accuracy on Source domain: 85.48%\n",
      "Pretraining Test F1 on Source domain: 88.31%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 91.89%\n",
      "Pretraining Test Specificity on Source domain: 76.00%\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED MODEL EVALUATION ON A-TEST\n",
    "Dataset_A_Pretrain = xgb_pretrain.predict(X_pretrain_test)\n",
    "\n",
    "#Calculate and print metrics on source domain's test set\n",
    "Dataset_A_Pretrain_acc = accuracy_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "Dataset_A_Pretrain_f1  = f1_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "\n",
    "cm_A = confusion_matrix(y_pretrain_test, Dataset_A_Pretrain)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A.ravel()\n",
    "\n",
    "\n",
    "recall_A = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A = TN_A / (TN_A + FP_A) * 100\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {Dataset_A_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {Dataset_A_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_A:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_A:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6f04989-11e6-4193-a3b7-c9861654f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Accuracy on target domain's test Set: 74.19%\n",
      "Pretraining F1 on target domain's test Set: 75.00%\n",
      "Pretraining Recall (Sensitivity) on target domain's test Set: 85.71%\n",
      "Pretraining Specificity on target domain's test Set: 64.71%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain = xgb_pretrain.predict(X_finetune_test)\n",
    "\n",
    "#Calculate and print metrics on target domain's test set\n",
    "Dataset_B_Pretrain_acc = accuracy_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "Dataset_B_Pretrain_f1 = f1_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "cm_B = confusion_matrix(y_finetune_test, Dataset_B_Pretrain)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B.ravel()\n",
    "recall_B = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pretraining Accuracy on target domain's test Set: {Dataset_B_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining F1 on target domain's test Set: {Dataset_B_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Recall (Sensitivity) on target domain's test Set: {recall_B:.2f}%\")\n",
    "print(f\"Pretraining Specificity on target domain's test Set: {specificity_B:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdaffd-5589-4825-a70c-53c2d7f5562f",
   "metadata": {},
   "source": [
    "### Finetuning on the target domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df4b914-0793-49bf-b37f-67c6d1bb0d17",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96e0a3b5-8fdb-4dfc-9d3f-fe59371e9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2916 candidates, totalling 14580 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid_finetune = {\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.001, 0.01, 0.05],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0.5, 1, 1.5],\n",
    "}\n",
    "\n",
    "xgb_finetune_best = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50,\n",
    "    n_jobs=1,\n",
    "    scale_pos_weight=1\n",
    ")\n",
    "\n",
    "grid_search_finetune = GridSearchCV(\n",
    "    estimator=xgb_finetune_best,\n",
    "    param_grid=param_grid_finetune,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "grid_search_finetune.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train,\n",
    "    eval_set=[(X_finetune_val, y_finetune_val)],\n",
    "    xgb_model=xgb_pretrain.get_booster(),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "xgb_finetune_best = grid_search_finetune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "311dca56-7e0e-48d6-8236-04c2869cebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for finetuning: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
      "Best F1-score: 0.8216\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nBest parameters for finetuning: {grid_search_finetune.best_params_}\")\n",
    "print(f\"Best F1-score: {grid_search_finetune.best_score_:.4f}\")\n",
    "\n",
    "# Best parameters for finetuning: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 4, \n",
    "#                                  'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
    "# Best F1-score: 0.8231"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd9fd0-9783-40e5-a383-59bb35b59f47",
   "metadata": {},
   "source": [
    "#### Finetuning on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bddce10f-fb66-44ac-8ecf-754a03f87809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DO NOT THE LINE CODE BELOW IF YOU DO HYPERPARAMETER TUNING\n",
    "best_finetune_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.009,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 1.5, \n",
    "    'subsample': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc73f4df-52f0-45e6-b742-9ada28c944aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.009\n",
      "  max_depth: 6\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 1.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.31364\n",
      "[1]\tvalidation_0-logloss:0.31171\n",
      "[2]\tvalidation_0-logloss:0.31046\n",
      "[3]\tvalidation_0-logloss:0.30874\n",
      "[4]\tvalidation_0-logloss:0.30726\n",
      "[5]\tvalidation_0-logloss:0.30543\n",
      "[6]\tvalidation_0-logloss:0.30367\n",
      "[7]\tvalidation_0-logloss:0.30296\n",
      "[8]\tvalidation_0-logloss:0.30126\n",
      "[9]\tvalidation_0-logloss:0.30033\n",
      "[10]\tvalidation_0-logloss:0.29865\n",
      "[11]\tvalidation_0-logloss:0.29749\n",
      "[12]\tvalidation_0-logloss:0.29669\n",
      "[13]\tvalidation_0-logloss:0.29564\n",
      "[14]\tvalidation_0-logloss:0.29440\n",
      "[15]\tvalidation_0-logloss:0.29289\n",
      "[16]\tvalidation_0-logloss:0.29135\n",
      "[17]\tvalidation_0-logloss:0.29038\n",
      "[18]\tvalidation_0-logloss:0.28935\n",
      "[19]\tvalidation_0-logloss:0.28867\n",
      "[20]\tvalidation_0-logloss:0.28775\n",
      "[21]\tvalidation_0-logloss:0.28648\n",
      "[22]\tvalidation_0-logloss:0.28564\n",
      "[23]\tvalidation_0-logloss:0.28466\n",
      "[24]\tvalidation_0-logloss:0.28360\n",
      "[25]\tvalidation_0-logloss:0.28297\n",
      "[26]\tvalidation_0-logloss:0.28250\n",
      "[27]\tvalidation_0-logloss:0.28132\n",
      "[28]\tvalidation_0-logloss:0.28076\n",
      "[29]\tvalidation_0-logloss:0.28022\n",
      "[30]\tvalidation_0-logloss:0.27933\n",
      "[31]\tvalidation_0-logloss:0.27807\n",
      "[32]\tvalidation_0-logloss:0.27706\n",
      "[33]\tvalidation_0-logloss:0.27598\n",
      "[34]\tvalidation_0-logloss:0.27486\n",
      "[35]\tvalidation_0-logloss:0.27414\n",
      "[36]\tvalidation_0-logloss:0.27295\n",
      "[37]\tvalidation_0-logloss:0.27224\n",
      "[38]\tvalidation_0-logloss:0.27110\n",
      "[39]\tvalidation_0-logloss:0.27006\n",
      "[40]\tvalidation_0-logloss:0.26940\n",
      "[41]\tvalidation_0-logloss:0.26854\n",
      "[42]\tvalidation_0-logloss:0.26798\n",
      "[43]\tvalidation_0-logloss:0.26710\n",
      "[44]\tvalidation_0-logloss:0.26645\n",
      "[45]\tvalidation_0-logloss:0.26565\n",
      "[46]\tvalidation_0-logloss:0.26511\n",
      "[47]\tvalidation_0-logloss:0.26410\n",
      "[48]\tvalidation_0-logloss:0.26305\n",
      "[49]\tvalidation_0-logloss:0.26238\n",
      "[50]\tvalidation_0-logloss:0.26186\n",
      "[51]\tvalidation_0-logloss:0.26117\n",
      "[52]\tvalidation_0-logloss:0.26065\n",
      "[53]\tvalidation_0-logloss:0.25993\n",
      "[54]\tvalidation_0-logloss:0.25933\n",
      "[55]\tvalidation_0-logloss:0.25880\n",
      "[56]\tvalidation_0-logloss:0.25814\n",
      "[57]\tvalidation_0-logloss:0.25772\n",
      "[58]\tvalidation_0-logloss:0.25726\n",
      "[59]\tvalidation_0-logloss:0.25692\n",
      "[60]\tvalidation_0-logloss:0.25605\n",
      "[61]\tvalidation_0-logloss:0.25576\n",
      "[62]\tvalidation_0-logloss:0.25496\n",
      "[63]\tvalidation_0-logloss:0.25420\n",
      "[64]\tvalidation_0-logloss:0.25362\n",
      "[65]\tvalidation_0-logloss:0.25308\n",
      "[66]\tvalidation_0-logloss:0.25256\n",
      "[67]\tvalidation_0-logloss:0.25187\n",
      "[68]\tvalidation_0-logloss:0.25105\n",
      "[69]\tvalidation_0-logloss:0.25044\n",
      "[70]\tvalidation_0-logloss:0.24958\n",
      "[71]\tvalidation_0-logloss:0.24897\n",
      "[72]\tvalidation_0-logloss:0.24826\n",
      "[73]\tvalidation_0-logloss:0.24792\n",
      "[74]\tvalidation_0-logloss:0.24779\n",
      "[75]\tvalidation_0-logloss:0.24708\n",
      "[76]\tvalidation_0-logloss:0.24664\n",
      "[77]\tvalidation_0-logloss:0.24610\n",
      "[78]\tvalidation_0-logloss:0.24554\n",
      "[79]\tvalidation_0-logloss:0.24464\n",
      "[80]\tvalidation_0-logloss:0.24409\n",
      "[81]\tvalidation_0-logloss:0.24364\n",
      "[82]\tvalidation_0-logloss:0.24329\n",
      "[83]\tvalidation_0-logloss:0.24278\n",
      "[84]\tvalidation_0-logloss:0.24285\n",
      "[85]\tvalidation_0-logloss:0.24237\n",
      "[86]\tvalidation_0-logloss:0.24164\n",
      "[87]\tvalidation_0-logloss:0.24092\n",
      "[88]\tvalidation_0-logloss:0.24054\n",
      "[89]\tvalidation_0-logloss:0.24051\n",
      "[90]\tvalidation_0-logloss:0.23980\n",
      "[91]\tvalidation_0-logloss:0.23948\n",
      "[92]\tvalidation_0-logloss:0.23886\n",
      "[93]\tvalidation_0-logloss:0.23882\n",
      "[94]\tvalidation_0-logloss:0.23864\n",
      "[95]\tvalidation_0-logloss:0.23789\n",
      "[96]\tvalidation_0-logloss:0.23754\n",
      "[97]\tvalidation_0-logloss:0.23684\n",
      "[98]\tvalidation_0-logloss:0.23682\n",
      "[99]\tvalidation_0-logloss:0.23636\n",
      "[100]\tvalidation_0-logloss:0.23638\n",
      "[101]\tvalidation_0-logloss:0.23606\n",
      "[102]\tvalidation_0-logloss:0.23558\n",
      "[103]\tvalidation_0-logloss:0.23523\n",
      "[104]\tvalidation_0-logloss:0.23523\n",
      "[105]\tvalidation_0-logloss:0.23487\n",
      "[106]\tvalidation_0-logloss:0.23456\n",
      "[107]\tvalidation_0-logloss:0.23390\n",
      "[108]\tvalidation_0-logloss:0.23397\n",
      "[109]\tvalidation_0-logloss:0.23370\n",
      "[110]\tvalidation_0-logloss:0.23380\n",
      "[111]\tvalidation_0-logloss:0.23388\n",
      "[112]\tvalidation_0-logloss:0.23381\n",
      "[113]\tvalidation_0-logloss:0.23366\n",
      "[114]\tvalidation_0-logloss:0.23321\n",
      "[115]\tvalidation_0-logloss:0.23309\n",
      "[116]\tvalidation_0-logloss:0.23255\n",
      "[117]\tvalidation_0-logloss:0.23237\n",
      "[118]\tvalidation_0-logloss:0.23229\n",
      "[119]\tvalidation_0-logloss:0.23163\n",
      "[120]\tvalidation_0-logloss:0.23119\n",
      "[121]\tvalidation_0-logloss:0.23092\n",
      "[122]\tvalidation_0-logloss:0.23036\n",
      "[123]\tvalidation_0-logloss:0.23034\n",
      "[124]\tvalidation_0-logloss:0.23023\n",
      "[125]\tvalidation_0-logloss:0.22991\n",
      "[126]\tvalidation_0-logloss:0.22966\n",
      "[127]\tvalidation_0-logloss:0.22928\n",
      "[128]\tvalidation_0-logloss:0.22923\n",
      "[129]\tvalidation_0-logloss:0.22861\n",
      "[130]\tvalidation_0-logloss:0.22850\n",
      "[131]\tvalidation_0-logloss:0.22812\n",
      "[132]\tvalidation_0-logloss:0.22788\n",
      "[133]\tvalidation_0-logloss:0.22745\n",
      "[134]\tvalidation_0-logloss:0.22748\n",
      "[135]\tvalidation_0-logloss:0.22718\n",
      "[136]\tvalidation_0-logloss:0.22663\n",
      "[137]\tvalidation_0-logloss:0.22634\n",
      "[138]\tvalidation_0-logloss:0.22605\n",
      "[139]\tvalidation_0-logloss:0.22586\n",
      "[140]\tvalidation_0-logloss:0.22536\n",
      "[141]\tvalidation_0-logloss:0.22514\n",
      "[142]\tvalidation_0-logloss:0.22466\n",
      "[143]\tvalidation_0-logloss:0.22482\n",
      "[144]\tvalidation_0-logloss:0.22456\n",
      "[145]\tvalidation_0-logloss:0.22440\n",
      "[146]\tvalidation_0-logloss:0.22420\n",
      "[147]\tvalidation_0-logloss:0.22371\n",
      "[148]\tvalidation_0-logloss:0.22392\n",
      "[149]\tvalidation_0-logloss:0.22392\n",
      "[150]\tvalidation_0-logloss:0.22379\n",
      "[151]\tvalidation_0-logloss:0.22382\n",
      "[152]\tvalidation_0-logloss:0.22372\n",
      "[153]\tvalidation_0-logloss:0.22317\n",
      "[154]\tvalidation_0-logloss:0.22289\n",
      "[155]\tvalidation_0-logloss:0.22254\n",
      "[156]\tvalidation_0-logloss:0.22236\n",
      "[157]\tvalidation_0-logloss:0.22217\n",
      "[158]\tvalidation_0-logloss:0.22174\n",
      "[159]\tvalidation_0-logloss:0.22152\n",
      "[160]\tvalidation_0-logloss:0.22120\n",
      "[161]\tvalidation_0-logloss:0.22117\n",
      "[162]\tvalidation_0-logloss:0.22081\n",
      "[163]\tvalidation_0-logloss:0.22062\n",
      "[164]\tvalidation_0-logloss:0.22085\n",
      "[165]\tvalidation_0-logloss:0.22066\n",
      "[166]\tvalidation_0-logloss:0.22030\n",
      "[167]\tvalidation_0-logloss:0.21982\n",
      "[168]\tvalidation_0-logloss:0.21955\n",
      "[169]\tvalidation_0-logloss:0.21929\n",
      "[170]\tvalidation_0-logloss:0.21879\n",
      "[171]\tvalidation_0-logloss:0.21858\n",
      "[172]\tvalidation_0-logloss:0.21790\n",
      "[173]\tvalidation_0-logloss:0.21771\n",
      "[174]\tvalidation_0-logloss:0.21738\n",
      "[175]\tvalidation_0-logloss:0.21704\n",
      "[176]\tvalidation_0-logloss:0.21690\n",
      "[177]\tvalidation_0-logloss:0.21651\n",
      "[178]\tvalidation_0-logloss:0.21620\n",
      "[179]\tvalidation_0-logloss:0.21596\n",
      "[180]\tvalidation_0-logloss:0.21568\n",
      "[181]\tvalidation_0-logloss:0.21552\n",
      "[182]\tvalidation_0-logloss:0.21543\n",
      "[183]\tvalidation_0-logloss:0.21516\n",
      "[184]\tvalidation_0-logloss:0.21465\n",
      "[185]\tvalidation_0-logloss:0.21463\n",
      "[186]\tvalidation_0-logloss:0.21455\n",
      "[187]\tvalidation_0-logloss:0.21429\n",
      "[188]\tvalidation_0-logloss:0.21403\n",
      "[189]\tvalidation_0-logloss:0.21404\n",
      "[190]\tvalidation_0-logloss:0.21405\n",
      "[191]\tvalidation_0-logloss:0.21379\n",
      "[192]\tvalidation_0-logloss:0.21378\n",
      "[193]\tvalidation_0-logloss:0.21347\n",
      "[194]\tvalidation_0-logloss:0.21347\n",
      "[195]\tvalidation_0-logloss:0.21331\n",
      "[196]\tvalidation_0-logloss:0.21283\n",
      "[197]\tvalidation_0-logloss:0.21255\n",
      "[198]\tvalidation_0-logloss:0.21232\n",
      "[199]\tvalidation_0-logloss:0.21226\n",
      "[200]\tvalidation_0-logloss:0.21211\n",
      "[201]\tvalidation_0-logloss:0.21222\n",
      "[202]\tvalidation_0-logloss:0.21214\n",
      "[203]\tvalidation_0-logloss:0.21213\n",
      "[204]\tvalidation_0-logloss:0.21193\n",
      "[205]\tvalidation_0-logloss:0.21188\n",
      "[206]\tvalidation_0-logloss:0.21163\n",
      "[207]\tvalidation_0-logloss:0.21140\n",
      "[208]\tvalidation_0-logloss:0.21116\n",
      "[209]\tvalidation_0-logloss:0.21090\n",
      "[210]\tvalidation_0-logloss:0.21074\n",
      "[211]\tvalidation_0-logloss:0.21039\n",
      "[212]\tvalidation_0-logloss:0.21037\n",
      "[213]\tvalidation_0-logloss:0.21008\n",
      "[214]\tvalidation_0-logloss:0.20988\n",
      "[215]\tvalidation_0-logloss:0.21012\n",
      "[216]\tvalidation_0-logloss:0.20973\n",
      "[217]\tvalidation_0-logloss:0.20972\n",
      "[218]\tvalidation_0-logloss:0.20964\n",
      "[219]\tvalidation_0-logloss:0.20954\n",
      "[220]\tvalidation_0-logloss:0.20930\n",
      "[221]\tvalidation_0-logloss:0.20915\n",
      "[222]\tvalidation_0-logloss:0.20874\n",
      "[223]\tvalidation_0-logloss:0.20870\n",
      "[224]\tvalidation_0-logloss:0.20860\n",
      "[225]\tvalidation_0-logloss:0.20801\n",
      "[226]\tvalidation_0-logloss:0.20786\n",
      "[227]\tvalidation_0-logloss:0.20779\n",
      "[228]\tvalidation_0-logloss:0.20753\n",
      "[229]\tvalidation_0-logloss:0.20740\n",
      "[230]\tvalidation_0-logloss:0.20690\n",
      "[231]\tvalidation_0-logloss:0.20681\n",
      "[232]\tvalidation_0-logloss:0.20680\n",
      "[233]\tvalidation_0-logloss:0.20656\n",
      "[234]\tvalidation_0-logloss:0.20648\n",
      "[235]\tvalidation_0-logloss:0.20632\n",
      "[236]\tvalidation_0-logloss:0.20623\n",
      "[237]\tvalidation_0-logloss:0.20621\n",
      "[238]\tvalidation_0-logloss:0.20621\n",
      "[239]\tvalidation_0-logloss:0.20643\n",
      "[240]\tvalidation_0-logloss:0.20649\n",
      "[241]\tvalidation_0-logloss:0.20638\n",
      "[242]\tvalidation_0-logloss:0.20627\n",
      "[243]\tvalidation_0-logloss:0.20576\n",
      "[244]\tvalidation_0-logloss:0.20560\n",
      "[245]\tvalidation_0-logloss:0.20543\n",
      "[246]\tvalidation_0-logloss:0.20516\n",
      "[247]\tvalidation_0-logloss:0.20464\n",
      "[248]\tvalidation_0-logloss:0.20428\n",
      "[249]\tvalidation_0-logloss:0.20416\n",
      "[250]\tvalidation_0-logloss:0.20407\n",
      "[251]\tvalidation_0-logloss:0.20425\n",
      "[252]\tvalidation_0-logloss:0.20380\n",
      "[253]\tvalidation_0-logloss:0.20361\n",
      "[254]\tvalidation_0-logloss:0.20340\n",
      "[255]\tvalidation_0-logloss:0.20296\n",
      "[256]\tvalidation_0-logloss:0.20246\n",
      "[257]\tvalidation_0-logloss:0.20268\n",
      "[258]\tvalidation_0-logloss:0.20254\n",
      "[259]\tvalidation_0-logloss:0.20238\n",
      "[260]\tvalidation_0-logloss:0.20223\n",
      "[261]\tvalidation_0-logloss:0.20180\n",
      "[262]\tvalidation_0-logloss:0.20122\n",
      "[263]\tvalidation_0-logloss:0.20086\n",
      "[264]\tvalidation_0-logloss:0.20072\n",
      "[265]\tvalidation_0-logloss:0.20052\n",
      "[266]\tvalidation_0-logloss:0.20003\n",
      "[267]\tvalidation_0-logloss:0.20013\n",
      "[268]\tvalidation_0-logloss:0.20030\n",
      "[269]\tvalidation_0-logloss:0.20022\n",
      "[270]\tvalidation_0-logloss:0.20031\n",
      "[271]\tvalidation_0-logloss:0.20008\n",
      "[272]\tvalidation_0-logloss:0.20000\n",
      "[273]\tvalidation_0-logloss:0.20022\n",
      "[274]\tvalidation_0-logloss:0.20007\n",
      "[275]\tvalidation_0-logloss:0.19983\n",
      "[276]\tvalidation_0-logloss:0.19975\n",
      "[277]\tvalidation_0-logloss:0.19946\n",
      "[278]\tvalidation_0-logloss:0.19953\n",
      "[279]\tvalidation_0-logloss:0.19963\n",
      "[280]\tvalidation_0-logloss:0.19950\n",
      "[281]\tvalidation_0-logloss:0.19939\n",
      "[282]\tvalidation_0-logloss:0.19944\n",
      "[283]\tvalidation_0-logloss:0.19929\n",
      "[284]\tvalidation_0-logloss:0.19929\n",
      "[285]\tvalidation_0-logloss:0.19941\n",
      "[286]\tvalidation_0-logloss:0.19934\n",
      "[287]\tvalidation_0-logloss:0.19925\n",
      "[288]\tvalidation_0-logloss:0.19922\n",
      "[289]\tvalidation_0-logloss:0.19865\n",
      "[290]\tvalidation_0-logloss:0.19848\n",
      "[291]\tvalidation_0-logloss:0.19821\n",
      "[292]\tvalidation_0-logloss:0.19848\n",
      "[293]\tvalidation_0-logloss:0.19836\n",
      "[294]\tvalidation_0-logloss:0.19821\n",
      "[295]\tvalidation_0-logloss:0.19819\n",
      "[296]\tvalidation_0-logloss:0.19808\n",
      "[297]\tvalidation_0-logloss:0.19794\n",
      "[298]\tvalidation_0-logloss:0.19797\n",
      "[299]\tvalidation_0-logloss:0.19763\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters from fine-tuning grid search......UNCOMMENT THE LINE BELOW IF YOU DO HYPERPARAMETER TUNING\n",
    "# best_finetune_params = grid_search_finetune.best_params_\n",
    "\n",
    "for param, value in best_finetune_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "xgb_finetune = xgb.XGBClassifier(\n",
    "    **best_finetune_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "xgb_finetune.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train, \n",
    "    eval_set=[(X_finetune_val, y_finetune_val)], \n",
    "    xgb_model=xgb_pretrain.get_booster(),\n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b386de1-f1cb-4ba2-ad3c-dd10c4138c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test Accuracy on Source domain: 80.65%\n",
      "Fine-Tuning Test F1 on Source domain: 84.62%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Source domain: 89.19%\n",
      "Fine-Tuning Test Specificity on Source domain: 68.00%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON A-TEST (Checking for Catastrophic Forgetting)\n",
    "Dataset_A_Finetune = xgb_finetune.predict(X_pretrain_test) # Using the fine-tuned model on A's test set\n",
    "\n",
    "# Calculate and print metrics on source domain's test set\n",
    "acc_A_Finetune = accuracy_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "f1_A_Finetune = f1_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "\n",
    "cm_A_Finetune = confusion_matrix(y_pretrain_test, Dataset_A_Finetune)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune.ravel()\n",
    "\n",
    "recall_A_Finetune = TP_A_F / (TP_A_F + FN_A_F) * 100\n",
    "specificity_A_Finetune = TN_A_F / (TN_A_F + FP_A_F) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test Accuracy on Source domain: {acc_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Source domain: {f1_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Source domain: {recall_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Source domain: {specificity_A_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afac6e80-0424-49c3-abc1-27ce75b57a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test ROC-AUC on Target domain (B): 85.29%\n",
      "Fine-Tuning Test Accuracy on Target domain (B): 83.87%\n",
      "Fine-Tuning Test F1 on Target domain (B): 84.85%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Target domain (B): 100.00%\n",
      "Fine-Tuning Test Specificity on Target domain (B): 70.59%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON B-TEST (Final Transfer Learning Performance)\n",
    "Dataset_B_Finetune = xgb_finetune.predict(X_finetune_test) # Using the fine-tuned model on B's test set\n",
    "\n",
    "# Calculate and print metrics on target domain's test set\n",
    "acc_B_Finetune = accuracy_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1_B_Finetune = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "cm_B_Finetune = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "TN_B_F, FP_B_F, FN_B_F, TP_B_F = cm_B_Finetune.ravel()\n",
    "\n",
    "recall_B_Finetune = TP_B_F / (TP_B_F + FN_B_F) * 100\n",
    "specificity_B_Finetune = TN_B_F / (TN_B_F + FP_B_F) * 100\n",
    "roc_auc_B_Finetune = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test ROC-AUC on Target domain (B): {roc_auc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Accuracy on Target domain (B): {acc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Target domain (B): {f1_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Target domain (B): {recall_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Target domain (B): {specificity_B_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aba10ea4-ab9b-4d57-914a-c4f843778d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "# plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Assuming y_finetune_test and Dataset_B_Finetune are already defined\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.invert_yaxis()  # You can uncomment this if you want to invert the Y-axis\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        # Set the text in Times New Roman\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c790849-940f-44e0-b416-6e65f4e90ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 82.35%\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "recall = recall_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1 = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate') # Changed back to match the image axis label\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a481e-9936-409b-972e-3021ab1952b7",
   "metadata": {},
   "source": [
    "### XGBoost with no Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44636e68-a03d-4dca-ae99-4163c450919b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.68921\n",
      "[1]\tvalidation_0-logloss:0.68507\n",
      "[2]\tvalidation_0-logloss:0.68126\n",
      "[3]\tvalidation_0-logloss:0.67732\n",
      "[4]\tvalidation_0-logloss:0.67260\n",
      "[5]\tvalidation_0-logloss:0.66873\n",
      "[6]\tvalidation_0-logloss:0.66405\n",
      "[7]\tvalidation_0-logloss:0.65966\n",
      "[8]\tvalidation_0-logloss:0.65562\n",
      "[9]\tvalidation_0-logloss:0.65204\n",
      "[10]\tvalidation_0-logloss:0.64815\n",
      "[11]\tvalidation_0-logloss:0.64398\n",
      "[12]\tvalidation_0-logloss:0.64027\n",
      "[13]\tvalidation_0-logloss:0.63645\n",
      "[14]\tvalidation_0-logloss:0.63237\n",
      "[15]\tvalidation_0-logloss:0.62943\n",
      "[16]\tvalidation_0-logloss:0.62584\n",
      "[17]\tvalidation_0-logloss:0.62310\n",
      "[18]\tvalidation_0-logloss:0.61913\n",
      "[19]\tvalidation_0-logloss:0.61560\n",
      "[20]\tvalidation_0-logloss:0.61218\n",
      "[21]\tvalidation_0-logloss:0.60934\n",
      "[22]\tvalidation_0-logloss:0.60605\n",
      "[23]\tvalidation_0-logloss:0.60343\n",
      "[24]\tvalidation_0-logloss:0.60043\n",
      "[25]\tvalidation_0-logloss:0.59687\n",
      "[26]\tvalidation_0-logloss:0.59372\n",
      "[27]\tvalidation_0-logloss:0.59036\n",
      "[28]\tvalidation_0-logloss:0.58756\n",
      "[29]\tvalidation_0-logloss:0.58452\n",
      "[30]\tvalidation_0-logloss:0.58149\n",
      "[31]\tvalidation_0-logloss:0.57854\n",
      "[32]\tvalidation_0-logloss:0.57535\n",
      "[33]\tvalidation_0-logloss:0.57228\n",
      "[34]\tvalidation_0-logloss:0.56890\n",
      "[35]\tvalidation_0-logloss:0.56590\n",
      "[36]\tvalidation_0-logloss:0.56372\n",
      "[37]\tvalidation_0-logloss:0.56057\n",
      "[38]\tvalidation_0-logloss:0.55727\n",
      "[39]\tvalidation_0-logloss:0.55458\n",
      "[40]\tvalidation_0-logloss:0.55232\n",
      "[41]\tvalidation_0-logloss:0.54947\n",
      "[42]\tvalidation_0-logloss:0.54766\n",
      "[43]\tvalidation_0-logloss:0.54499\n",
      "[44]\tvalidation_0-logloss:0.54195\n",
      "[45]\tvalidation_0-logloss:0.53931\n",
      "[46]\tvalidation_0-logloss:0.53610\n",
      "[47]\tvalidation_0-logloss:0.53368\n",
      "[48]\tvalidation_0-logloss:0.53113\n",
      "[49]\tvalidation_0-logloss:0.52881\n",
      "[50]\tvalidation_0-logloss:0.52644\n",
      "[51]\tvalidation_0-logloss:0.52385\n",
      "[52]\tvalidation_0-logloss:0.52155\n",
      "[53]\tvalidation_0-logloss:0.51925\n",
      "[54]\tvalidation_0-logloss:0.51676\n",
      "[55]\tvalidation_0-logloss:0.51455\n",
      "[56]\tvalidation_0-logloss:0.51233\n",
      "[57]\tvalidation_0-logloss:0.51004\n",
      "[58]\tvalidation_0-logloss:0.50824\n",
      "[59]\tvalidation_0-logloss:0.50640\n",
      "[60]\tvalidation_0-logloss:0.50481\n",
      "[61]\tvalidation_0-logloss:0.50236\n",
      "[62]\tvalidation_0-logloss:0.49988\n",
      "[63]\tvalidation_0-logloss:0.49870\n",
      "[64]\tvalidation_0-logloss:0.49643\n",
      "[65]\tvalidation_0-logloss:0.49447\n",
      "[66]\tvalidation_0-logloss:0.49284\n",
      "[67]\tvalidation_0-logloss:0.49029\n",
      "[68]\tvalidation_0-logloss:0.48833\n",
      "[69]\tvalidation_0-logloss:0.48670\n",
      "[70]\tvalidation_0-logloss:0.48475\n",
      "[71]\tvalidation_0-logloss:0.48286\n",
      "[72]\tvalidation_0-logloss:0.48104\n",
      "[73]\tvalidation_0-logloss:0.47897\n",
      "[74]\tvalidation_0-logloss:0.47701\n",
      "[75]\tvalidation_0-logloss:0.47504\n",
      "[76]\tvalidation_0-logloss:0.47401\n",
      "[77]\tvalidation_0-logloss:0.47232\n",
      "[78]\tvalidation_0-logloss:0.47108\n",
      "[79]\tvalidation_0-logloss:0.46899\n",
      "[80]\tvalidation_0-logloss:0.46678\n",
      "[81]\tvalidation_0-logloss:0.46456\n",
      "[82]\tvalidation_0-logloss:0.46259\n",
      "[83]\tvalidation_0-logloss:0.46062\n",
      "[84]\tvalidation_0-logloss:0.45914\n",
      "[85]\tvalidation_0-logloss:0.45756\n",
      "[86]\tvalidation_0-logloss:0.45648\n",
      "[87]\tvalidation_0-logloss:0.45477\n",
      "[88]\tvalidation_0-logloss:0.45305\n",
      "[89]\tvalidation_0-logloss:0.45136\n",
      "[90]\tvalidation_0-logloss:0.44969\n",
      "[91]\tvalidation_0-logloss:0.44772\n",
      "[92]\tvalidation_0-logloss:0.44635\n",
      "[93]\tvalidation_0-logloss:0.44501\n",
      "[94]\tvalidation_0-logloss:0.44305\n",
      "[95]\tvalidation_0-logloss:0.44120\n",
      "[96]\tvalidation_0-logloss:0.43942\n",
      "[97]\tvalidation_0-logloss:0.43809\n",
      "[98]\tvalidation_0-logloss:0.43659\n",
      "[99]\tvalidation_0-logloss:0.43490\n",
      "[100]\tvalidation_0-logloss:0.43320\n",
      "[101]\tvalidation_0-logloss:0.43184\n",
      "[102]\tvalidation_0-logloss:0.42999\n",
      "[103]\tvalidation_0-logloss:0.42836\n",
      "[104]\tvalidation_0-logloss:0.42704\n",
      "[105]\tvalidation_0-logloss:0.42535\n",
      "[106]\tvalidation_0-logloss:0.42391\n",
      "[107]\tvalidation_0-logloss:0.42226\n",
      "[108]\tvalidation_0-logloss:0.42123\n",
      "[109]\tvalidation_0-logloss:0.41971\n",
      "[110]\tvalidation_0-logloss:0.41809\n",
      "[111]\tvalidation_0-logloss:0.41657\n",
      "[112]\tvalidation_0-logloss:0.41485\n",
      "[113]\tvalidation_0-logloss:0.41368\n",
      "[114]\tvalidation_0-logloss:0.41185\n",
      "[115]\tvalidation_0-logloss:0.41031\n",
      "[116]\tvalidation_0-logloss:0.40852\n",
      "[117]\tvalidation_0-logloss:0.40665\n",
      "[118]\tvalidation_0-logloss:0.40499\n",
      "[119]\tvalidation_0-logloss:0.40347\n",
      "[120]\tvalidation_0-logloss:0.40207\n",
      "[121]\tvalidation_0-logloss:0.40097\n",
      "[122]\tvalidation_0-logloss:0.39931\n",
      "[123]\tvalidation_0-logloss:0.39789\n",
      "[124]\tvalidation_0-logloss:0.39698\n",
      "[125]\tvalidation_0-logloss:0.39555\n",
      "[126]\tvalidation_0-logloss:0.39394\n",
      "[127]\tvalidation_0-logloss:0.39255\n",
      "[128]\tvalidation_0-logloss:0.39121\n",
      "[129]\tvalidation_0-logloss:0.39002\n",
      "[130]\tvalidation_0-logloss:0.38862\n",
      "[131]\tvalidation_0-logloss:0.38746\n",
      "[132]\tvalidation_0-logloss:0.38641\n",
      "[133]\tvalidation_0-logloss:0.38570\n",
      "[134]\tvalidation_0-logloss:0.38413\n",
      "[135]\tvalidation_0-logloss:0.38278\n",
      "[136]\tvalidation_0-logloss:0.38211\n",
      "[137]\tvalidation_0-logloss:0.38087\n",
      "[138]\tvalidation_0-logloss:0.37964\n",
      "[139]\tvalidation_0-logloss:0.37837\n",
      "[140]\tvalidation_0-logloss:0.37709\n",
      "[141]\tvalidation_0-logloss:0.37581\n",
      "[142]\tvalidation_0-logloss:0.37485\n",
      "[143]\tvalidation_0-logloss:0.37360\n",
      "[144]\tvalidation_0-logloss:0.37281\n",
      "[145]\tvalidation_0-logloss:0.37164\n",
      "[146]\tvalidation_0-logloss:0.37025\n",
      "[147]\tvalidation_0-logloss:0.36906\n",
      "[148]\tvalidation_0-logloss:0.36769\n",
      "[149]\tvalidation_0-logloss:0.36660\n",
      "[150]\tvalidation_0-logloss:0.36547\n",
      "[151]\tvalidation_0-logloss:0.36404\n",
      "[152]\tvalidation_0-logloss:0.36302\n",
      "[153]\tvalidation_0-logloss:0.36178\n",
      "[154]\tvalidation_0-logloss:0.36071\n",
      "[155]\tvalidation_0-logloss:0.35929\n",
      "[156]\tvalidation_0-logloss:0.35829\n",
      "[157]\tvalidation_0-logloss:0.35713\n",
      "[158]\tvalidation_0-logloss:0.35584\n",
      "[159]\tvalidation_0-logloss:0.35445\n",
      "[160]\tvalidation_0-logloss:0.35316\n",
      "[161]\tvalidation_0-logloss:0.35202\n",
      "[162]\tvalidation_0-logloss:0.35086\n",
      "[163]\tvalidation_0-logloss:0.34989\n",
      "[164]\tvalidation_0-logloss:0.34862\n",
      "[165]\tvalidation_0-logloss:0.34738\n",
      "[166]\tvalidation_0-logloss:0.34686\n",
      "[167]\tvalidation_0-logloss:0.34619\n",
      "[168]\tvalidation_0-logloss:0.34506\n",
      "[169]\tvalidation_0-logloss:0.34416\n",
      "[170]\tvalidation_0-logloss:0.34360\n",
      "[171]\tvalidation_0-logloss:0.34298\n",
      "[172]\tvalidation_0-logloss:0.34204\n",
      "[173]\tvalidation_0-logloss:0.34143\n",
      "[174]\tvalidation_0-logloss:0.34033\n",
      "[175]\tvalidation_0-logloss:0.33972\n",
      "[176]\tvalidation_0-logloss:0.33861\n",
      "[177]\tvalidation_0-logloss:0.33751\n",
      "[178]\tvalidation_0-logloss:0.33670\n",
      "[179]\tvalidation_0-logloss:0.33561\n",
      "[180]\tvalidation_0-logloss:0.33456\n",
      "[181]\tvalidation_0-logloss:0.33330\n",
      "[182]\tvalidation_0-logloss:0.33273\n",
      "[183]\tvalidation_0-logloss:0.33199\n",
      "[184]\tvalidation_0-logloss:0.33099\n",
      "[185]\tvalidation_0-logloss:0.33021\n",
      "[186]\tvalidation_0-logloss:0.32922\n",
      "[187]\tvalidation_0-logloss:0.32832\n",
      "[188]\tvalidation_0-logloss:0.32756\n",
      "[189]\tvalidation_0-logloss:0.32662\n",
      "[190]\tvalidation_0-logloss:0.32553\n",
      "[191]\tvalidation_0-logloss:0.32474\n",
      "[192]\tvalidation_0-logloss:0.32380\n",
      "[193]\tvalidation_0-logloss:0.32312\n",
      "[194]\tvalidation_0-logloss:0.32264\n",
      "[195]\tvalidation_0-logloss:0.32195\n",
      "[196]\tvalidation_0-logloss:0.32128\n",
      "[197]\tvalidation_0-logloss:0.32077\n",
      "[198]\tvalidation_0-logloss:0.32028\n",
      "[199]\tvalidation_0-logloss:0.31924\n",
      "[200]\tvalidation_0-logloss:0.31891\n",
      "[201]\tvalidation_0-logloss:0.31810\n",
      "[202]\tvalidation_0-logloss:0.31731\n",
      "[203]\tvalidation_0-logloss:0.31636\n",
      "[204]\tvalidation_0-logloss:0.31573\n",
      "[205]\tvalidation_0-logloss:0.31495\n",
      "[206]\tvalidation_0-logloss:0.31429\n",
      "[207]\tvalidation_0-logloss:0.31356\n",
      "[208]\tvalidation_0-logloss:0.31281\n",
      "[209]\tvalidation_0-logloss:0.31216\n",
      "[210]\tvalidation_0-logloss:0.31158\n",
      "[211]\tvalidation_0-logloss:0.31066\n",
      "[212]\tvalidation_0-logloss:0.31030\n",
      "[213]\tvalidation_0-logloss:0.30984\n",
      "[214]\tvalidation_0-logloss:0.30923\n",
      "[215]\tvalidation_0-logloss:0.30871\n",
      "[216]\tvalidation_0-logloss:0.30855\n",
      "[217]\tvalidation_0-logloss:0.30813\n",
      "[218]\tvalidation_0-logloss:0.30753\n",
      "[219]\tvalidation_0-logloss:0.30680\n",
      "[220]\tvalidation_0-logloss:0.30615\n",
      "[221]\tvalidation_0-logloss:0.30544\n",
      "[222]\tvalidation_0-logloss:0.30453\n",
      "[223]\tvalidation_0-logloss:0.30377\n",
      "[224]\tvalidation_0-logloss:0.30320\n",
      "[225]\tvalidation_0-logloss:0.30239\n",
      "[226]\tvalidation_0-logloss:0.30192\n",
      "[227]\tvalidation_0-logloss:0.30140\n",
      "[228]\tvalidation_0-logloss:0.30110\n",
      "[229]\tvalidation_0-logloss:0.30041\n",
      "[230]\tvalidation_0-logloss:0.29980\n",
      "[231]\tvalidation_0-logloss:0.29916\n",
      "[232]\tvalidation_0-logloss:0.29867\n",
      "[233]\tvalidation_0-logloss:0.29809\n",
      "[234]\tvalidation_0-logloss:0.29741\n",
      "[235]\tvalidation_0-logloss:0.29670\n",
      "[236]\tvalidation_0-logloss:0.29581\n",
      "[237]\tvalidation_0-logloss:0.29524\n",
      "[238]\tvalidation_0-logloss:0.29487\n",
      "[239]\tvalidation_0-logloss:0.29434\n",
      "[240]\tvalidation_0-logloss:0.29352\n",
      "[241]\tvalidation_0-logloss:0.29297\n",
      "[242]\tvalidation_0-logloss:0.29242\n",
      "[243]\tvalidation_0-logloss:0.29239\n",
      "[244]\tvalidation_0-logloss:0.29207\n",
      "[245]\tvalidation_0-logloss:0.29156\n",
      "[246]\tvalidation_0-logloss:0.29080\n",
      "[247]\tvalidation_0-logloss:0.29034\n",
      "[248]\tvalidation_0-logloss:0.28981\n",
      "[249]\tvalidation_0-logloss:0.28947\n",
      "[250]\tvalidation_0-logloss:0.28889\n",
      "[251]\tvalidation_0-logloss:0.28813\n",
      "[252]\tvalidation_0-logloss:0.28764\n",
      "[253]\tvalidation_0-logloss:0.28705\n",
      "[254]\tvalidation_0-logloss:0.28673\n",
      "[255]\tvalidation_0-logloss:0.28625\n",
      "[256]\tvalidation_0-logloss:0.28583\n",
      "[257]\tvalidation_0-logloss:0.28544\n",
      "[258]\tvalidation_0-logloss:0.28500\n",
      "[259]\tvalidation_0-logloss:0.28470\n",
      "[260]\tvalidation_0-logloss:0.28426\n",
      "[261]\tvalidation_0-logloss:0.28400\n",
      "[262]\tvalidation_0-logloss:0.28347\n",
      "[263]\tvalidation_0-logloss:0.28290\n",
      "[264]\tvalidation_0-logloss:0.28242\n",
      "[265]\tvalidation_0-logloss:0.28189\n",
      "[266]\tvalidation_0-logloss:0.28128\n",
      "[267]\tvalidation_0-logloss:0.28074\n",
      "[268]\tvalidation_0-logloss:0.28034\n",
      "[269]\tvalidation_0-logloss:0.27980\n",
      "[270]\tvalidation_0-logloss:0.27966\n",
      "[271]\tvalidation_0-logloss:0.27915\n",
      "[272]\tvalidation_0-logloss:0.27860\n",
      "[273]\tvalidation_0-logloss:0.27813\n",
      "[274]\tvalidation_0-logloss:0.27764\n",
      "[275]\tvalidation_0-logloss:0.27694\n",
      "[276]\tvalidation_0-logloss:0.27662\n",
      "[277]\tvalidation_0-logloss:0.27622\n",
      "[278]\tvalidation_0-logloss:0.27580\n",
      "[279]\tvalidation_0-logloss:0.27542\n",
      "[280]\tvalidation_0-logloss:0.27496\n",
      "[281]\tvalidation_0-logloss:0.27448\n",
      "[282]\tvalidation_0-logloss:0.27421\n",
      "[283]\tvalidation_0-logloss:0.27383\n",
      "[284]\tvalidation_0-logloss:0.27351\n",
      "[285]\tvalidation_0-logloss:0.27305\n",
      "[286]\tvalidation_0-logloss:0.27272\n",
      "[287]\tvalidation_0-logloss:0.27234\n",
      "[288]\tvalidation_0-logloss:0.27193\n",
      "[289]\tvalidation_0-logloss:0.27141\n",
      "[290]\tvalidation_0-logloss:0.27100\n",
      "[291]\tvalidation_0-logloss:0.27061\n",
      "[292]\tvalidation_0-logloss:0.27017\n",
      "[293]\tvalidation_0-logloss:0.26990\n",
      "[294]\tvalidation_0-logloss:0.26969\n",
      "[295]\tvalidation_0-logloss:0.26932\n",
      "[296]\tvalidation_0-logloss:0.26909\n",
      "[297]\tvalidation_0-logloss:0.26857\n",
      "[298]\tvalidation_0-logloss:0.26818\n",
      "[299]\tvalidation_0-logloss:0.26777\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=1,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = XGBClassifier(\n",
    "    n_estimators=300,            \n",
    "    max_depth=6,\n",
    "    learning_rate=0.009,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.7,\n",
    "    eval_metric='logloss',\n",
    "    reg_lambda = 1.5,\n",
    "    reg_alpha = 0.1,\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "baseline_model.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train,\n",
    "    eval_set=[(X_finetune_val, y_finetune_val)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bab295b0-00fb-44d5-be89-b0a3367bbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (Dataset B): 83.87%\n",
      "Baseline F1-score (Dataset B): 83.87%\n",
      "Baseline Recall (Sensitivity): 92.86%\n",
      "Baseline Specificity: 76.47%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Dataset B test set\n",
    "y_pred_baseline = baseline_model.predict(X_finetune_test)\n",
    "\n",
    "baseline_acc = accuracy_score(y_finetune_test, y_pred_baseline) * 100\n",
    "baseline_f1  = f1_score(y_finetune_test, y_pred_baseline) * 100\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, y_pred_baseline)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "recall_score_calc = TP / (TP + FN) * 100\n",
    "specificity_score_calc = TN / (TN + FP) * 100\n",
    "\n",
    "\n",
    "print(f\"Baseline Accuracy (Dataset B): {baseline_acc:.2f}%\")\n",
    "print(f\"Baseline F1-score (Dataset B): {baseline_f1:.2f}%\")\n",
    "print(f\"Baseline Recall (Sensitivity): {recall_score_calc:.2f}%\")\n",
    "print(f\"Baseline Specificity: {specificity_score_calc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ada6c-57c4-4083-b15b-4a9f32ce3e7d",
   "metadata": {},
   "source": [
    "## 6. Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88547a09-5369-4f68-9e57-6dbef8030156",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2baf0ab6-9b0b-462b-9157-66d45fdc5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training, validation, and test datasets for the source domain\n",
    "X_A_train = X_pretrain_train.values  # Features for training on the source domain (pre-training phase)\n",
    "y_A_train = y_pretrain_train.values  # Target labels for training on the source domain\n",
    "\n",
    "X_A_val   = X_pretrain_val.values  # Features for validation on the source domain\n",
    "y_A_val   = y_pretrain_val.values  # Target labels for validation on the source domain\n",
    "\n",
    "X_A_test  = X_pretrain_test.values  # Features for testing on the source domain\n",
    "y_A_test  = y_pretrain_test.values  # Target labels for testing on the source domain\n",
    "\n",
    "# Defining the training, validation, and test datasets for the target domain\n",
    "X_B_train = X_finetune_train.values  # Features for training on the target domain (fine-tuning phase)\n",
    "y_B_train = y_finetune_train.values  # Target labels for training on the target domain\n",
    "\n",
    "X_B_val   = X_finetune_val.values  # Features for validation on the target domain\n",
    "y_B_val   = y_finetune_val.values  # Target labels for validation on the target domain\n",
    "\n",
    "X_B_test  = X_finetune_test.values  # Features for testing on the target domain\n",
    "y_B_test  = y_finetune_test.values  # Target labels for testing on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71aa0290-a98b-4f3c-916e-427ebc557794",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_A_train = scaler.fit_transform(X_A_train).astype(np.float32)  # Fit scaler on source train set, transform it\n",
    "X_A_val = scaler.transform(X_A_val).astype(np.float32)          # Transform source validation set\n",
    "X_A_test = scaler.transform(X_A_test).astype(np.float32)        # Transform source test set\n",
    "\n",
    "y_A_train = y_A_train.astype(np.int64)  # Convert source train labels to int64\n",
    "y_A_val = y_A_val.astype(np.int64)      # Convert source validation labels\n",
    "y_A_test = y_A_test.astype(np.int64)    # Convert source test labels\n",
    "\n",
    "X_B_train = scaler.transform(X_B_train).astype(np.float32)      # Apply source-domain scaling to target train set\n",
    "X_B_val = scaler.transform(X_B_val).astype(np.float32)          # Apply scaling to target validation set\n",
    "X_B_test = scaler.transform(X_B_test).astype(np.float32)        # Apply scaling to target test set\n",
    "\n",
    "y_B_train = y_B_train.astype(np.int64)  # Convert target train labels to int64\n",
    "y_B_val = y_B_val.astype(np.int64)      # Convert target validation labels\n",
    "y_B_test = y_B_test.astype(np.int64)    # Convert target test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc3966-a643-4813-bbcb-b8b2e7db60ab",
   "metadata": {},
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40a9a9-1054-4cb1-aec6-bd8211b2d002",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Hyperparameter tuning for Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "feb57e27-1f6c-437d-82c0-853b7eb56ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-29 22:50:19,621] A new study created in memory with name: no-name-bbda8a31-e4aa-4bbd-8bbc-d30a736d7e4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_balanced_accuracy = 0.81588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:50:45,741] Trial 0 finished with value: 0.8235294117647058 and parameters: {'n_d_a': 8, 'n_steps': 10, 'gamma': 1.5213303366613837, 'lambda_sparse': 5.410389733001134e-06, 'lr': 0.01342596619210637, 'momentum': 0.24000000000000002, 'batch_size': 64, 'virtual_batch_size': 32, 'step_size': 80, 'scheduler_gamma': 0.818499861081206}. Best is trial 0 with value: 0.8235294117647058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 results: Accuracy = 0.8033, F1-Score = 0.8235\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 39 and best_val_balanced_accuracy = 0.52083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:51:06,406] Trial 1 finished with value: 0.7628865979381443 and parameters: {'n_d_a': 16, 'n_steps': 6, 'gamma': 1.2169440085479426, 'lambda_sparse': 0.00010244960546271797, 'lr': 1.7637096255912015e-05, 'momentum': 0.17, 'batch_size': 128, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8143267286746101}. Best is trial 0 with value: 0.8235294117647058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 results: Accuracy = 0.6230, F1-Score = 0.7629\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_balanced_accuracy = 0.52196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:51:35,691] Trial 2 finished with value: 0.7391304347826086 and parameters: {'n_d_a': 16, 'n_steps': 9, 'gamma': 1.3772838542029473, 'lambda_sparse': 0.0012147182643342878, 'lr': 4.4391477650325e-05, 'momentum': 0.14, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 20, 'scheduler_gamma': 0.972381929489005}. Best is trial 0 with value: 0.8235294117647058.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 results: Accuracy = 0.6066, F1-Score = 0.7391\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_balanced_accuracy = 0.82095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:51:55,161] Trial 3 finished with value: 0.868421052631579 and parameters: {'n_d_a': 8, 'n_steps': 8, 'gamma': 1.9220570074194403, 'lambda_sparse': 0.00018960152929251446, 'lr': 0.0018429014386945133, 'momentum': 0.31, 'batch_size': 64, 'virtual_batch_size': 32, 'step_size': 20, 'scheduler_gamma': 0.8042307215723511}. Best is trial 3 with value: 0.868421052631579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 results: Accuracy = 0.8361, F1-Score = 0.8684\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_balanced_accuracy = 0.64077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:52:19,574] Trial 4 finished with value: 0.7710843373493976 and parameters: {'n_d_a': 16, 'n_steps': 8, 'gamma': 1.9171355348195878, 'lambda_sparse': 0.0004203641470651379, 'lr': 0.0001039912561129326, 'momentum': 0.13, 'batch_size': 64, 'virtual_batch_size': 32, 'step_size': 40, 'scheduler_gamma': 0.9406610746396492}. Best is trial 3 with value: 0.868421052631579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 results: Accuracy = 0.6885, F1-Score = 0.7711\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_balanced_accuracy = 0.57714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:52:36,389] Trial 5 finished with value: 0.7692307692307693 and parameters: {'n_d_a': 16, 'n_steps': 8, 'gamma': 1.0656518045688657, 'lambda_sparse': 7.166146405054393e-05, 'lr': 2.6190820019582343e-05, 'momentum': 0.11, 'batch_size': 128, 'virtual_batch_size': 32, 'step_size': 80, 'scheduler_gamma': 0.8984430057811911}. Best is trial 3 with value: 0.868421052631579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 results: Accuracy = 0.6557, F1-Score = 0.7692\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_balanced_accuracy = 0.64302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:53:10,358] Trial 6 finished with value: 0.7123287671232876 and parameters: {'n_d_a': 24, 'n_steps': 4, 'gamma': 1.2625119200618897, 'lambda_sparse': 8.104964390129223e-05, 'lr': 6.227907072548271e-05, 'momentum': 0.11, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.9745848890014654}. Best is trial 3 with value: 0.868421052631579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 results: Accuracy = 0.6557, F1-Score = 0.7123\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_balanced_accuracy = 0.84291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:53:20,156] Trial 7 finished with value: 0.8571428571428571 and parameters: {'n_d_a': 16, 'n_steps': 9, 'gamma': 1.713032600489249, 'lambda_sparse': 2.1129961427347326e-06, 'lr': 0.026017830155790147, 'momentum': 0.3, 'batch_size': 128, 'virtual_batch_size': 32, 'step_size': 20, 'scheduler_gamma': 0.8748846634237243}. Best is trial 3 with value: 0.868421052631579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 results: Accuracy = 0.8361, F1-Score = 0.8571\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_balanced_accuracy = 0.49493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:53:32,031] Trial 8 finished with value: 0.7111111111111111 and parameters: {'n_d_a': 8, 'n_steps': 10, 'gamma': 1.2370498443341091, 'lambda_sparse': 4.031704677136463e-05, 'lr': 0.00012576354450521905, 'momentum': 0.03, 'batch_size': 128, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8413542259560896}. Best is trial 3 with value: 0.868421052631579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 results: Accuracy = 0.5738, F1-Score = 0.7111\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_balanced_accuracy = 0.86261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:54:30,260] Trial 9 finished with value: 0.8918918918918919 and parameters: {'n_d_a': 24, 'n_steps': 8, 'gamma': 1.6885600549362636, 'lambda_sparse': 2.8716801056848872e-05, 'lr': 0.010630745765207688, 'momentum': 0.03, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 80, 'scheduler_gamma': 0.9710378005624937}. Best is trial 9 with value: 0.8918918918918919.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 results: Accuracy = 0.8689, F1-Score = 0.8919\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_balanced_accuracy = 0.85529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:55:19,458] Trial 10 finished with value: 0.8947368421052632 and parameters: {'n_d_a': 32, 'n_steps': 6, 'gamma': 1.653956992579569, 'lambda_sparse': 0.0071352940992739445, 'lr': 0.08738079416760637, 'momentum': 0.01, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.9199664752544251}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 results: Accuracy = 0.8689, F1-Score = 0.8947\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_balanced_accuracy = 0.82827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:55:44,880] Trial 11 finished with value: 0.8648648648648649 and parameters: {'n_d_a': 32, 'n_steps': 6, 'gamma': 1.642315121942996, 'lambda_sparse': 0.009822421841518512, 'lr': 0.09345138729220054, 'momentum': 0.01, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.9286832550462242}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 results: Accuracy = 0.8361, F1-Score = 0.8649\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_balanced_accuracy = 0.82939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:56:17,029] Trial 12 finished with value: 0.8405797101449275 and parameters: {'n_d_a': 32, 'n_steps': 6, 'gamma': 1.7264472543313818, 'lambda_sparse': 0.009815277977733744, 'lr': 0.004162291150038078, 'momentum': 0.05, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.9330066911301361}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 results: Accuracy = 0.8197, F1-Score = 0.8406\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_balanced_accuracy = 0.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:56:45,648] Trial 13 finished with value: 0.8767123287671232 and parameters: {'n_d_a': 24, 'n_steps': 4, 'gamma': 1.5658215988402213, 'lambda_sparse': 1.533337572138197e-05, 'lr': 0.0811135327427699, 'momentum': 0.06999999999999999, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9012108693048789}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 results: Accuracy = 0.8525, F1-Score = 0.8767\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_balanced_accuracy = 0.86261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:58:46,094] Trial 14 finished with value: 0.8918918918918919 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.8029000566405253, 'lambda_sparse': 0.001431577558782822, 'lr': 0.011476610065719284, 'momentum': 0.21000000000000002, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9528847015976063}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 results: Accuracy = 0.8689, F1-Score = 0.8919\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_balanced_accuracy = 0.86261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 22:59:41,553] Trial 15 finished with value: 0.8918918918918919 and parameters: {'n_d_a': 24, 'n_steps': 5, 'gamma': 1.4285509288879212, 'lambda_sparse': 1.3373549361967474e-05, 'lr': 0.030643125950367577, 'momentum': 0.38, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 30, 'scheduler_gamma': 0.8697609975218107}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 results: Accuracy = 0.8689, F1-Score = 0.8919\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_balanced_accuracy = 0.82207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:01:52,989] Trial 16 finished with value: 0.8450704225352113 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.9952946042149973, 'lambda_sparse': 0.001894821100149528, 'lr': 0.0006807733619712546, 'momentum': 0.060000000000000005, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.9125637029256918}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 results: Accuracy = 0.8197, F1-Score = 0.8451\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_balanced_accuracy = 0.85642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:03:55,227] Trial 17 finished with value: 0.8732394366197183 and parameters: {'n_d_a': 24, 'n_steps': 5, 'gamma': 1.8080781254654097, 'lambda_sparse': 2.0153132622979908e-05, 'lr': 0.003651351555928336, 'momentum': 0.01, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.9564458604455907}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 results: Accuracy = 0.8525, F1-Score = 0.8732\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_balanced_accuracy = 0.82207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:05:48,475] Trial 18 finished with value: 0.8450704225352113 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.5800332973195446, 'lambda_sparse': 1.2948214118603603e-06, 'lr': 0.00044186008478279214, 'momentum': 0.08, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 30, 'scheduler_gamma': 0.9170202357728412}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 results: Accuracy = 0.8197, F1-Score = 0.8451\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_balanced_accuracy = 0.82207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:06:52,262] Trial 19 finished with value: 0.8450704225352113 and parameters: {'n_d_a': 24, 'n_steps': 9, 'gamma': 1.3893349416284, 'lambda_sparse': 0.00048682957895504356, 'lr': 0.029248975918370217, 'momentum': 0.17, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8790260223663894}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 results: Accuracy = 0.8197, F1-Score = 0.8451\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_balanced_accuracy = 0.82939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:08:03,178] Trial 20 finished with value: 0.8405797101449275 and parameters: {'n_d_a': 32, 'n_steps': 5, 'gamma': 1.6579464069909144, 'lambda_sparse': 4.2174500472724605e-06, 'lr': 0.007369260206584333, 'momentum': 0.24000000000000002, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 30, 'scheduler_gamma': 0.8494739835105347}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 results: Accuracy = 0.8197, F1-Score = 0.8406\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_balanced_accuracy = 0.86261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:09:08,986] Trial 21 finished with value: 0.8918918918918919 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.8187273929128114, 'lambda_sparse': 0.003342339323325052, 'lr': 0.012374050860024573, 'momentum': 0.22, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9524080844627302}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 results: Accuracy = 0.8689, F1-Score = 0.8919\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_balanced_accuracy = 0.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:10:57,880] Trial 22 finished with value: 0.8767123287671232 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.7741755406804633, 'lambda_sparse': 0.003675212293114865, 'lr': 0.050294795347091754, 'momentum': 0.28, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9582341994481751}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 results: Accuracy = 0.8525, F1-Score = 0.8767\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_balanced_accuracy = 0.85642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:12:14,753] Trial 23 finished with value: 0.8732394366197183 and parameters: {'n_d_a': 24, 'n_steps': 6, 'gamma': 1.8636296560320442, 'lambda_sparse': 0.0005133516655906477, 'lr': 0.0017297901427154295, 'momentum': 0.19, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9494454223807756}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23 results: Accuracy = 0.8525, F1-Score = 0.8732\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_balanced_accuracy = 0.82207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:13:36,213] Trial 24 finished with value: 0.8450704225352113 and parameters: {'n_d_a': 32, 'n_steps': 8, 'gamma': 1.6419859742228073, 'lambda_sparse': 0.00433714178241383, 'lr': 0.0074901428387888404, 'momentum': 0.36000000000000004, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.9778694854051286}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 results: Accuracy = 0.8197, F1-Score = 0.8451\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_balanced_accuracy = 0.8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:57:16,828] Trial 25 finished with value: 0.8767123287671232 and parameters: {'n_d_a': 24, 'n_steps': 6, 'gamma': 1.7373038564603938, 'lambda_sparse': 0.0014312062156990168, 'lr': 0.0127026042834243, 'momentum': 0.09, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.9207373774849952}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 results: Accuracy = 0.8525, F1-Score = 0.8767\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_balanced_accuracy = 0.80743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:57:54,457] Trial 26 finished with value: 0.8533333333333334 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.5938083620815644, 'lambda_sparse': 0.00022432731604777229, 'lr': 0.00027639575871573425, 'momentum': 0.15000000000000002, 'batch_size': 32, 'virtual_batch_size': 32, 'step_size': 40, 'scheduler_gamma': 0.940452181097548}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 results: Accuracy = 0.8197, F1-Score = 0.8533\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_balanced_accuracy = 0.83559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:58:55,173] Trial 27 finished with value: 0.8611111111111112 and parameters: {'n_d_a': 24, 'n_steps': 8, 'gamma': 1.4907155075230714, 'lambda_sparse': 0.0008937513535196862, 'lr': 0.0020600050629223368, 'momentum': 0.05, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9637049821325204}. Best is trial 10 with value: 0.8947368421052632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27 results: Accuracy = 0.8361, F1-Score = 0.8611\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_balanced_accuracy = 0.87613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:59:20,799] Trial 28 finished with value: 0.9066666666666666 and parameters: {'n_d_a': 32, 'n_steps': 7, 'gamma': 1.8698558098046372, 'lambda_sparse': 0.005393173126575441, 'lr': 0.04179737727422789, 'momentum': 0.27, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 30, 'scheduler_gamma': 0.9421521438008308}. Best is trial 28 with value: 0.9066666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 results: Accuracy = 0.8852, F1-Score = 0.9067\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_balanced_accuracy = 0.82207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-29 23:59:43,820] Trial 29 finished with value: 0.8450704225352113 and parameters: {'n_d_a': 32, 'n_steps': 10, 'gamma': 1.4776803433276946, 'lambda_sparse': 7.632793437647826e-06, 'lr': 0.05179155526814573, 'momentum': 0.26, 'batch_size': 64, 'virtual_batch_size': 32, 'step_size': 80, 'scheduler_gamma': 0.9052827819153031}. Best is trial 28 with value: 0.9066666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 results: Accuracy = 0.8197, F1-Score = 0.8451\n"
     ]
    }
   ],
   "source": [
    "# Objective function to optimize\n",
    "def objective(trial):\n",
    "# n_d and n_a (often kept equal for simplicity)\n",
    "    n_d_a = trial.suggest_int('n_d_a', 8, 32, step=8) \n",
    "    n_steps = trial.suggest_int('n_steps', 4, 10) \n",
    "    gamma = trial.suggest_float('gamma', 1.0, 2.0)\n",
    "    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-6, 1e-2, log=True)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
    "    momentum = trial.suggest_float('momentum', 0.01, 0.4, step=0.01)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    virtual_batch_size = trial.suggest_categorical('virtual_batch_size', [16, 32])\n",
    "    step_size = trial.suggest_int('step_size', 20, 80, step=10)\n",
    "    scheduler_gamma = trial.suggest_float('scheduler_gamma', 0.8, 0.98)\n",
    "\n",
    "    tabnet_model = TabNetClassifier(\n",
    "        n_d=n_d_a,\n",
    "        n_a=n_d_a,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        momentum=momentum,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params={'lr': lr},\n",
    "        mask_type='sparsemax',\n",
    "        scheduler_params={'step_size': step_size, 'gamma': scheduler_gamma},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        verbose=0, # Crucial to silence output during 50+ trials\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    tabnet_model.fit(\n",
    "        X_train=X_A_train, \n",
    "        y_train=y_A_train, \n",
    "        eval_set=[(X_A_val, y_A_val)], \n",
    "        eval_name=[\"val\"], \n",
    "        # Use a supported metric for early stopping\n",
    "        eval_metric=[\"balanced_accuracy\"], \n",
    "        max_epochs=100, \n",
    "        patience=20, # Reduced patience for faster tuning\n",
    "        batch_size=batch_size, \n",
    "        virtual_batch_size=virtual_batch_size\n",
    "    )\n",
    "    \n",
    "    # Predict and calculate the final metric to maximize\n",
    "    preds = tabnet_model.predict(X_A_val)\n",
    "    f1 = f1_score(y_A_val, preds)\n",
    "\n",
    "    accuracy = accuracy_score(y_A_val, preds)\n",
    "    \n",
    "    # Print the results of the current trial for monitoring\n",
    "    print(f\"Trial {trial.number} results: Accuracy = {accuracy:.4f}, F1-Score = {f1:.4f}\")\n",
    "        \n",
    "    return f1 \n",
    "\n",
    "# --- Run the Optimization ---\n",
    "study_scratch = optuna.create_study(direction='maximize')\n",
    "study_scratch.optimize(objective, n_trials=30) # Recommend a higher trial count for full tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db6e5139-db7e-4c28-8d68-f0005c79e622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pretrain params:\n",
      "  Value (F1-score): 0.9067\n",
      "  Params:\n",
      "    n_d_a: 32\n",
      "    n_steps: 7\n",
      "    gamma: 1.8698558098046372\n",
      "    lambda_sparse: 0.005393173126575441\n",
      "    lr: 0.04179737727422789\n",
      "    momentum: 0.27\n",
      "    batch_size: 64\n",
      "    virtual_batch_size: 16\n",
      "    step_size: 30\n",
      "    scheduler_gamma: 0.9421521438008308\n"
     ]
    }
   ],
   "source": [
    "# Get best trial and parameters\n",
    "best_trial = study_scratch.best_trial\n",
    "best_pretrain_params = best_trial.params\n",
    "\n",
    "print(\"Best pretrain params:\")\n",
    "print(f\"  Value (F1-score): {best_trial.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "\n",
    "for key, value in best_pretrain_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578e93b-d85d-451f-9949-1eb687a6bc80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Pre-training on the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79f43b5b-4246-48f2-bf12-642d16222412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_d_a: 16\n",
      "n_steps: 9\n",
      "gamma: 1.7899467948557366\n",
      "lambda_sparse: 4.387608964907318e-05\n",
      "lr: 0.003074702431245894\n",
      "momentum: 0.22\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 40\n",
      "scheduler_gamma: 0.9464940708357479\n"
     ]
    }
   ],
   "source": [
    "# Define the best parameters found during the Grid Search for pretraining on Dataset A......DO NOT RUN THIS CODE IF YOU DO HYPERPARAMETER TUNING\n",
    "best_pretrain_params = {\n",
    "    \"n_d_a\": 16,\n",
    "    \"n_steps\": 9,\n",
    "    \"gamma\": 1.7899467948557366,\n",
    "    \"lambda_sparse\": 4.387608964907318e-05,\n",
    "    \"lr\": 0.003074702431245894,\n",
    "    \"momentum\": 0.22,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 40,\n",
    "    \"scheduler_gamma\": 0.9464940708357479,\n",
    "}\n",
    "for key, value in best_pretrain_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e6cf23c-94a0-4d00-b5b7-94b8f78973a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.21364 | val_logloss: 1.03659 |  0:00:01s\n",
      "epoch 1  | loss: 0.79312 | val_logloss: 0.87236 |  0:00:03s\n",
      "epoch 2  | loss: 0.65424 | val_logloss: 0.55415 |  0:00:04s\n",
      "epoch 3  | loss: 0.6064  | val_logloss: 0.69821 |  0:00:06s\n",
      "epoch 4  | loss: 0.53383 | val_logloss: 0.55025 |  0:00:08s\n",
      "epoch 5  | loss: 0.4903  | val_logloss: 0.49206 |  0:00:09s\n",
      "epoch 6  | loss: 0.50623 | val_logloss: 0.46262 |  0:00:11s\n",
      "epoch 7  | loss: 0.4663  | val_logloss: 0.53205 |  0:00:13s\n",
      "epoch 8  | loss: 0.46921 | val_logloss: 0.58841 |  0:00:15s\n",
      "epoch 9  | loss: 0.47955 | val_logloss: 0.59093 |  0:00:16s\n",
      "epoch 10 | loss: 0.46567 | val_logloss: 0.53411 |  0:00:18s\n",
      "epoch 11 | loss: 0.42929 | val_logloss: 0.44199 |  0:00:19s\n",
      "epoch 12 | loss: 0.43843 | val_logloss: 0.53864 |  0:00:21s\n",
      "epoch 13 | loss: 0.43684 | val_logloss: 0.48473 |  0:00:22s\n",
      "epoch 14 | loss: 0.40049 | val_logloss: 0.46563 |  0:00:24s\n",
      "epoch 15 | loss: 0.41974 | val_logloss: 0.55322 |  0:00:25s\n",
      "epoch 16 | loss: 0.40758 | val_logloss: 0.42258 |  0:00:27s\n",
      "epoch 17 | loss: 0.37546 | val_logloss: 0.53323 |  0:00:29s\n",
      "epoch 18 | loss: 0.41949 | val_logloss: 0.5033  |  0:00:30s\n",
      "epoch 19 | loss: 0.40517 | val_logloss: 0.53719 |  0:00:32s\n",
      "epoch 20 | loss: 0.38633 | val_logloss: 0.48165 |  0:00:33s\n",
      "epoch 21 | loss: 0.36847 | val_logloss: 0.49956 |  0:00:35s\n",
      "epoch 22 | loss: 0.40491 | val_logloss: 0.45653 |  0:00:37s\n",
      "epoch 23 | loss: 0.40175 | val_logloss: 0.53628 |  0:00:38s\n",
      "epoch 24 | loss: 0.40812 | val_logloss: 0.52744 |  0:00:40s\n",
      "epoch 25 | loss: 0.37205 | val_logloss: 0.49454 |  0:00:41s\n",
      "epoch 26 | loss: 0.42724 | val_logloss: 0.45027 |  0:00:43s\n",
      "epoch 27 | loss: 0.3534  | val_logloss: 0.51327 |  0:00:45s\n",
      "epoch 28 | loss: 0.38214 | val_logloss: 0.60029 |  0:00:46s\n",
      "epoch 29 | loss: 0.43604 | val_logloss: 0.44041 |  0:00:48s\n",
      "epoch 30 | loss: 0.37854 | val_logloss: 0.40392 |  0:00:49s\n",
      "epoch 31 | loss: 0.36674 | val_logloss: 0.42045 |  0:00:51s\n",
      "epoch 32 | loss: 0.41555 | val_logloss: 0.38889 |  0:00:53s\n",
      "epoch 33 | loss: 0.36124 | val_logloss: 0.39741 |  0:00:54s\n",
      "epoch 34 | loss: 0.37411 | val_logloss: 0.48098 |  0:00:56s\n",
      "epoch 35 | loss: 0.38373 | val_logloss: 0.42283 |  0:00:57s\n",
      "epoch 36 | loss: 0.37533 | val_logloss: 0.3955  |  0:00:59s\n",
      "epoch 37 | loss: 0.36249 | val_logloss: 0.64829 |  0:01:01s\n",
      "epoch 38 | loss: 0.37468 | val_logloss: 0.44046 |  0:01:03s\n",
      "epoch 39 | loss: 0.37329 | val_logloss: 0.61148 |  0:01:04s\n",
      "epoch 40 | loss: 0.44057 | val_logloss: 0.46411 |  0:01:06s\n",
      "epoch 41 | loss: 0.34593 | val_logloss: 0.48457 |  0:01:08s\n",
      "epoch 42 | loss: 0.37121 | val_logloss: 0.5053  |  0:01:10s\n",
      "epoch 43 | loss: 0.35215 | val_logloss: 0.46895 |  0:01:12s\n",
      "epoch 44 | loss: 0.34898 | val_logloss: 0.4676  |  0:01:14s\n",
      "epoch 45 | loss: 0.35125 | val_logloss: 0.49337 |  0:01:16s\n",
      "epoch 46 | loss: 0.34718 | val_logloss: 0.44733 |  0:01:17s\n",
      "epoch 47 | loss: 0.33936 | val_logloss: 0.46599 |  0:01:19s\n",
      "epoch 48 | loss: 0.35585 | val_logloss: 0.44051 |  0:01:21s\n",
      "epoch 49 | loss: 0.33832 | val_logloss: 0.45882 |  0:01:23s\n",
      "epoch 50 | loss: 0.37378 | val_logloss: 0.47202 |  0:01:25s\n",
      "epoch 51 | loss: 0.34563 | val_logloss: 0.52779 |  0:01:27s\n",
      "epoch 52 | loss: 0.36071 | val_logloss: 0.47257 |  0:01:28s\n",
      "epoch 53 | loss: 0.35965 | val_logloss: 0.45399 |  0:01:30s\n",
      "epoch 54 | loss: 0.35026 | val_logloss: 0.40842 |  0:01:31s\n",
      "epoch 55 | loss: 0.36428 | val_logloss: 0.52241 |  0:01:33s\n",
      "epoch 56 | loss: 0.36017 | val_logloss: 0.47733 |  0:01:34s\n",
      "epoch 57 | loss: 0.31402 | val_logloss: 0.46098 |  0:01:36s\n",
      "epoch 58 | loss: 0.3391  | val_logloss: 0.40029 |  0:01:37s\n",
      "epoch 59 | loss: 0.34277 | val_logloss: 0.38818 |  0:01:39s\n",
      "epoch 60 | loss: 0.33725 | val_logloss: 0.39439 |  0:01:40s\n",
      "epoch 61 | loss: 0.34463 | val_logloss: 0.43517 |  0:01:42s\n",
      "epoch 62 | loss: 0.375   | val_logloss: 0.45344 |  0:01:43s\n",
      "epoch 63 | loss: 0.34717 | val_logloss: 0.41998 |  0:01:45s\n",
      "epoch 64 | loss: 0.30625 | val_logloss: 0.57424 |  0:01:46s\n",
      "epoch 65 | loss: 0.3322  | val_logloss: 0.45803 |  0:01:48s\n",
      "epoch 66 | loss: 0.3345  | val_logloss: 0.40454 |  0:01:49s\n",
      "epoch 67 | loss: 0.34376 | val_logloss: 0.36115 |  0:01:51s\n",
      "epoch 68 | loss: 0.3169  | val_logloss: 0.4424  |  0:01:52s\n",
      "epoch 69 | loss: 0.3182  | val_logloss: 0.4569  |  0:01:54s\n",
      "epoch 70 | loss: 0.30706 | val_logloss: 0.44153 |  0:01:55s\n",
      "epoch 71 | loss: 0.30564 | val_logloss: 0.4098  |  0:01:57s\n",
      "epoch 72 | loss: 0.29289 | val_logloss: 0.43236 |  0:01:58s\n",
      "epoch 73 | loss: 0.32352 | val_logloss: 0.43008 |  0:02:00s\n",
      "epoch 74 | loss: 0.31261 | val_logloss: 0.41132 |  0:02:02s\n",
      "epoch 75 | loss: 0.31033 | val_logloss: 0.4173  |  0:02:03s\n",
      "epoch 76 | loss: 0.3139  | val_logloss: 0.37414 |  0:02:04s\n",
      "epoch 77 | loss: 0.32519 | val_logloss: 0.39135 |  0:02:06s\n",
      "epoch 78 | loss: 0.29784 | val_logloss: 0.44724 |  0:02:08s\n",
      "epoch 79 | loss: 0.29168 | val_logloss: 0.45871 |  0:02:09s\n",
      "epoch 80 | loss: 0.28412 | val_logloss: 0.42653 |  0:02:11s\n",
      "epoch 81 | loss: 0.2971  | val_logloss: 0.4173  |  0:02:12s\n",
      "epoch 82 | loss: 0.27447 | val_logloss: 0.36715 |  0:02:14s\n",
      "epoch 83 | loss: 0.28735 | val_logloss: 0.3616  |  0:02:15s\n",
      "epoch 84 | loss: 0.31415 | val_logloss: 0.4022  |  0:02:17s\n",
      "epoch 85 | loss: 0.30245 | val_logloss: 0.40624 |  0:02:18s\n",
      "epoch 86 | loss: 0.27899 | val_logloss: 0.43431 |  0:02:19s\n",
      "epoch 87 | loss: 0.31808 | val_logloss: 0.36999 |  0:02:21s\n",
      "epoch 88 | loss: 0.29381 | val_logloss: 0.36118 |  0:02:23s\n",
      "epoch 89 | loss: 0.26261 | val_logloss: 0.37114 |  0:02:24s\n",
      "epoch 90 | loss: 0.26055 | val_logloss: 0.3858  |  0:02:26s\n",
      "epoch 91 | loss: 0.26257 | val_logloss: 0.41009 |  0:02:27s\n",
      "epoch 92 | loss: 0.26964 | val_logloss: 0.37279 |  0:02:29s\n",
      "epoch 93 | loss: 0.28125 | val_logloss: 0.32616 |  0:02:30s\n",
      "epoch 94 | loss: 0.31629 | val_logloss: 0.39561 |  0:02:32s\n",
      "epoch 95 | loss: 0.27685 | val_logloss: 0.40175 |  0:02:33s\n",
      "epoch 96 | loss: 0.26251 | val_logloss: 0.44152 |  0:02:35s\n",
      "epoch 97 | loss: 0.28802 | val_logloss: 0.32493 |  0:02:36s\n",
      "epoch 98 | loss: 0.29367 | val_logloss: 0.32724 |  0:02:38s\n",
      "epoch 99 | loss: 0.27225 | val_logloss: 0.33861 |  0:02:39s\n",
      "epoch 100| loss: 0.27879 | val_logloss: 0.36244 |  0:02:41s\n",
      "epoch 101| loss: 0.272   | val_logloss: 0.40353 |  0:02:42s\n",
      "epoch 102| loss: 0.28283 | val_logloss: 0.39964 |  0:02:44s\n",
      "epoch 103| loss: 0.30847 | val_logloss: 0.36811 |  0:02:45s\n",
      "epoch 104| loss: 0.29549 | val_logloss: 0.36767 |  0:02:47s\n",
      "epoch 105| loss: 0.30798 | val_logloss: 0.44554 |  0:02:48s\n",
      "epoch 106| loss: 0.29234 | val_logloss: 0.38522 |  0:02:49s\n",
      "epoch 107| loss: 0.27869 | val_logloss: 0.37435 |  0:02:51s\n",
      "epoch 108| loss: 0.27733 | val_logloss: 0.35729 |  0:02:52s\n",
      "epoch 109| loss: 0.2938  | val_logloss: 0.36866 |  0:02:54s\n",
      "epoch 110| loss: 0.25986 | val_logloss: 0.41006 |  0:02:55s\n",
      "epoch 111| loss: 0.32115 | val_logloss: 0.47359 |  0:02:57s\n",
      "epoch 112| loss: 0.2633  | val_logloss: 0.41832 |  0:02:58s\n",
      "epoch 113| loss: 0.25932 | val_logloss: 0.43033 |  0:03:00s\n",
      "epoch 114| loss: 0.26161 | val_logloss: 0.49206 |  0:03:02s\n",
      "epoch 115| loss: 0.2657  | val_logloss: 0.45841 |  0:03:03s\n",
      "epoch 116| loss: 0.29692 | val_logloss: 0.54386 |  0:03:05s\n",
      "epoch 117| loss: 0.26819 | val_logloss: 0.5414  |  0:03:06s\n",
      "epoch 118| loss: 0.24652 | val_logloss: 0.49986 |  0:03:08s\n",
      "epoch 119| loss: 0.29358 | val_logloss: 0.49227 |  0:03:09s\n",
      "epoch 120| loss: 0.2385  | val_logloss: 0.49272 |  0:03:11s\n",
      "epoch 121| loss: 0.2634  | val_logloss: 0.46037 |  0:03:12s\n",
      "epoch 122| loss: 0.28116 | val_logloss: 0.46909 |  0:03:14s\n",
      "epoch 123| loss: 0.28007 | val_logloss: 0.47436 |  0:03:15s\n",
      "epoch 124| loss: 0.26708 | val_logloss: 0.41538 |  0:03:17s\n",
      "epoch 125| loss: 0.27909 | val_logloss: 0.35476 |  0:03:18s\n",
      "epoch 126| loss: 0.26677 | val_logloss: 0.4252  |  0:03:19s\n",
      "epoch 127| loss: 0.25523 | val_logloss: 0.38179 |  0:03:21s\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 97 and best_val_logloss = 0.32493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at tabnet_pretrain_model.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tabnet_pretrain_model.zip'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .....UNCOMMENT THIS LINE IF YOU DO HYPERPARAMETER TUNING\n",
    "# best_pretrain_params = study_scratch.best_params\n",
    "\n",
    "tabnet_pretrain = TabNetClassifier(\n",
    "    n_d=best_pretrain_params['n_d_a'],           # split n_d_a into n_d\n",
    "    n_a=best_pretrain_params['n_d_a'],           # and n_a\n",
    "    n_steps=best_pretrain_params['n_steps'],\n",
    "    gamma=best_pretrain_params['gamma'],\n",
    "    lambda_sparse=best_pretrain_params['lambda_sparse'],\n",
    "    momentum=best_pretrain_params['momentum'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={'lr': best_pretrain_params['lr']},\n",
    "    mask_type='sparsemax',\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_pretrain_params['step_size'], 'gamma': best_pretrain_params['scheduler_gamma']},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# Train the final model\n",
    "tabnet_pretrain.fit(\n",
    "    X_train=X_A_train,\n",
    "    y_train=y_A_train,\n",
    "    eval_set=[(X_A_val, y_A_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"logloss\"],\n",
    "    max_epochs=150,\n",
    "    patience=30,\n",
    "    batch_size=best_pretrain_params['batch_size'],\n",
    "    virtual_batch_size=best_pretrain_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "tabnet_pretrain.save_model(\"tabnet_pretrain_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8244220-7390-4797-a19a-4d7e158111ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset A, Test Accuracy: 83.87%\n",
      "Pre-training, test on Dataset A, Test F1-score: 86.49%\n",
      "Pre-training, test on Dataset A, Test Recall (Sensitivity): 86.49%\n",
      "Pre-training, test on Dataset A, Test Specificity: 80.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Pretrain_TNet = tabnet_pretrain.predict(X_A_test)\n",
    "\n",
    "cm_A_TNet = confusion_matrix(y_A_test, Dataset_A_Pretrain_TNet)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A_TNet.ravel()\n",
    "\n",
    "# Calculate Metrics for TabNet on Dataset A\n",
    "acc_A_TNet = accuracy_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "f1_A_TNet = f1_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "recall_A_TNet = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A_TNet = TN_A / (TN_A + FP_A) * 100\n",
    "\n",
    "\n",
    "print(f\"Pre-training, test on Dataset A, Test Accuracy: {acc_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test F1-score: {f1_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Recall (Sensitivity): {recall_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Specificity: {specificity_A_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c40aac0-e457-447b-8a49-bca02c5b9a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset B, Accuracy: 74.19%\n",
      "Pre-training, test on Dataset B, F1-score: 73.33%\n",
      "Pre-training, test on Dataset B, Recall (Sensitivity): 78.57%\n",
      "Pre-training, test on Dataset B, Specificity: 70.59%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain_TNet = tabnet_pretrain.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_TNet = confusion_matrix(y_B_test, Dataset_B_Pretrain_TNet)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_TNet = accuracy_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "f1_B_TNet = f1_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_TNet = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B_TNet = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pre-training, test on Dataset B, Accuracy: {acc_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, F1-score: {f1_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Recall (Sensitivity): {recall_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Specificity: {specificity_B_TNet:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41fb9f-b867-490f-92a5-7a68fa4b134b",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5429c335-a2f1-4d1c-96a8-4f2ca38b8b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 00:08:46,950] A new study created in memory with name: no-name-bab354e7-25a7-47e6-b959-3fb7edff0247\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:09:05,180] Trial 0 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.2422921413473458, 'lambda_sparse': 4.4674843238322395e-05, 'lr': 0.0005454191359802393, 'momentum': 0.06999999999999999, 'weight_decay': 0.00021888834807352566, 'batch_size': 128, 'virtual_batch_size': 16, 'step_size': 30, 'scheduler_gamma': 0.8283388192784523}. Best is trial 0 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 36 and best_val_logloss = 0.17214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:09:18,424] Trial 1 finished with value: 0.9032258064516129 and parameters: {'gamma': 1.1143049288356874, 'lambda_sparse': 2.4633424661838425e-05, 'lr': 1.4170275794756587e-05, 'momentum': 0.24000000000000002, 'weight_decay': 0.0008719987291601801, 'batch_size': 128, 'virtual_batch_size': 32, 'step_size': 50, 'scheduler_gamma': 0.9445796584268462}. Best is trial 0 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 31 and best_val_logloss = 0.26891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_logloss = 0.23802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:10:08,530] Trial 2 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.7010768485304697, 'lambda_sparse': 0.004209994443332075, 'lr': 7.19430394095179e-05, 'momentum': 0.01, 'weight_decay': 0.00014615584048433632, 'batch_size': 32, 'virtual_batch_size': 32, 'step_size': 30, 'scheduler_gamma': 0.8988790736053499}. Best is trial 0 with value: 0.9333333333333333.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 6 and best_val_logloss = 0.16703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:10:32,248] Trial 3 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.6859638435272462, 'lambda_sparse': 0.007710358970953229, 'lr': 0.0011670357457049811, 'momentum': 0.37, 'weight_decay': 1.2197843684303826e-05, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.8659247247952376}. Best is trial 0 with value: 0.9333333333333333.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 100 with best_epoch = 95 and best_val_logloss = 0.19454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:11:27,469] Trial 4 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.2055073954950917, 'lambda_sparse': 1.3570165178999344e-06, 'lr': 0.00010255317285506084, 'momentum': 0.05, 'weight_decay': 0.00010480136300812869, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 30, 'scheduler_gamma': 0.8352495239962844}. Best is trial 0 with value: 0.9333333333333333.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 17 and best_val_logloss = 0.29894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:11:50,220] Trial 5 finished with value: 0.875 and parameters: {'gamma': 1.5364086938612993, 'lambda_sparse': 0.0001646856904190091, 'lr': 1.3623264669154953e-05, 'momentum': 0.23, 'weight_decay': 0.00085863401351914, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.9598941196769243}. Best is trial 0 with value: 0.9333333333333333.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:12:06,210] Trial 6 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.5202562811749707, 'lambda_sparse': 0.001492946611442833, 'lr': 0.0015173683281350027, 'momentum': 0.12, 'weight_decay': 0.00038741137118607585, 'batch_size': 128, 'virtual_batch_size': 16, 'step_size': 40, 'scheduler_gamma': 0.8256660444317862}. Best is trial 0 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 23 and best_val_logloss = 0.17338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:12:25,902] Trial 7 finished with value: 0.875 and parameters: {'gamma': 1.2238634803903032, 'lambda_sparse': 0.005932084907582451, 'lr': 5.970895836225864e-05, 'momentum': 0.06999999999999999, 'weight_decay': 1.4341988553927436e-05, 'batch_size': 128, 'virtual_batch_size': 32, 'step_size': 20, 'scheduler_gamma': 0.9161687142715591}. Best is trial 0 with value: 0.9333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 93 with best_epoch = 53 and best_val_logloss = 0.26856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 26 and best_val_logloss = 0.16256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:12:49,491] Trial 8 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.0093336159088, 'lambda_sparse': 0.000287623142768745, 'lr': 0.0005151997387371908, 'momentum': 0.29000000000000004, 'weight_decay': 0.00035940837944500203, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8291178754457263}. Best is trial 8 with value: 0.9655172413793104.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:13:08,649] Trial 9 finished with value: 0.875 and parameters: {'gamma': 1.9123842149319294, 'lambda_sparse': 1.2856603319977834e-05, 'lr': 2.2238398861131135e-05, 'momentum': 0.18000000000000002, 'weight_decay': 0.0005982640845713534, 'batch_size': 128, 'virtual_batch_size': 32, 'step_size': 80, 'scheduler_gamma': 0.8972708789479265}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 100 with best_epoch = 81 and best_val_logloss = 0.35572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 1 and best_val_logloss = 0.12619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:13:25,200] Trial 10 finished with value: 0.9285714285714286 and parameters: {'gamma': 1.056491089792874, 'lambda_sparse': 0.0003355712601491638, 'lr': 0.009163076554093286, 'momentum': 0.36000000000000004, 'weight_decay': 4.2900515449855195e-05, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 80, 'scheduler_gamma': 0.8055107152024413}. Best is trial 8 with value: 0.9655172413793104.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:13:56,033] Trial 11 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.3244735471416709, 'lambda_sparse': 4.3676256950140066e-05, 'lr': 0.00046880596004914905, 'momentum': 0.29000000000000004, 'weight_decay': 0.00023369340665332084, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8578587526087255}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.14469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:14:19,472] Trial 12 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.367507400579059, 'lambda_sparse': 0.0004251618915937133, 'lr': 0.0002913586505450098, 'momentum': 0.31, 'weight_decay': 0.00028979687663479756, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8659228799097902}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.14635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:14:34,111] Trial 13 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.3687334972351624, 'lambda_sparse': 2.8857319575208558e-06, 'lr': 0.0038778033501324204, 'momentum': 0.29000000000000004, 'weight_decay': 5.1987993662030704e-05, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8496538330136844}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 2 and best_val_logloss = 0.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:14:56,852] Trial 14 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.0441750291969256, 'lambda_sparse': 8.403206735528225e-06, 'lr': 0.00028370846539118943, 'momentum': 0.29000000000000004, 'weight_decay': 0.00039282828129995513, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8704054512320905}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.17077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:15:15,867] Trial 15 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.367157955639628, 'lambda_sparse': 8.975856154353565e-05, 'lr': 0.0007532660778740462, 'momentum': 0.17, 'weight_decay': 5.62424157757405e-05, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8041387914316378}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 17 and best_val_logloss = 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:15:30,175] Trial 16 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.0144225699927032, 'lambda_sparse': 0.0010281254654526094, 'lr': 0.002761025671404811, 'momentum': 0.4, 'weight_decay': 0.00019052461370645097, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8481697239896773}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 4 and best_val_logloss = 0.13228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 39 and best_val_logloss = 0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:16:03,015] Trial 17 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.1640956787854742, 'lambda_sparse': 7.875496948974441e-05, 'lr': 0.00017714633793248366, 'momentum': 0.32, 'weight_decay': 9.425180373703271e-05, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.9233799647128421}. Best is trial 8 with value: 0.9655172413793104.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:16:25,599] Trial 18 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.6463492872169527, 'lambda_sparse': 0.000276905937036994, 'lr': 0.0005424595396278098, 'momentum': 0.26, 'weight_decay': 0.0005120038395547117, 'batch_size': 64, 'virtual_batch_size': 32, 'step_size': 50, 'scheduler_gamma': 0.8785190569628886}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 33 and best_val_logloss = 0.18969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:16:56,648] Trial 19 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.8953141104688926, 'lambda_sparse': 0.001141507117085539, 'lr': 0.00015188140705682494, 'momentum': 0.19, 'weight_decay': 2.3474766977528945e-05, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.8474892853065131}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 100 with best_epoch = 86 and best_val_logloss = 0.19736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_val_logloss = 0.20341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:17:46,938] Trial 20 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.3027921810114023, 'lambda_sparse': 6.439677736864882e-06, 'lr': 3.676301976046555e-05, 'momentum': 0.34, 'weight_decay': 0.00011798399091112759, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 80, 'scheduler_gamma': 0.8148534992691371}. Best is trial 8 with value: 0.9655172413793104.\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:18:09,235] Trial 21 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.4450803677623445, 'lambda_sparse': 0.000525220952174356, 'lr': 0.0003498965749168937, 'momentum': 0.29000000000000004, 'weight_decay': 0.00026975227309178785, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8584268259771287}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.14347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:18:31,351] Trial 22 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.4279136888033503, 'lambda_sparse': 3.111392333427441e-05, 'lr': 0.0002553392100364577, 'momentum': 0.32, 'weight_decay': 0.0003048851522889992, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8847416628354472}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.16422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:18:53,180] Trial 23 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.6073537882702764, 'lambda_sparse': 0.000141705515446348, 'lr': 0.0010741830020459238, 'momentum': 0.26, 'weight_decay': 0.0001786146614554196, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8364462889344734}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.17957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:19:15,135] Trial 24 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.3291972342796488, 'lambda_sparse': 0.0024096083969248447, 'lr': 0.00044209270883691456, 'momentum': 0.22, 'weight_decay': 0.000574566245674024, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.8579010259989587}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 29 and best_val_logloss = 0.15997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:19:29,248] Trial 25 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.7813299025266465, 'lambda_sparse': 0.0004516781153057403, 'lr': 0.002021764788064135, 'momentum': 0.32, 'weight_decay': 0.00031467034169290956, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8754011740190726}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 3 and best_val_logloss = 0.17753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:19:56,903] Trial 26 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.1117857717386121, 'lambda_sparse': 0.00017894829946397023, 'lr': 0.00015548252739601523, 'momentum': 0.4, 'weight_decay': 7.415960220252758e-05, 'batch_size': 64, 'virtual_batch_size': 32, 'step_size': 80, 'scheduler_gamma': 0.8212116594809854}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 100 with best_epoch = 86 and best_val_logloss = 0.16757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:20:18,550] Trial 27 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.2769280168017008, 'lambda_sparse': 0.0007260379723648869, 'lr': 0.0007643322743133475, 'momentum': 0.15000000000000002, 'weight_decay': 0.00022938367426647064, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 70, 'scheduler_gamma': 0.9052485020473331}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 23 and best_val_logloss = 0.16858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:20:33,298] Trial 28 finished with value: 0.9333333333333333 and parameters: {'gamma': 1.4529768377094345, 'lambda_sparse': 5.64854915071735e-05, 'lr': 0.004418840121748493, 'momentum': 0.27, 'weight_decay': 0.0004359578007004053, 'batch_size': 64, 'virtual_batch_size': 16, 'step_size': 50, 'scheduler_gamma': 0.9773694610251796}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 2 and best_val_logloss = 0.16867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: mask_type changed from entmax to sparsemax\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 15 and best_val_logloss = 0.16513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2025-12-30 00:21:01,868] Trial 29 finished with value: 0.9655172413793104 and parameters: {'gamma': 1.1505639134565493, 'lambda_sparse': 2.424671090397197e-05, 'lr': 0.0007412784697649567, 'momentum': 0.36000000000000004, 'weight_decay': 0.00014598653267065606, 'batch_size': 32, 'virtual_batch_size': 16, 'step_size': 60, 'scheduler_gamma': 0.8363723847926725}. Best is trial 8 with value: 0.9655172413793104.\n"
     ]
    }
   ],
   "source": [
    "def objective_finetune(trial):\n",
    "\n",
    "    # --- Hyperparameters to tune ---\n",
    "    gamma = trial.suggest_float('gamma', 1.0, 2.0)\n",
    "    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-6, 1e-2, log=True)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    momentum = trial.suggest_float('momentum', 0.01, 0.4, step=0.01)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    virtual_batch_size = trial.suggest_categorical('virtual_batch_size', [16, 32])\n",
    "\n",
    "    step_size = trial.suggest_int('step_size', 20, 80, step=10)\n",
    "    scheduler_gamma = trial.suggest_float('scheduler_gamma', 0.8, 0.98)\n",
    "\n",
    "    # --- Model definition ---\n",
    "    tabnet_model_finetune = TabNetClassifier(\n",
    "        n_d=best_pretrain_params['n_d_a'],\n",
    "        n_a=best_pretrain_params['n_d_a'],\n",
    "        n_steps=best_pretrain_params['n_steps'],\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        momentum=momentum,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params={\n",
    "            'lr': lr,\n",
    "        },\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        scheduler_params={\n",
    "            'step_size': step_size,\n",
    "            'gamma': scheduler_gamma\n",
    "        },\n",
    "        mask_type='entmax',\n",
    "        verbose=0,\n",
    "        seed=42,\n",
    "        device_name='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "\n",
    "    # --- Fine-tuning ---\n",
    "    tabnet_model_finetune.fit(\n",
    "        X_train=X_B_train,\n",
    "        y_train=y_B_train,\n",
    "        eval_set=[(X_B_val, y_B_val)],\n",
    "        eval_name=[\"val\"],\n",
    "        eval_metric=[\"logloss\"],\n",
    "        max_epochs=100,\n",
    "        patience=40,  # FIXED (not optimized)\n",
    "        batch_size=batch_size,\n",
    "        virtual_batch_size=virtual_batch_size,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        from_unsupervised=tabnet_pretrain\n",
    "    )\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    preds = tabnet_model_finetune.predict(X_B_val)\n",
    "    f1 = f1_score(y_B_val, preds)\n",
    "    acc = accuracy_score(y_B_val, preds)\n",
    "\n",
    "    print(\n",
    "        f\"Trial {trial.number} | \"\n",
    "        f\"F1: {f1:.4f} | Acc: {acc:.4f} | \"\n",
    "        f\"LR: {lr:.1e} | Mom: {momentum:.2f}\"\n",
    "    )\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "# --- Run the Optimization ---\n",
    "study_finetune = optuna.create_study(direction='maximize')  # We want to maximize F1-Score\n",
    "study_finetune.optimize(objective_finetune, n_trials=30)  # Number of trials to run for optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46cfcb11-06a9-4d81-8aa6-9e34972d611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best finetune params:\n",
      "  Value (F1-score): 0.9655\n",
      "  Params:\n",
      "    gamma: 1.0093336159088\n",
      "    lambda_sparse: 0.000287623142768745\n",
      "    lr: 0.0005151997387371908\n",
      "    momentum: 0.29000000000000004\n",
      "    weight_decay: 0.00035940837944500203\n",
      "    batch_size: 64\n",
      "    virtual_batch_size: 16\n",
      "    step_size: 70\n",
      "    scheduler_gamma: 0.8291178754457263\n"
     ]
    }
   ],
   "source": [
    "# Get best trial and parameters\n",
    "best_trial_finetune = study_finetune.best_trial\n",
    "best_finetune_params = best_trial_finetune.params\n",
    "\n",
    "print(\"Best finetune params:\")\n",
    "print(f\"  Value (F1-score): {best_trial_finetune.value:.4f}\")\n",
    "print(\"  Params:\")\n",
    "\n",
    "for key, value in best_finetune_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42615b97-2b2e-436f-ba9c-900939d4e405",
   "metadata": {},
   "source": [
    "#### Finetunine on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62318eaf-23a4-4d5f-ad96-4c2a8fc38558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 1.87\n",
      "lambda_sparse: 0.00176\n",
      "lr: 0.00236\n",
      "momentum: 0.92\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 60\n",
      "scheduler_gamma: 0.946\n"
     ]
    }
   ],
   "source": [
    "best_finetune_params = {\n",
    "    \"gamma\": 1.87,  \n",
    "    \"lambda_sparse\": 0.00176,  \n",
    "    \"lr\": 0.00236,  \n",
    "    \"momentum\": 0.92, \n",
    "    \"batch_size\": 32,  \n",
    "    \"virtual_batch_size\": 32,  \n",
    "    \"step_size\": 60,  \n",
    "    \"scheduler_gamma\": 0.946, \n",
    "}\n",
    "\n",
    "# Print the updated values\n",
    "for key, value in best_finetune_params.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "60a1ed99-b4e0-49c3-b7f3-3e48f2446be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_a changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_d changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_steps changed from 3 to 9\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65235 | val_logloss: 0.24879 |  0:00:00s\n",
      "epoch 1  | loss: 0.59593 | val_logloss: 0.2366  |  0:00:01s\n",
      "epoch 2  | loss: 0.58144 | val_logloss: 0.22615 |  0:00:02s\n",
      "epoch 3  | loss: 0.485   | val_logloss: 0.30044 |  0:00:03s\n",
      "epoch 4  | loss: 0.60511 | val_logloss: 0.3088  |  0:00:04s\n",
      "epoch 5  | loss: 0.48286 | val_logloss: 0.23589 |  0:00:04s\n",
      "epoch 6  | loss: 0.45735 | val_logloss: 0.16189 |  0:00:05s\n",
      "epoch 7  | loss: 0.49516 | val_logloss: 0.16318 |  0:00:06s\n",
      "epoch 8  | loss: 0.48312 | val_logloss: 0.1911  |  0:00:07s\n",
      "epoch 9  | loss: 0.51852 | val_logloss: 0.19563 |  0:00:08s\n",
      "epoch 10 | loss: 0.41846 | val_logloss: 0.20051 |  0:00:08s\n",
      "epoch 11 | loss: 0.45739 | val_logloss: 0.18843 |  0:00:09s\n",
      "epoch 12 | loss: 0.45904 | val_logloss: 0.25945 |  0:00:10s\n",
      "epoch 13 | loss: 0.43297 | val_logloss: 0.17831 |  0:00:11s\n",
      "epoch 14 | loss: 0.43837 | val_logloss: 0.28718 |  0:00:11s\n",
      "epoch 15 | loss: 0.44192 | val_logloss: 0.29492 |  0:00:12s\n",
      "epoch 16 | loss: 0.46761 | val_logloss: 0.27825 |  0:00:13s\n",
      "epoch 17 | loss: 0.41965 | val_logloss: 0.27933 |  0:00:14s\n",
      "epoch 18 | loss: 0.43714 | val_logloss: 0.30427 |  0:00:15s\n",
      "epoch 19 | loss: 0.39024 | val_logloss: 0.28889 |  0:00:15s\n",
      "epoch 20 | loss: 0.45468 | val_logloss: 0.24873 |  0:00:16s\n",
      "epoch 21 | loss: 0.38451 | val_logloss: 0.26281 |  0:00:17s\n",
      "epoch 22 | loss: 0.42085 | val_logloss: 0.2804  |  0:00:18s\n",
      "epoch 23 | loss: 0.41017 | val_logloss: 0.23485 |  0:00:19s\n",
      "epoch 24 | loss: 0.41168 | val_logloss: 0.23441 |  0:00:20s\n",
      "epoch 25 | loss: 0.42947 | val_logloss: 0.2916  |  0:00:21s\n",
      "epoch 26 | loss: 0.40664 | val_logloss: 0.3218  |  0:00:21s\n",
      "epoch 27 | loss: 0.38821 | val_logloss: 0.33632 |  0:00:22s\n",
      "epoch 28 | loss: 0.43451 | val_logloss: 0.2991  |  0:00:23s\n",
      "epoch 29 | loss: 0.41786 | val_logloss: 0.2609  |  0:00:24s\n",
      "epoch 30 | loss: 0.41462 | val_logloss: 0.28093 |  0:00:24s\n",
      "epoch 31 | loss: 0.40889 | val_logloss: 0.23643 |  0:00:25s\n",
      "epoch 32 | loss: 0.41186 | val_logloss: 0.20836 |  0:00:26s\n",
      "epoch 33 | loss: 0.38377 | val_logloss: 0.25244 |  0:00:27s\n",
      "epoch 34 | loss: 0.43937 | val_logloss: 0.28511 |  0:00:27s\n",
      "epoch 35 | loss: 0.42113 | val_logloss: 0.25574 |  0:00:28s\n",
      "epoch 36 | loss: 0.42674 | val_logloss: 0.2591  |  0:00:29s\n",
      "epoch 37 | loss: 0.38818 | val_logloss: 0.26547 |  0:00:29s\n",
      "epoch 38 | loss: 0.39275 | val_logloss: 0.25639 |  0:00:30s\n",
      "epoch 39 | loss: 0.36681 | val_logloss: 0.28337 |  0:00:31s\n",
      "epoch 40 | loss: 0.41538 | val_logloss: 0.28305 |  0:00:32s\n",
      "epoch 41 | loss: 0.39936 | val_logloss: 0.23091 |  0:00:32s\n",
      "epoch 42 | loss: 0.39722 | val_logloss: 0.24954 |  0:00:33s\n",
      "epoch 43 | loss: 0.39084 | val_logloss: 0.26122 |  0:00:34s\n",
      "epoch 44 | loss: 0.39068 | val_logloss: 0.24932 |  0:00:34s\n",
      "epoch 45 | loss: 0.39989 | val_logloss: 0.25626 |  0:00:35s\n",
      "epoch 46 | loss: 0.4177  | val_logloss: 0.2531  |  0:00:36s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 6 and best_val_logloss = 0.16189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below if you do hyperparameter tuning\n",
    "# best_finetune_params = study_finetune.best_params\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "tabnet_finetuned = TabNetClassifier(\n",
    "    n_d=8,\n",
    "    n_a=8,\n",
    "    n_steps=3,\n",
    "    gamma=best_finetune_params['gamma'],\n",
    "    lambda_sparse=best_finetune_params['lambda_sparse'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={\n",
    "        'lr': best_finetune_params['lr']\n",
    "    },\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_finetune_params['step_size'], 'gamma': best_finetune_params['scheduler_gamma']},\n",
    "    seed=42,\n",
    "    verbose=1,\n",
    "    device_name='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "tabnet_finetuned.fit(\n",
    "    X_train=X_B_train,\n",
    "    y_train=y_B_train,           \n",
    "    eval_set=[(X_B_val, y_B_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=['logloss'],\n",
    "    max_epochs=100,\n",
    "    patience=40,\n",
    "    batch_size=best_finetune_params['batch_size'],\n",
    "    virtual_batch_size=best_finetune_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # Initialize with pre-trained weights\n",
    "    from_unsupervised=tabnet_pretrain  # Transfer learning!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fcb0603e-8399-4861-9f00-b943aeff7fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset A, Test Accuracy: 82.26%\n",
      "Fine-tuned, test on Dataset A, Test F1-score: 84.51%\n",
      "Fine-tuned, test on Dataset A, Test Recall (Sensitivity): 81.08%\n",
      "Fine-tuned, test on Dataset A, Test Specificity: 84.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Finetune_TNet = tabnet_finetuned.predict(X_A_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset A\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_A_Finetune_TNet = confusion_matrix(y_A_test, Dataset_A_Finetune_TNet)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_A_Finetune_TNet = accuracy_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "f1_A_Finetune_TNet = f1_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_A_Finetune_TNet = TP_A_F / (TP_A_F + FN_A_F) * 100 if (TP_A_F + FN_A_F) > 0 else 0\n",
    "specificity_A_Finetune_TNet = TN_A_F / (TN_A_F + FP_A_F) * 100 if (TN_A_F + FP_A_F) > 0 else 0\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Accuracy: {acc_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test F1-score: {f1_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Recall (Sensitivity): {recall_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Specificity: {specificity_A_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "357c6039-9f26-4de1-a9da-1f10dcda17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset B, Accuracy: 70.97%\n",
      "Fine-tuned, test on Dataset B, F1-score: 70.97%\n",
      "Fine-tuned, test on Dataset B, Recall (Sensitivity): 78.57%\n",
      "Fine-tuned, test on Dataset B, Specificity: 64.71%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Finetune_TNet = tabnet_finetuned.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_Finetune_TNet = confusion_matrix(y_B_test, Dataset_B_Finetune_TNet)\n",
    "TN_F, FP_F, FN_F, TP_F = cm_B_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_Finetune_TNet = accuracy_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "f1_B_Finetune_TNet = f1_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_Finetune_TNet = TP_F / (TP_F + FN_F) * 100\n",
    "specificity_B_Finetune_TNet = TN_F / (TN_F + FP_F) * 100\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset B, Accuracy: {acc_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, F1-score: {f1_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Recall (Sensitivity): {recall_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Specificity: {specificity_B_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dee12720-0a89-4fc6-94f6-ce748465e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n"
     ]
    }
   ],
   "source": [
    "# Manually define feature names \n",
    "feature_names = [f\"Feature_{i+1}\" for i in range(X_B_train.shape[1])]\n",
    "\n",
    "print(\"Selected features:\", similar_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c017cf94-a388-49a9-850b-4091454eca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features without target: ['trestbps', 'sex', 'exang', 'slope', 'cp', 'age', 'thalach', 'ca', 'oldpeak', 'thal']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'target_column_name' is the name of your target column (e.g. 'y' or 'target')\n",
    "target_column_name = 'target'  # Replace this with your actual target column name\n",
    "\n",
    "# Remove the target column from similar_features list\n",
    "feature_names = [feature for feature in similar_features if feature != target_column_name]\n",
    "\n",
    "# Print to verify\n",
    "print(\"Selected features without target:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a23970d-1bb7-40a4-9671-a3f0f2b22b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea545270769d4f9cb1c78ff66fd906a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\AppData\\Local\\Temp\\ipykernel_19640\\3427791113.py:26: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values_tabnet, X_B_test_df, max_display=20, show=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# Convert to DataFrame with correct feature names\n",
    "X_B_train_df = pd.DataFrame(X_B_train, columns=feature_names)\n",
    "X_B_test_df = pd.DataFrame(X_B_test, columns=feature_names)\n",
    "\n",
    "# Define prediction function\n",
    "def tabnet_predict(X):\n",
    "    return tabnet_finetuned.predict_proba(X)[:, 1]\n",
    "\n",
    "# Sample background data - increase size if possible\n",
    "background = X_B_train_df.sample(n=2, random_state=42)\n",
    "\n",
    "# Create explainer\n",
    "explainer_tabnet = shap.KernelExplainer(tabnet_predict, background)\n",
    "\n",
    "# Calculate SHAP values - start with fewer samples for testing\n",
    "# test_sample = X_B_test_df.iloc[:2]  # Start with 20 samples\n",
    "# shap_values_tabnet = explainer_tabnet.shap_values(test_sample)\n",
    "\n",
    "# Uncomment this line to calculate SHAP values for the entire test dataset\n",
    "shap_values_tabnet = explainer_tabnet.shap_values(X_B_test_df)  # Passing the entire test set\n",
    "\n",
    "# Generate summary plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "shap.summary_plot(shap_values_tabnet, X_B_test_df, max_display=20, show=False)\n",
    "\n",
    "plt.xlabel('SHAP Value', fontsize=24)\n",
    "plt.ylabel('', fontsize=26)\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=18, fontweight='normal')  # X-axis tick font size\n",
    "plt.yticks(fontsize=28, fontweight='normal')  # Y-axis tick font size\n",
    "\n",
    "plt.tight_layout()  # Adjust the layout to prevent clipping\n",
    "\n",
    "# Save the plot as an image with high resolution and no caption\n",
    "plt.savefig('shap_summary_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8667e78a-f5b0-4fa6-9cf4-a0c362f0f545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "\n",
    "shap_values_abs = np.abs(shap_values_tabnet)\n",
    "mean_shap_values = np.mean(shap_values_abs, axis=0)\n",
    "\n",
    "# 2. DataFrame Creation (Fixed Naming)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': mean_shap_values\n",
    "})\n",
    "\n",
    "# 3. Sorting (Correct)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 4. Plotting (Fixed Reference)\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='#008bfb') \n",
    "plt.xlabel('Mean |SHAP Value|', fontweight='normal', fontsize = 36)\n",
    "# plt.title('Feature Importance (TabNet)', fontsize=20, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=28, fontweight='normal')   # X-axis tick font size\n",
    "plt.yticks(fontsize=48, fontweight='normal')  # Y-axis tick font size\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_feature_importance_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81509e62-8502-4cb6-a7e1-d6c997fb4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Create the plot with a specific size\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Display confusion matrix as an image with the 'Blues' color map\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "# Set color bar ticks based on the max value of the matrix\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# Remove title as per request (You can uncomment the next line if you want to add a title)\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "# Label the axes\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Normalize the color range based on the confusion matrix values\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "# Iterate through the matrix to add text inside each cell\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))  # Get the color of the cell based on the value\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]  # Calculate luminance\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'  # Choose white or black text based on luminance\n",
    "        \n",
    "        # Add the text inside the cell with bold and Times New Roman font\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image with high resolution\n",
    "plt.savefig('confusion_matrix_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26f9b1-2251-4300-90ca-eca153ba1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Times New Roman font is used in all plots\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '20'})\n",
    "\n",
    "# Get predictions for TabNet model\n",
    "y_pred = tabnet_finetuned.predict(X_B_test)  # Get the class predictions for target domain\n",
    "y_pred_prob = tabnet_finetuned.predict_proba(X_B_test)[:, 1]  # Probabilities for the positive class (ROC)\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_B_test, y_pred) * 100\n",
    "recall = recall_score(y_B_test, y_pred) * 100\n",
    "f1 = f1_score(y_B_test, y_pred) * 100\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1-Score: {f1:.2f}%\")\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "tn, fp, fn, tp = confusion_matrix(y_B_test, y_pred).ravel()\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "print(f\"Specificity: {specificity:.2f}%\")\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_B_test, y_pred_prob) * 100\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_B_test, y_pred_prob)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_tabnet.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()  # Display the plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d28fe7-74ba-41e7-8fef-2b8d2b0f3303",
   "metadata": {},
   "source": [
    "## 7. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e077c-9bfc-4381-bb15-265bf2789828",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63318ef1-8c86-4760-8cb1-aad3d9a6f266",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for pretraining stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c7664098-5023-43ce-947f-7e8ca0bdbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_for_tuning(hp):\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    hp_l2_reg = hp.Choice('l2_reg', values=[0.01, 0.001, 0.0001])\n",
    "    hp_dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_neurons_l1 = hp.Int('neurons_l1', min_value=32, max_value=128, step=32)\n",
    "\n",
    "    # input_dim = X_pretrain_train_res.shape[1]\n",
    "    input_dim = X_A_train.shape[1]\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # Layer 1 (Tuned Neurons, Tuned Dropout, Tuned L2)\n",
    "    x = Dense(\n",
    "        hp_neurons_l1, \n",
    "        activation='relu', \n",
    "        name='feature_layer_1',\n",
    "        kernel_regularizer=keras.regularizers.l2(hp_l2_reg)\n",
    "    )(inputs)\n",
    "    x = Dropout(hp_dropout_rate)(x)\n",
    "\n",
    "    # Layer 2 (Fixed at half of L1, or can be tuned as well)\n",
    "    x = Dense(\n",
    "        int(hp_neurons_l1 / 2), # e.g., 64 -> 32\n",
    "        activation='relu', \n",
    "        name='feature_layer_2',\n",
    "        kernel_regularizer=keras.regularizers.l2(hp_l2_reg)\n",
    "    )(x)\n",
    "    x = Dropout(hp_dropout_rate)(x)\n",
    "    \n",
    "    # Layer 3 (Fixed at quarter of L1, or can be tuned)\n",
    "    x = Dense(\n",
    "        int(hp_neurons_l1 / 4), # e.g., 64 -> 16\n",
    "        activation='relu', \n",
    "        name='feature_layer_3',\n",
    "        kernel_regularizer=keras.regularizers.l2(hp_l2_reg)\n",
    "    )(x)\n",
    "    x = Dropout(hp_dropout_rate)(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')] \n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4c473533-9faa-4745-9ee2-1db8d6643f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 10)\n",
      "(590, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_pretrain_val.shape)\n",
    "print(X_pretrain_train.shape)  # should match input layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0a24bac-0d47-4c74-b389-245d1b1bf42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "l2_reg (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "neurons_l1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.001             |0.001             |learning_rate\n",
      "0.001             |0.001             |l2_reg\n",
      "0.1               |0.1               |dropout_rate\n",
      "96                |96                |neurons_l1\n",
      "\n",
      "Epoch 1/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7508 - auc: 0.8465 - loss: 0.6890 - val_accuracy: 0.7541 - val_auc: 0.8198 - val_loss: 0.6453\n",
      "Epoch 2/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8441 - auc: 0.9101 - loss: 0.5092 - val_accuracy: 0.7541 - val_auc: 0.8452 - val_loss: 0.6083\n",
      "Epoch 3/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8644 - auc: 0.9193 - loss: 0.4703 - val_accuracy: 0.7705 - val_auc: 0.8666 - val_loss: 0.5745\n",
      "Epoch 4/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8712 - auc: 0.9364 - loss: 0.4307 - val_accuracy: 0.8033 - val_auc: 0.8863 - val_loss: 0.5316\n",
      "Epoch 5/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8746 - auc: 0.9469 - loss: 0.4016 - val_accuracy: 0.8033 - val_auc: 0.8936 - val_loss: 0.5274\n",
      "Epoch 6/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8847 - auc: 0.9510 - loss: 0.3891 - val_accuracy: 0.8197 - val_auc: 0.9037 - val_loss: 0.4959\n",
      "Epoch 7/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8898 - auc: 0.9539 - loss: 0.3768 - val_accuracy: 0.8033 - val_auc: 0.9071 - val_loss: 0.4985\n",
      "Epoch 8/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8932 - auc: 0.9539 - loss: 0.3735 - val_accuracy: 0.8033 - val_auc: 0.9043 - val_loss: 0.4754\n",
      "Epoch 9/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9085 - auc: 0.9608 - loss: 0.3510 - val_accuracy: 0.7869 - val_auc: 0.9015 - val_loss: 0.4755\n",
      "Epoch 10/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9119 - auc: 0.9593 - loss: 0.3502 - val_accuracy: 0.7869 - val_auc: 0.9020 - val_loss: 0.4690\n",
      "Epoch 11/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9017 - auc: 0.9632 - loss: 0.3445 - val_accuracy: 0.7869 - val_auc: 0.9043 - val_loss: 0.4634\n",
      "Epoch 12/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9068 - auc: 0.9613 - loss: 0.3419 - val_accuracy: 0.7869 - val_auc: 0.9009 - val_loss: 0.4839\n",
      "Epoch 13/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9102 - auc: 0.9659 - loss: 0.3290 - val_accuracy: 0.7705 - val_auc: 0.8958 - val_loss: 0.4696\n",
      "Epoch 14/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9169 - auc: 0.9686 - loss: 0.3169 - val_accuracy: 0.7705 - val_auc: 0.9015 - val_loss: 0.4689\n",
      "Epoch 15/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9136 - auc: 0.9695 - loss: 0.3101 - val_accuracy: 0.7705 - val_auc: 0.8981 - val_loss: 0.4708\n",
      "Epoch 16/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9237 - auc: 0.9695 - loss: 0.3049 - val_accuracy: 0.7705 - val_auc: 0.8992 - val_loss: 0.4686\n",
      "Epoch 17/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9169 - auc: 0.9704 - loss: 0.3029 - val_accuracy: 0.8033 - val_auc: 0.9009 - val_loss: 0.4656\n",
      "Epoch 18/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9254 - auc: 0.9708 - loss: 0.3024 - val_accuracy: 0.7705 - val_auc: 0.9003 - val_loss: 0.4850\n",
      "Epoch 19/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9068 - auc: 0.9697 - loss: 0.3013 - val_accuracy: 0.7869 - val_auc: 0.8986 - val_loss: 0.4717\n",
      "Epoch 20/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9186 - auc: 0.9712 - loss: 0.2916 - val_accuracy: 0.7705 - val_auc: 0.9026 - val_loss: 0.4658\n",
      "Epoch 21/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - auc: 0.9709 - loss: 0.2918 - val_accuracy: 0.7869 - val_auc: 0.9015 - val_loss: 0.4779\n",
      "Epoch 1/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7525 - auc: 0.8510 - loss: 0.6657 - val_accuracy: 0.7705 - val_auc: 0.8592 - val_loss: 0.6219\n",
      "Epoch 2/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8424 - auc: 0.9232 - loss: 0.5013 - val_accuracy: 0.7869 - val_auc: 0.8744 - val_loss: 0.5614\n",
      "Epoch 3/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8458 - auc: 0.9290 - loss: 0.4504 - val_accuracy: 0.8033 - val_auc: 0.8834 - val_loss: 0.5452\n",
      "Epoch 4/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8695 - auc: 0.9397 - loss: 0.4206 - val_accuracy: 0.8033 - val_auc: 0.8919 - val_loss: 0.5113\n",
      "Epoch 5/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8780 - auc: 0.9485 - loss: 0.3969 - val_accuracy: 0.8361 - val_auc: 0.9020 - val_loss: 0.4931\n",
      "Epoch 6/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8864 - auc: 0.9538 - loss: 0.3765 - val_accuracy: 0.8197 - val_auc: 0.9003 - val_loss: 0.4889\n",
      "Epoch 7/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8949 - auc: 0.9572 - loss: 0.3655 - val_accuracy: 0.8361 - val_auc: 0.9054 - val_loss: 0.4677\n",
      "Epoch 8/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9017 - auc: 0.9598 - loss: 0.3559 - val_accuracy: 0.8197 - val_auc: 0.9065 - val_loss: 0.4662\n",
      "Epoch 9/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - auc: 0.9581 - loss: 0.3585 - val_accuracy: 0.8197 - val_auc: 0.9065 - val_loss: 0.4587\n",
      "Epoch 10/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - auc: 0.9626 - loss: 0.3376 - val_accuracy: 0.8197 - val_auc: 0.9071 - val_loss: 0.4605\n",
      "Epoch 11/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9102 - auc: 0.9620 - loss: 0.3397 - val_accuracy: 0.8033 - val_auc: 0.9093 - val_loss: 0.4553\n",
      "Epoch 12/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9034 - auc: 0.9648 - loss: 0.3320 - val_accuracy: 0.8361 - val_auc: 0.9032 - val_loss: 0.4608\n",
      "Epoch 13/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9051 - auc: 0.9671 - loss: 0.3204 - val_accuracy: 0.8033 - val_auc: 0.9048 - val_loss: 0.4597\n",
      "Epoch 14/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9034 - auc: 0.9674 - loss: 0.3226 - val_accuracy: 0.8033 - val_auc: 0.9071 - val_loss: 0.4557\n",
      "Epoch 15/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9119 - auc: 0.9686 - loss: 0.3123 - val_accuracy: 0.8197 - val_auc: 0.9122 - val_loss: 0.4463\n",
      "Epoch 16/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9085 - auc: 0.9673 - loss: 0.3141 - val_accuracy: 0.8361 - val_auc: 0.9093 - val_loss: 0.4613\n",
      "Epoch 17/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9102 - auc: 0.9707 - loss: 0.3073 - val_accuracy: 0.8197 - val_auc: 0.9105 - val_loss: 0.4552\n",
      "Epoch 18/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9034 - auc: 0.9720 - loss: 0.2989 - val_accuracy: 0.7869 - val_auc: 0.9060 - val_loss: 0.4464\n",
      "Epoch 19/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9102 - auc: 0.9742 - loss: 0.2892 - val_accuracy: 0.8033 - val_auc: 0.9032 - val_loss: 0.4587\n",
      "Epoch 20/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9085 - auc: 0.9713 - loss: 0.3000 - val_accuracy: 0.7869 - val_auc: 0.9009 - val_loss: 0.4643\n",
      "Epoch 21/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - auc: 0.9707 - loss: 0.3018 - val_accuracy: 0.7869 - val_auc: 0.9032 - val_loss: 0.4623\n",
      "Epoch 22/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9220 - auc: 0.9752 - loss: 0.2831 - val_accuracy: 0.8033 - val_auc: 0.8986 - val_loss: 0.4579\n",
      "Epoch 23/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9305 - auc: 0.9758 - loss: 0.2739 - val_accuracy: 0.8033 - val_auc: 0.9032 - val_loss: 0.4652\n",
      "Epoch 24/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9119 - auc: 0.9727 - loss: 0.2883 - val_accuracy: 0.7869 - val_auc: 0.9032 - val_loss: 0.4687\n",
      "Epoch 25/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - auc: 0.9739 - loss: 0.2799 - val_accuracy: 0.7869 - val_auc: 0.9043 - val_loss: 0.4662\n",
      "Epoch 1/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7051 - auc: 0.7684 - loss: 0.7423 - val_accuracy: 0.7377 - val_auc: 0.8288 - val_loss: 0.6830\n",
      "Epoch 2/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8424 - auc: 0.9076 - loss: 0.5736 - val_accuracy: 0.7541 - val_auc: 0.8485 - val_loss: 0.5994\n",
      "Epoch 3/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8542 - auc: 0.9245 - loss: 0.4692 - val_accuracy: 0.7705 - val_auc: 0.8643 - val_loss: 0.5780\n",
      "Epoch 4/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8627 - auc: 0.9336 - loss: 0.4347 - val_accuracy: 0.7869 - val_auc: 0.8806 - val_loss: 0.5383\n",
      "Epoch 5/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8814 - auc: 0.9447 - loss: 0.4050 - val_accuracy: 0.8033 - val_auc: 0.8857 - val_loss: 0.5280\n",
      "Epoch 6/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8915 - auc: 0.9502 - loss: 0.3857 - val_accuracy: 0.8033 - val_auc: 0.8919 - val_loss: 0.5166\n",
      "Epoch 7/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8966 - auc: 0.9592 - loss: 0.3622 - val_accuracy: 0.8033 - val_auc: 0.8953 - val_loss: 0.5119\n",
      "Epoch 8/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8915 - auc: 0.9574 - loss: 0.3572 - val_accuracy: 0.8033 - val_auc: 0.8930 - val_loss: 0.5044\n",
      "Epoch 9/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9051 - auc: 0.9581 - loss: 0.3524 - val_accuracy: 0.7869 - val_auc: 0.8936 - val_loss: 0.5083\n",
      "Epoch 10/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9085 - auc: 0.9611 - loss: 0.3438 - val_accuracy: 0.8033 - val_auc: 0.8925 - val_loss: 0.4941\n",
      "Epoch 11/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9102 - auc: 0.9648 - loss: 0.3312 - val_accuracy: 0.7705 - val_auc: 0.8947 - val_loss: 0.4951\n",
      "Epoch 12/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9068 - auc: 0.9639 - loss: 0.3328 - val_accuracy: 0.7869 - val_auc: 0.8913 - val_loss: 0.4975\n",
      "Epoch 13/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9136 - auc: 0.9627 - loss: 0.3313 - val_accuracy: 0.7705 - val_auc: 0.8891 - val_loss: 0.4899\n",
      "Epoch 14/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9102 - auc: 0.9667 - loss: 0.3186 - val_accuracy: 0.7541 - val_auc: 0.8880 - val_loss: 0.5090\n",
      "Epoch 15/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9186 - auc: 0.9707 - loss: 0.3039 - val_accuracy: 0.7705 - val_auc: 0.8964 - val_loss: 0.4949\n",
      "Epoch 16/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9220 - auc: 0.9666 - loss: 0.3130 - val_accuracy: 0.7541 - val_auc: 0.8975 - val_loss: 0.4767\n",
      "Epoch 17/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9186 - auc: 0.9723 - loss: 0.3022 - val_accuracy: 0.7541 - val_auc: 0.8981 - val_loss: 0.4932\n",
      "Epoch 18/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9237 - auc: 0.9724 - loss: 0.2912 - val_accuracy: 0.7541 - val_auc: 0.8941 - val_loss: 0.5079\n",
      "Epoch 19/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9085 - auc: 0.9735 - loss: 0.2926 - val_accuracy: 0.7705 - val_auc: 0.8936 - val_loss: 0.4729\n",
      "Epoch 20/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9203 - auc: 0.9730 - loss: 0.2874 - val_accuracy: 0.7541 - val_auc: 0.8964 - val_loss: 0.5039\n",
      "Epoch 21/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9237 - auc: 0.9714 - loss: 0.2959 - val_accuracy: 0.7541 - val_auc: 0.8941 - val_loss: 0.4847\n",
      "Epoch 22/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9305 - auc: 0.9757 - loss: 0.2793 - val_accuracy: 0.7541 - val_auc: 0.8936 - val_loss: 0.4860\n",
      "Epoch 23/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9220 - auc: 0.9762 - loss: 0.2734 - val_accuracy: 0.7705 - val_auc: 0.8975 - val_loss: 0.4690\n",
      "Epoch 24/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9322 - auc: 0.9753 - loss: 0.2723 - val_accuracy: 0.7541 - val_auc: 0.8975 - val_loss: 0.4686\n",
      "Epoch 25/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9339 - auc: 0.9772 - loss: 0.2699 - val_accuracy: 0.7705 - val_auc: 0.8964 - val_loss: 0.4699\n",
      "Epoch 26/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9390 - auc: 0.9788 - loss: 0.2595 - val_accuracy: 0.7705 - val_auc: 0.8964 - val_loss: 0.4890\n",
      "Epoch 27/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9271 - auc: 0.9805 - loss: 0.2533 - val_accuracy: 0.8033 - val_auc: 0.8947 - val_loss: 0.4907\n",
      "Epoch 28/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9271 - auc: 0.9791 - loss: 0.2564 - val_accuracy: 0.7869 - val_auc: 0.8986 - val_loss: 0.4907\n",
      "Epoch 29/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9305 - auc: 0.9794 - loss: 0.2539 - val_accuracy: 0.7705 - val_auc: 0.9003 - val_loss: 0.4783\n",
      "Epoch 30/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9356 - auc: 0.9759 - loss: 0.2628 - val_accuracy: 0.7705 - val_auc: 0.9015 - val_loss: 0.4730\n",
      "Epoch 31/80\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9271 - auc: 0.9789 - loss: 0.2547 - val_accuracy: 0.7869 - val_auc: 0.8958 - val_loss: 0.4863\n",
      "Epoch 32/80\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9062 - auc: 0.9824 - loss: 0.2585"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19640\\451259872.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Optional: Print the search space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_space_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Run the search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m tuner.search(\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m# X_pretrain_train_res,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# y_pretrain_train_res,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mX_A_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;31m# Oracle is calculating, resend request.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFatalError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconfig_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[0;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuner_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTunerCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;31m# Only checkpoint the best epoch across all executions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# Save the build config for model loading later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;33m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \"\"\"\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    419\u001b[0m                         \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m                 val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m    424\u001b[0m                     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                     \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbegin_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                 \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weighted_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\metrics\\confusion_metrics.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1572\u001b[0m                 \u001b[0mvariable_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_thresholds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfalse_positives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1576\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_negatives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1577\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfalse_negatives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(shape, dtype)\u001b[0m\n\u001b[0;32m   7333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7334\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7335\u001b[0m         \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7336\u001b[0m     \"\"\"\n\u001b[1;32m-> 7337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(shape, dtype)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2590\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2591\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2592\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2593\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(shape, dtype, name, layout)\u001b[0m\n\u001b[0;32m   2651\u001b[0m         \u001b[1;31m# Happens when shape is a list with tensor elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2652\u001b[0m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2654\u001b[0m       \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Ensure it's a vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2655\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2656\u001b[0m   \u001b[1;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(dims, value, name, layout)\u001b[0m\n\u001b[0;32m    242\u001b[0m   \u001b[0mnumber\u001b[0m \u001b[0margument\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m`\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mvalid\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m`\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m   \u001b[0mspecifying\u001b[0m \u001b[0ma\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mD\u001b[0m \u001b[0mshaped\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mTensorFlow\u001b[0m \u001b[0mdoes\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msupport\u001b[0m \u001b[0mthis\u001b[0m \u001b[0msyntax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m   \"\"\"\n\u001b[1;32m--> 246\u001b[1;33m   result = d_api.call_with_layout(\n\u001b[0m\u001b[0;32m    247\u001b[0m       \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m   \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m   \u001b[0mshape_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\dtensor\\python\\api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(fn, layout, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_dtensor_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mrelayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(dims, value, name)\u001b[0m\n\u001b[0;32m   3621\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Fill\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3622\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3625\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3628\u001b[0m       return fill_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model_for_tuning,\n",
    "    objective='auc',  # Metric to MAXIMIZE during tuning\n",
    "    max_trials=30,        # Number of different models/hyperparameter combos to test\n",
    "    executions_per_trial=3, # Number of times to train each model to reduce randomness\n",
    "    directory='mlp_tuning', \n",
    "    project_name='heart_disease_pretrain'\n",
    ")\n",
    "\n",
    "# Optional: Print the search space\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Run the search\n",
    "tuner.search(\n",
    "    # X_pretrain_train_res, \n",
    "    # y_pretrain_train_res,\n",
    "    X_A_train, \n",
    "    y_A_train,\n",
    "    epochs=80, \n",
    "    validation_data=(X_A_val, y_A_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\n--- Optimal Hyperparameters ---\")\n",
    "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"L2 Reg: {best_hps.get('l2_reg')}\")\n",
    "print(f\"Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Neurons L1: {best_hps.get('neurons_l1')}\")\n",
    "\n",
    "# Retrieve the best model found\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be87d2-2bc6-4625-9aff-ebdb8ed66fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "best_params = best_hp.get_config()['values']\n",
    "\n",
    "print(\"--- Best Hyperparameters ---\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1df4cc-4459-498a-a4e1-6bc8757c079b",
   "metadata": {},
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b6deece6-fe3b-4e0e-beed-38de643fc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN THIS LINE IF YOU DO THE HYPERPARAMETER TUNING\n",
    "best_params = {\n",
    "    'learning_rate' : 0.01,\n",
    "    'l2_reg' : 0.0001,\n",
    "    'neurons_l1' : 96,\n",
    "    'dropout_rate' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "90ed9878-a295-4f60-b9fb-cc2c0715e139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │           \u001b[38;5;34m4,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m1,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m25\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,913</span> (27.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,913\u001b[0m (27.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,913</span> (27.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,913\u001b[0m (27.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_mlp_model(input_shape, best_params):\n",
    "    neurons_l1 = best_params['neurons_l1']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    l2_reg = best_params['l2_reg']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(neurons_l1, activation='relu', name='feature_layer_1', kernel_regularizer=keras.regularizers.l2(l2_reg))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/2), activation='relu', name='feature_layer_2', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/4), activation='relu', name='feature_layer_3', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# input_dim = X_pretrain_train_res.shape[1]\n",
    "input_dim = X_A_train.shape[1]\n",
    "mlp_pretrain = create_mlp_model(input_dim, best_params)\n",
    "mlp_pretrain.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "654d4553-dfdd-48c9-a387-9d970de06b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.8390 - auc: 0.9066 - loss: 0.4111 - val_accuracy: 0.7869 - val_auc: 0.9048 - val_loss: 0.4519\n",
      "Epoch 2/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8610 - auc: 0.9274 - loss: 0.3553 - val_accuracy: 0.8361 - val_auc: 0.9026 - val_loss: 0.3843\n",
      "Epoch 3/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8847 - auc: 0.9483 - loss: 0.3060 - val_accuracy: 0.8525 - val_auc: 0.9178 - val_loss: 0.3508\n",
      "Epoch 4/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - auc: 0.9607 - loss: 0.2710 - val_accuracy: 0.8197 - val_auc: 0.9093 - val_loss: 0.3510\n",
      "Epoch 5/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8949 - auc: 0.9660 - loss: 0.2541 - val_accuracy: 0.8361 - val_auc: 0.9105 - val_loss: 0.3537\n",
      "Epoch 6/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9169 - auc: 0.9719 - loss: 0.2257 - val_accuracy: 0.8525 - val_auc: 0.9178 - val_loss: 0.3558\n",
      "Epoch 7/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9085 - auc: 0.9673 - loss: 0.2449 - val_accuracy: 0.8361 - val_auc: 0.9122 - val_loss: 0.3574\n",
      "Epoch 8/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9102 - auc: 0.9672 - loss: 0.2418 - val_accuracy: 0.8197 - val_auc: 0.9037 - val_loss: 0.4030\n",
      "Epoch 9/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9169 - auc: 0.9734 - loss: 0.2205 - val_accuracy: 0.8361 - val_auc: 0.9082 - val_loss: 0.3764\n",
      "Epoch 10/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9119 - auc: 0.9716 - loss: 0.2286 - val_accuracy: 0.8525 - val_auc: 0.9048 - val_loss: 0.3878\n",
      "Epoch 11/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9271 - auc: 0.9795 - loss: 0.1978 - val_accuracy: 0.8197 - val_auc: 0.9065 - val_loss: 0.4371\n",
      "Epoch 12/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9305 - auc: 0.9813 - loss: 0.1848 - val_accuracy: 0.8361 - val_auc: 0.9003 - val_loss: 0.4631\n",
      "Epoch 13/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9237 - auc: 0.9794 - loss: 0.1957 - val_accuracy: 0.8197 - val_auc: 0.8958 - val_loss: 0.4307\n",
      "Epoch 14/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9237 - auc: 0.9802 - loss: 0.1965 - val_accuracy: 0.8689 - val_auc: 0.9071 - val_loss: 0.3907\n",
      "Epoch 15/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9373 - auc: 0.9838 - loss: 0.1723 - val_accuracy: 0.8197 - val_auc: 0.8975 - val_loss: 0.4766\n",
      "Epoch 16/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9153 - auc: 0.9712 - loss: 0.2424 - val_accuracy: 0.8361 - val_auc: 0.8998 - val_loss: 0.4132\n",
      "Epoch 17/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9305 - auc: 0.9843 - loss: 0.1851 - val_accuracy: 0.8525 - val_auc: 0.8964 - val_loss: 0.4654\n",
      "Epoch 18/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9339 - auc: 0.9825 - loss: 0.1830 - val_accuracy: 0.8361 - val_auc: 0.8829 - val_loss: 0.4717\n",
      "Epoch 19/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9390 - auc: 0.9877 - loss: 0.1561 - val_accuracy: 0.8525 - val_auc: 0.9003 - val_loss: 0.4798\n",
      "Epoch 20/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9458 - auc: 0.9869 - loss: 0.1554 - val_accuracy: 0.8525 - val_auc: 0.8902 - val_loss: 0.5141\n",
      "Epoch 21/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9424 - auc: 0.9906 - loss: 0.1459 - val_accuracy: 0.8525 - val_auc: 0.8857 - val_loss: 0.5877\n",
      "Epoch 22/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9424 - auc: 0.9853 - loss: 0.1678 - val_accuracy: 0.8689 - val_auc: 0.8863 - val_loss: 0.5396\n",
      "Epoch 23/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9339 - auc: 0.9856 - loss: 0.1749 - val_accuracy: 0.8361 - val_auc: 0.9127 - val_loss: 0.4649\n",
      "Epoch 24/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9339 - auc: 0.9857 - loss: 0.1749 - val_accuracy: 0.8033 - val_auc: 0.8784 - val_loss: 0.6050\n",
      "Epoch 25/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9288 - auc: 0.9863 - loss: 0.1682 - val_accuracy: 0.8361 - val_auc: 0.9127 - val_loss: 0.3991\n",
      "Epoch 26/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9424 - auc: 0.9855 - loss: 0.1731 - val_accuracy: 0.8361 - val_auc: 0.8896 - val_loss: 0.5692\n",
      "Epoch 27/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9322 - auc: 0.9865 - loss: 0.1729 - val_accuracy: 0.8852 - val_auc: 0.9020 - val_loss: 0.4327\n",
      "Epoch 28/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9424 - auc: 0.9918 - loss: 0.1407 - val_accuracy: 0.8525 - val_auc: 0.8598 - val_loss: 0.6826\n",
      "Epoch 29/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9373 - auc: 0.9898 - loss: 0.1544 - val_accuracy: 0.8525 - val_auc: 0.8727 - val_loss: 0.5366\n",
      "Epoch 30/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9542 - auc: 0.9915 - loss: 0.1375 - val_accuracy: 0.8033 - val_auc: 0.8761 - val_loss: 0.5823\n",
      "Epoch 31/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9525 - auc: 0.9909 - loss: 0.1519 - val_accuracy: 0.8033 - val_auc: 0.8801 - val_loss: 0.5385\n",
      "Epoch 32/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9576 - auc: 0.9921 - loss: 0.1439 - val_accuracy: 0.8197 - val_auc: 0.8801 - val_loss: 0.6465\n",
      "Epoch 33/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9644 - auc: 0.9930 - loss: 0.1378 - val_accuracy: 0.8361 - val_auc: 0.8688 - val_loss: 0.6626\n",
      "Epoch 34/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9407 - auc: 0.9889 - loss: 0.1654 - val_accuracy: 0.8361 - val_auc: 0.8756 - val_loss: 0.7134\n",
      "Epoch 35/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9458 - auc: 0.9861 - loss: 0.1783 - val_accuracy: 0.8033 - val_auc: 0.8818 - val_loss: 0.5366\n",
      "Epoch 36/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9525 - auc: 0.9922 - loss: 0.1420 - val_accuracy: 0.7869 - val_auc: 0.8874 - val_loss: 0.5792\n",
      "Epoch 37/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9593 - auc: 0.9954 - loss: 0.1200 - val_accuracy: 0.8197 - val_auc: 0.8666 - val_loss: 0.7156\n",
      "Epoch 38/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9593 - auc: 0.9957 - loss: 0.1161 - val_accuracy: 0.8525 - val_auc: 0.8615 - val_loss: 0.5993\n",
      "Epoch 39/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9661 - auc: 0.9950 - loss: 0.1130 - val_accuracy: 0.8033 - val_auc: 0.8716 - val_loss: 0.6950\n",
      "Epoch 40/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9610 - auc: 0.9957 - loss: 0.1147 - val_accuracy: 0.7705 - val_auc: 0.8637 - val_loss: 0.6916\n",
      "Epoch 41/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - auc: 0.9972 - loss: 0.1005 - val_accuracy: 0.8361 - val_auc: 0.8620 - val_loss: 0.9687\n",
      "Epoch 42/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9441 - auc: 0.9912 - loss: 0.1455 - val_accuracy: 0.7869 - val_auc: 0.8756 - val_loss: 0.6954\n",
      "Epoch 43/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9339 - auc: 0.9839 - loss: 0.1953 - val_accuracy: 0.8361 - val_auc: 0.8823 - val_loss: 0.5677\n",
      "Epoch 44/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9458 - auc: 0.9906 - loss: 0.1574 - val_accuracy: 0.8197 - val_auc: 0.8699 - val_loss: 0.5582\n",
      "Epoch 45/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9746 - auc: 0.9971 - loss: 0.1154 - val_accuracy: 0.7869 - val_auc: 0.8767 - val_loss: 0.6702\n",
      "Epoch 46/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - auc: 0.9956 - loss: 0.1128 - val_accuracy: 0.7213 - val_auc: 0.8508 - val_loss: 0.7743\n",
      "Epoch 47/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9593 - auc: 0.9936 - loss: 0.1365 - val_accuracy: 0.8197 - val_auc: 0.8497 - val_loss: 0.8568\n",
      "Epoch 48/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9559 - auc: 0.9920 - loss: 0.1472 - val_accuracy: 0.7869 - val_auc: 0.8682 - val_loss: 0.7185\n",
      "Epoch 49/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9644 - auc: 0.9952 - loss: 0.1229 - val_accuracy: 0.8033 - val_auc: 0.8649 - val_loss: 0.7662\n",
      "Epoch 50/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9678 - auc: 0.9956 - loss: 0.1151 - val_accuracy: 0.8197 - val_auc: 0.8604 - val_loss: 0.7977\n",
      "Epoch 51/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9644 - auc: 0.9951 - loss: 0.1226 - val_accuracy: 0.8033 - val_auc: 0.8446 - val_loss: 0.9931\n",
      "Epoch 52/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - auc: 0.9957 - loss: 0.1187 - val_accuracy: 0.7869 - val_auc: 0.8519 - val_loss: 0.8276\n",
      "Epoch 53/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9627 - auc: 0.9923 - loss: 0.1393 - val_accuracy: 0.7541 - val_auc: 0.8452 - val_loss: 1.0105\n",
      "Epoch 54/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - auc: 0.9967 - loss: 0.1095 - val_accuracy: 0.8361 - val_auc: 0.8671 - val_loss: 0.9159\n",
      "Epoch 55/150\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9390 - auc: 0.9852 - loss: 0.1948 - val_accuracy: 0.7541 - val_auc: 0.8559 - val_loss: 0.7587\n"
     ]
    }
   ],
   "source": [
    "pretrain_history = mlp_pretrain.fit(\n",
    "    # X_pretrain_train_res, \n",
    "    # y_pretrain_train_res,\n",
    "    X_A_train, \n",
    "    y_A_train,\n",
    "    epochs=150, # Start with a reasonable number of epochs\n",
    "    batch_size=32,\n",
    "    # validation_data=(X_pretrain_val, y_pretrain_val),\n",
    "    validation_data=(X_A_val, y_A_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=52, restore_best_weights=True)\n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the pre-trained weights using the required extension\n",
    "mlp_pretrain.save_weights('mlp_pretrain.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78806114-d3ef-4ba3-b5c8-e51be309a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.9077\n",
      "Max F1 Score at this threshold: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Use the fine-tune validation set (X_finetune_val) to find the threshold\n",
    "y_val_proba = mlp_pretrain.predict(X_B_val).ravel()\n",
    "precision, recall, thresholds = precision_recall_curve(y_B_val, y_val_proba)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6) # Added 1e-6 to prevent division by zero\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")\n",
    "\n",
    "# Now, use best_threshold instead of 0.5 for final testing (e.g., y_pred = (y_pred_proba > best_threshold).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2295ba14-c5ca-45c7-a0b9-064a2ecea201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Pretraining Test Accuracy on Source domain: 83.87%\n",
      "Pretraining Test F1 on Source domain: 86.84%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 89.19%\n",
      "Pretraining Test Specificity on Source domain: 76.00%\n",
      "Pretraining Test ROC-AUC on Source domain: 0.93%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\")\n",
    "\n",
    "y_pred_proba_a = mlp_pretrain.predict(X_A_test).ravel()\n",
    "\n",
    "\n",
    "# y_pred_a = (y_pred_proba_a > best_threshold).astype(int)\n",
    "\n",
    "y_pred_a = (y_pred_proba_a > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a = accuracy_score(y_A_test, y_pred_a) * 100\n",
    "f1_a = f1_score(y_A_test, y_pred_a) * 100\n",
    "roc_auc_a = roc_auc_score(y_A_test, y_pred_proba_a) * 100\n",
    "recall_a = recall_score(y_A_test, y_pred_a) * 100\n",
    "precision_a = precision_score(y_A_test, y_pred_a) * 100\n",
    "specificity_a = recall_score(y_A_test, y_pred_a, pos_label=0) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {accuracy_a:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {f1_a:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_a:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_a:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on Source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1a0ba920-aab0-487d-b8c5-58d22703692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Pretraining Test Accuracy on target domain: 77.42%\n",
      "Pretraining Test F1 on target domain: 78.79%\n",
      "Pretraining Test Recall (Sensitivity) on target domain: 92.86%\n",
      "Pretraining Test Specificity on target domain: 64.71%\n",
      "Pretraining Test ROC-AUC on target domain: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\")\n",
    "\n",
    "# Get raw probability predictions\n",
    "y_pred_proba_b = mlp_pretrain.predict(X_B_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "# y_pred_b = (y_pred_proba_b > best_threshold).astype(int)\n",
    "\n",
    "y_pred_b = (y_pred_proba_b > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b = accuracy_score(y_B_test, y_pred_b) * 100\n",
    "f1_b = f1_score(y_B_test, y_pred_b) * 100\n",
    "roc_auc_b = roc_auc_score(y_B_test, y_pred_proba_b) * 100\n",
    "recall_b = recall_score(y_B_test, y_pred_b) * 100\n",
    "precision_b = precision_score(y_B_test, y_pred_b) * 100\n",
    "specificity_b = recall_score(y_B_test, y_pred_b, pos_label=0) * 100\n",
    "\n",
    "print(f\"Pretraining Test Accuracy on target domain: {accuracy_b:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on target domain: {f1_b:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on target domain: {recall_b:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on target domain: {specificity_b:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on target domain: {roc_auc_score(y_finetune_test, y_pred_proba_b):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e01e12-434e-48a8-bd31-fe2a5ae61bbf",
   "metadata": {},
   "source": [
    "### Finetuning on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cdd7167-26dd-4d0c-9a56-ca4e44086c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │           \u001b[38;5;34m4,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │           \u001b[38;5;34m1,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m25\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,913</span> (27.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,913\u001b[0m (27.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,857</span> (22.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,857\u001b[0m (22.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> (4.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,056\u001b[0m (4.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def setup_fine_tuning(input_shape, pretrain_weights_path, best_params, fine_tune_lr=1e-1):\n",
    "    # Create the model with exactly the same architecture as pre-training\n",
    "    model_ft = create_mlp_model(input_shape, best_params)\n",
    "    \n",
    "    # Load pre-trained weights\n",
    "    model_ft.load_weights(pretrain_weights_path)\n",
    "\n",
    "    # Freeze layers for fine-tuning\n",
    "    model_ft.get_layer('feature_layer_1').trainable = False\n",
    "    model_ft.get_layer('feature_layer_2').trainable = True\n",
    "    model_ft.get_layer('feature_layer_3').trainable = True\n",
    "    \n",
    "    # Recompile with lower learning rate for fine-tuning\n",
    "    model_ft.compile(\n",
    "        optimizer=Adam(learning_rate=fine_tune_lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "\n",
    "    )\n",
    "    \n",
    "    finetune_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return model_ft, finetune_scheduler\n",
    "\n",
    "\n",
    "mlp_finetune, finetune_scheduler = setup_fine_tuning(\n",
    "    input_shape=input_dim,  # Use the input dimension from Dataset B\n",
    "    pretrain_weights_path='mlp_pretrain.weights.h5', \n",
    "    best_params=best_params,  # Add best_trial here\n",
    "    fine_tune_lr=0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Save the fine-tuned model weights (optional)\n",
    "mlp_finetune.save_weights('mlp_finetune_weights.weights.h5')\n",
    "\n",
    "# Check the model summary to ensure layers are frozen correctly\n",
    "mlp_finetune.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fc5d9c6-5dbc-425f-b6e0-5d5891ec0c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7901 - auc: 0.8504 - loss: 0.5963 - val_accuracy: 0.6000 - val_auc: 1.0000 - val_loss: 0.4510\n",
      "Epoch 2/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7443 - auc: 0.8408 - loss: 0.5430 - val_accuracy: 0.9333 - val_auc: 0.9955 - val_loss: 0.2813\n",
      "Epoch 3/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8130 - auc: 0.8780 - loss: 0.4971 - val_accuracy: 0.9667 - val_auc: 0.9955 - val_loss: 0.2628\n",
      "Epoch 4/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8359 - auc: 0.8979 - loss: 0.4474 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2467\n",
      "Epoch 5/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8473 - auc: 0.9096 - loss: 0.4180 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2538\n",
      "Epoch 6/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8244 - auc: 0.9013 - loss: 0.4466 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2624\n",
      "Epoch 7/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8244 - auc: 0.9147 - loss: 0.4056 - val_accuracy: 0.8667 - val_auc: 0.9799 - val_loss: 0.2480\n",
      "Epoch 8/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8588 - auc: 0.9142 - loss: 0.4003 - val_accuracy: 0.8667 - val_auc: 0.9710 - val_loss: 0.3462\n",
      "Epoch 9/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8435 - auc: 0.9016 - loss: 0.4705 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.3158\n",
      "Epoch 10/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8435 - auc: 0.9055 - loss: 0.4457 - val_accuracy: 0.9667 - val_auc: 0.9955 - val_loss: 0.2213\n",
      "Epoch 11/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8435 - auc: 0.9200 - loss: 0.4159 - val_accuracy: 0.9667 - val_auc: 0.9844 - val_loss: 0.2714\n",
      "Epoch 12/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8550 - auc: 0.9265 - loss: 0.3932 - val_accuracy: 0.9000 - val_auc: 0.9911 - val_loss: 0.2869\n",
      "Epoch 13/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8435 - auc: 0.9293 - loss: 0.3776 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3297\n",
      "Epoch 14/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8588 - auc: 0.9303 - loss: 0.4187 - val_accuracy: 0.9000 - val_auc: 0.9576 - val_loss: 0.3500\n",
      "Epoch 15/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8779 - auc: 0.9277 - loss: 0.3911 - val_accuracy: 0.9333 - val_auc: 0.9844 - val_loss: 0.2364\n",
      "Epoch 16/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8359 - auc: 0.9321 - loss: 0.3872 - val_accuracy: 0.9333 - val_auc: 0.9911 - val_loss: 0.2549\n",
      "Epoch 17/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8664 - auc: 0.9256 - loss: 0.4252 - val_accuracy: 0.9000 - val_auc: 0.9353 - val_loss: 0.4417\n",
      "Epoch 18/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8588 - auc: 0.9381 - loss: 0.3790 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3602\n",
      "Epoch 19/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8702 - auc: 0.9417 - loss: 0.3691 - val_accuracy: 0.9333 - val_auc: 0.9598 - val_loss: 0.4053\n",
      "Epoch 20/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8473 - auc: 0.9386 - loss: 0.3788 - val_accuracy: 0.9000 - val_auc: 0.9308 - val_loss: 0.4971\n",
      "Epoch 21/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8817 - auc: 0.9438 - loss: 0.3750 - val_accuracy: 0.9000 - val_auc: 0.9353 - val_loss: 0.4733\n",
      "Epoch 22/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8779 - auc: 0.9421 - loss: 0.3599 - val_accuracy: 0.9000 - val_auc: 0.9241 - val_loss: 0.5510\n",
      "Epoch 23/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8969 - auc: 0.9528 - loss: 0.3464 - val_accuracy: 0.9000 - val_auc: 0.9062 - val_loss: 0.9215\n",
      "Epoch 24/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8626 - auc: 0.9412 - loss: 0.3775 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.3601\n",
      "Epoch 25/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8702 - auc: 0.9403 - loss: 0.3732 - val_accuracy: 0.9000 - val_auc: 0.9754 - val_loss: 0.3149\n",
      "Epoch 26/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8588 - auc: 0.9270 - loss: 0.4244 - val_accuracy: 0.9000 - val_auc: 0.9308 - val_loss: 0.5528\n",
      "Epoch 27/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8779 - auc: 0.9447 - loss: 0.3926 - val_accuracy: 0.9000 - val_auc: 0.9353 - val_loss: 0.5248\n",
      "Epoch 28/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8588 - auc: 0.9432 - loss: 0.3757 - val_accuracy: 0.8000 - val_auc: 0.9241 - val_loss: 0.5827\n",
      "Epoch 29/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8817 - auc: 0.9397 - loss: 0.3767 - val_accuracy: 0.8333 - val_auc: 0.9420 - val_loss: 0.6549\n",
      "Epoch 30/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8435 - auc: 0.9227 - loss: 0.4438 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3895\n",
      "Epoch 31/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8779 - auc: 0.9502 - loss: 0.3762 - val_accuracy: 0.8667 - val_auc: 0.9420 - val_loss: 0.6688\n",
      "Epoch 32/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8817 - auc: 0.9533 - loss: 0.3643 - val_accuracy: 0.8333 - val_auc: 0.9219 - val_loss: 0.7966\n",
      "Epoch 33/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8855 - auc: 0.9487 - loss: 0.3693 - val_accuracy: 0.8667 - val_auc: 0.9241 - val_loss: 0.6468\n",
      "Epoch 34/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8817 - auc: 0.9485 - loss: 0.3689 - val_accuracy: 0.9000 - val_auc: 0.9509 - val_loss: 0.6879\n",
      "Epoch 35/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8817 - auc: 0.9355 - loss: 0.4180 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3766\n",
      "Epoch 36/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8740 - auc: 0.9422 - loss: 0.3971 - val_accuracy: 0.8667 - val_auc: 0.9330 - val_loss: 0.5357\n",
      "Epoch 37/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8893 - auc: 0.9546 - loss: 0.3583 - val_accuracy: 0.8667 - val_auc: 0.9554 - val_loss: 0.5579\n",
      "Epoch 38/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8626 - auc: 0.9441 - loss: 0.3845 - val_accuracy: 0.9000 - val_auc: 0.9420 - val_loss: 0.5242\n",
      "Epoch 39/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8893 - auc: 0.9532 - loss: 0.3577 - val_accuracy: 0.9000 - val_auc: 0.9330 - val_loss: 0.5133\n",
      "Epoch 40/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8855 - auc: 0.9534 - loss: 0.3532 - val_accuracy: 0.9000 - val_auc: 0.9286 - val_loss: 0.5908\n",
      "Epoch 41/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8626 - auc: 0.9447 - loss: 0.3883 - val_accuracy: 0.8333 - val_auc: 0.9509 - val_loss: 0.8977\n",
      "Epoch 42/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9046 - auc: 0.9506 - loss: 0.3555 - val_accuracy: 0.8667 - val_auc: 0.9509 - val_loss: 0.7109\n",
      "Epoch 43/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8893 - auc: 0.9524 - loss: 0.3637 - val_accuracy: 0.9000 - val_auc: 0.9442 - val_loss: 0.8091\n",
      "Epoch 44/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8931 - auc: 0.9483 - loss: 0.3496 - val_accuracy: 0.9000 - val_auc: 0.9554 - val_loss: 0.7594\n",
      "Epoch 45/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8855 - auc: 0.9478 - loss: 0.3615 - val_accuracy: 0.9000 - val_auc: 0.9353 - val_loss: 0.7673\n",
      "Epoch 46/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8740 - auc: 0.9208 - loss: 0.4188 - val_accuracy: 0.9333 - val_auc: 0.9263 - val_loss: 0.3271\n",
      "Epoch 47/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8626 - auc: 0.9361 - loss: 0.3808 - val_accuracy: 0.9000 - val_auc: 0.9554 - val_loss: 0.4646\n",
      "Epoch 48/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9008 - auc: 0.9509 - loss: 0.3865 - val_accuracy: 0.9000 - val_auc: 0.9375 - val_loss: 0.4637\n",
      "Epoch 49/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8779 - auc: 0.9501 - loss: 0.3586 - val_accuracy: 0.9000 - val_auc: 0.9487 - val_loss: 0.5196\n",
      "Epoch 50/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8626 - auc: 0.9338 - loss: 0.4084 - val_accuracy: 0.8667 - val_auc: 0.9420 - val_loss: 0.4721\n",
      "Epoch 51/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8779 - auc: 0.9480 - loss: 0.3648 - val_accuracy: 0.8667 - val_auc: 0.9576 - val_loss: 0.5833\n",
      "Epoch 52/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8740 - auc: 0.9473 - loss: 0.3689 - val_accuracy: 0.9000 - val_auc: 0.9621 - val_loss: 0.4325\n",
      "Epoch 53/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9084 - auc: 0.9573 - loss: 0.3249 - val_accuracy: 0.8667 - val_auc: 0.9554 - val_loss: 0.8380\n",
      "Epoch 54/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8817 - auc: 0.9518 - loss: 0.3637 - val_accuracy: 0.9333 - val_auc: 0.9509 - val_loss: 0.5173\n",
      "Epoch 55/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - auc: 0.9552 - loss: 0.3456 - val_accuracy: 0.8667 - val_auc: 0.9464 - val_loss: 0.3691\n",
      "Epoch 56/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8817 - auc: 0.9474 - loss: 0.3871 - val_accuracy: 0.8667 - val_auc: 0.9509 - val_loss: 0.3867\n",
      "Epoch 57/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8855 - auc: 0.9547 - loss: 0.3406 - val_accuracy: 0.9000 - val_auc: 0.9487 - val_loss: 0.4622\n",
      "Epoch 58/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8664 - auc: 0.9451 - loss: 0.3741 - val_accuracy: 0.8667 - val_auc: 0.9487 - val_loss: 0.5852\n",
      "Epoch 59/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8511 - auc: 0.9332 - loss: 0.4063 - val_accuracy: 0.8667 - val_auc: 0.9665 - val_loss: 0.4221\n",
      "Epoch 60/300\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8664 - auc: 0.9342 - loss: 0.4060 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3695\n",
      "Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\n"
     ]
    }
   ],
   "source": [
    "history_finetune = mlp_finetune.fit(\n",
    "    # X_finetune_train_res, \n",
    "    # y_finetune_train_res,\n",
    "    X_B_train, \n",
    "    y_B_train,\n",
    "    epochs=300, # Fewer epochs are usually needed for fine-tuning\n",
    "    batch_size=16, # Smaller batch size often works better for smaller datasets\n",
    "    validation_data=(X_B_val, y_B_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True), \n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "194686bb-1fa6-4c31-afd9-23ebc85b3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.3637\n",
      "Max F1 Score at this threshold: 0.9655\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Use the fine-tune validation set (X_finetune_val) to find the optimal threshold ---\n",
    "y_val_proba_ft = mlp_finetune.predict(X_B_val).ravel()  # Raw probability predictions\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_B_val, y_val_proba_ft)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6)  # Adding 1e-6 to prevent division by zero\n",
    "\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_finetune_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_finetune_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5c47083e-617e-4efb-9637-cf8d8aa52515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Finetune Test Accuracy on source domain: 77.42%\n",
      "Finetune Test F1 on source domain: 82.50%\n",
      "Finetune Test Recall (Sensitivity) on source domain: 89.19%\n",
      "Finetune Test Specificity on source domain: 60.00%\n",
      "Finetune Test ROC-AUC on source domain: 0.84%\n"
     ]
    }
   ],
   "source": [
    "# Get raw probability predictions\n",
    "y_pred_proba_a_ft = mlp_finetune.predict(X_A_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_a_ft = (y_pred_proba_a_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a_ft = accuracy_score(y_A_test, y_pred_a_ft) * 100\n",
    "f1_a_ft = f1_score(y_A_test, y_pred_a_ft) * 100\n",
    "roc_auc_a_ft = roc_auc_score(y_A_test, y_pred_proba_a_ft) * 100\n",
    "recall_a_ft = recall_score(y_A_test, y_pred_a_ft) * 100\n",
    "precision_a_ft = precision_score(y_A_test, y_pred_a_ft) * 100\n",
    "specificity_a_ft = recall_score(y_A_test, y_pred_a_ft, pos_label=0) * 100\n",
    "\n",
    "print(f\"Finetune Test Accuracy on source domain: {accuracy_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on source domain: {f1_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on source domain: {recall_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on source domain: {specificity_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a_ft):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
