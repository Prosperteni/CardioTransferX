{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bcfb71-06cb-4875-a056-d0c6e7a1e03f",
   "metadata": {},
   "source": [
    "# <font size=5> <strong>Heart Disease Prediction - AblationStudy(Feature Selection and SMOTE)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f549498-ec6a-486b-a9fa-8bc07bd6aa5b",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d3eb7e-461a-4535-821a-ef64396d461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import(accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
    "                            auc, confusion_matrix, classification_report, make_scorer)\n",
    "\n",
    "# Modeling â€“ XGBoost and TabNet\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "import random\n",
    "import os\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "xgb.set_config(verbosity=0)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a94f5b-532a-4c85-b045-0754856c43e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed5e14-1c39-4cd1-b6a0-f7175bdf4f3d",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae88cdd-d479-4855-837e-85e887c863f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_csv(\"Cleveland+Hungary+VA_long_beach+Switzerland.csv\") # Source domain = multi-hospital dataset\n",
    "df_B = pd.read_csv(\"Heart_disease_cleveland.csv\")                     # Target domain = original Cleveland dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4042b1b-b974-4412-9a46-ad17daa5779f",
   "metadata": {},
   "source": [
    "### Exploring and Inspecting Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154cc2bf-576d-4b87-9108-5892e1736f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 919 entries, 0 to 918\n",
      "Data columns (total 16 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        919 non-null    int64  \n",
      " 1   age       919 non-null    int64  \n",
      " 2   sex       919 non-null    object \n",
      " 3   dataset   919 non-null    object \n",
      " 4   cp        919 non-null    object \n",
      " 5   trestbps  919 non-null    float64\n",
      " 6   chol      919 non-null    float64\n",
      " 7   fbs       919 non-null    bool   \n",
      " 8   restecg   919 non-null    object \n",
      " 9   thalch    919 non-null    float64\n",
      " 10  exang     919 non-null    bool   \n",
      " 11  oldpeak   919 non-null    float64\n",
      " 12  slope     919 non-null    object \n",
      " 13  ca        919 non-null    float64\n",
      " 14  thal      919 non-null    object \n",
      " 15  num       919 non-null    int64  \n",
      "dtypes: bool(2), float64(5), int64(3), object(6)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_A.info() # Displays concise summary of DataFrame A: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4569bfa4-2b5a-4e51-b930-0695fb312a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_B.info() # Displays concise summary of DataFrame B: index range, column names, non-null counts, and data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e990a-d349-4170-bb43-96a53e2a7ede",
   "metadata": {},
   "source": [
    "##### Cleaning and harmonizing information in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9653ec03-f608-4290-82f6-d6a39b3ef5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets before preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m                       0               1                  2\n",
      "id                     1               2                  3\n",
      "age                   63              67                 67\n",
      "sex                 Male            Male               Male\n",
      "dataset        Cleveland       Cleveland          Cleveland\n",
      "cp        typical angina    asymptomatic       asymptomatic\n",
      "trestbps           145.0           160.0              120.0\n",
      "chol               233.0           286.0              229.0\n",
      "fbs                 True           False              False\n",
      "restecg   lv hypertrophy  lv hypertrophy     lv hypertrophy\n",
      "thalch             150.0           108.0              129.0\n",
      "exang              False            True               True\n",
      "oldpeak              2.3             1.5                2.6\n",
      "slope        downsloping            flat               flat\n",
      "ca                   0.0             3.0                2.0\n",
      "thal        fixed defect          normal  reversable defect\n",
      "num                    0               2                  1\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "age        63.0   67.0   67.0\n",
      "sex         1.0    1.0    1.0\n",
      "cp          0.0    3.0    3.0\n",
      "trestbps  145.0  160.0  120.0\n",
      "chol      233.0  286.0  229.0\n",
      "fbs         1.0    0.0    0.0\n",
      "restecg     2.0    2.0    2.0\n",
      "thalach   150.0  108.0  129.0\n",
      "exang       0.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "slope       2.0    1.0    1.0\n",
      "ca          0.0    3.0    2.0\n",
      "thal        2.0    1.0    3.0\n",
      "target      0.0    1.0    1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets before preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2df8ede-ec12-435d-96b3-69ea3f3ba6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Cleveland data from df_A before pretraining\n",
    "df_A = df_A[df_A['dataset'] != 'Cleveland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f871dd-ca19-4a0c-a2f0-5bf65455002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',\n",
      "       'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'],\n",
      "      dtype='object')\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_A.columns) # Prints the list of column names in DataFrame A.\n",
    "print(df_B.columns) # Prints the list of column names in DataFrame B."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edb2754-fbd5-44da-a9a9-310d6f34d472",
   "metadata": {},
   "source": [
    "1. We inspected the datasets using df.info(), df.columns, and df.head().\n",
    "#    Observations from Dataset A (combined multi-hospital dataset):\n",
    "- Many categorical columns (sex, cp, fbs, restecg, slope, thal, exang) are strings/booleans.\n",
    "- Some numeric columns have missing values (trestbps, chol, thalach, oldpeak, ca).\n",
    "- Column names differ from Dataset B (e.g., 'thalch' vs 'thalach', 'num' vs 'target').\n",
    "- Extra columns exist (e.g., 'id', 'dataset') that are irrelevant for modeling.\n",
    "- The target column uses 0â€“4 scale instead of 0/1 like Dataset B.\n",
    "\n",
    "#    Observations from Dataset B (Cleveland dataset):\n",
    "- All categorical columns are already numeric (int64), matching expected encoding.\n",
    "- No missing values.\n",
    "- Target column is binary (0=no disease, 1=disease).\n",
    "\n",
    "2. Based on these observations, the following harmonization steps are necessary:\n",
    "- Rename columns in Dataset A to match Dataset B.\n",
    "- Drop irrelevant columns in Dataset A (id, dataset).\n",
    "- Map all categorical strings/booleans in Dataset A to numeric codes matching Dataset B.\n",
    "- Fill missing values: \n",
    "#           â€¢ Categorical â†’ mode of column\n",
    "#           â€¢ Numeric â†’ median of column\n",
    "- Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "- Align features so both datasets have identical column names and encodings.\n",
    "\n",
    "3. Purpose:\n",
    "- Ensure that Dataset A (pretraining) and Dataset B (fine-tuning) are fully compatible.\n",
    "- Prevent encoding mismatches that would break transfer learning.\n",
    "- Guarantee that the XGBoost model receives numeric input for all features.\n",
    "- Maintain consistency for feature importance and SHAP explainability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856b1cf3-d252-4c47-a02e-1450c084d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.rename(columns={'thalch': 'thalach','num': 'target'}) #Rename columns in Dataset A to match Dataset B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0bc1c1-cea8-40ab-b12e-5e694f524027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_A.drop(columns=['id', 'dataset']) #Drop irrelevant columns in Dataset A (id, dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1915aeb1-8cdf-4f58-a0a6-20c303b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target column in Dataset A to binary (0=no disease, 1=disease)\n",
    "df_A['target'] = df_A['target'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae38850-7e49-4efc-b2e2-ccb20ca3da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all categorical strings/booleans in Dataset A to numeric codes matching the target domain.\n",
    "sex_map = {'Male': 1, 'Female': 0}\n",
    "\n",
    "cp_map = {\n",
    "    'typical angina': 0,\n",
    "    'atypical angina': 1,\n",
    "    'non-anginal': 2,\n",
    "    'asymptomatic': 3\n",
    "}\n",
    "\n",
    "fbs_map = {True: 1, False: 0}\n",
    "\n",
    "restecg_map = {\n",
    "    'normal': 0,\n",
    "    'st-t abnormality': 1,\n",
    "    'lv hypertrophy': 2\n",
    "}\n",
    "\n",
    "exang_map = {True: 1, False: 0}\n",
    "\n",
    "slope_map = {\n",
    "    'upsloping': 0,\n",
    "    'flat': 1,\n",
    "    'downsloping': 2\n",
    "}\n",
    "\n",
    "thal_map = {\n",
    "    'normal': 1,\n",
    "    'fixed defect': 2,\n",
    "    'reversable defect': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2ac638-c3d6-4ad2-b138-6de8b87454a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features so both datasets have identical column names and encodings.\n",
    "df_A['sex'] = df_A['sex'].map(sex_map)\n",
    "df_A['cp'] = df_A['cp'].map(cp_map)\n",
    "df_A['fbs'] = df_A['fbs'].map(fbs_map)\n",
    "df_A['restecg'] = df_A['restecg'].map(restecg_map)\n",
    "df_A['exang'] = df_A['exang'].map(exang_map)\n",
    "df_A['slope'] = df_A['slope'].map(slope_map)\n",
    "df_A['thal'] = df_A['thal'].map(thal_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e875d2bd-fdd7-4f55-98d3-b73e4b58589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final Check (Both should return zero missing values.)\n",
    "print(df_A.isnull().sum())\n",
    "print(df_B.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed95ab7-b7dd-4f15-be3c-fb4b6bf2c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       615 non-null    int64  \n",
      " 1   sex       615 non-null    int64  \n",
      " 2   cp        615 non-null    int64  \n",
      " 3   trestbps  615 non-null    float64\n",
      " 4   chol      615 non-null    float64\n",
      " 5   fbs       615 non-null    int64  \n",
      " 6   restecg   615 non-null    int64  \n",
      " 7   thalach   615 non-null    float64\n",
      " 8   exang     615 non-null    int64  \n",
      " 9   oldpeak   615 non-null    float64\n",
      " 10  slope     615 non-null    int64  \n",
      " 11  ca        615 non-null    float64\n",
      " 12  thal      615 non-null    int64  \n",
      " 13  target    615 non-null    int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 72.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the target domain to ensure all columns are non-null.\n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bd4404-68aa-497c-8c21-7b57d80c56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for the source domain to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "942f2971-925d-45e2-a4cb-c175fb3f4785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>615.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.092683</td>\n",
       "      <td>0.842276</td>\n",
       "      <td>2.297561</td>\n",
       "      <td>133.209366</td>\n",
       "      <td>178.288276</td>\n",
       "      <td>0.151220</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>130.435220</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.942377</td>\n",
       "      <td>0.808130</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>2.347967</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.544659</td>\n",
       "      <td>0.364778</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>18.305233</td>\n",
       "      <td>122.310526</td>\n",
       "      <td>0.358554</td>\n",
       "      <td>0.611066</td>\n",
       "      <td>24.077586</td>\n",
       "      <td>0.499294</td>\n",
       "      <td>1.099715</td>\n",
       "      <td>0.578326</td>\n",
       "      <td>0.689712</td>\n",
       "      <td>0.887421</td>\n",
       "      <td>0.490297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>142.450000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean    53.092683    0.842276    2.297561  133.209366  178.288276    0.151220   \n",
       "std      9.544659    0.364778    0.913655   18.305233  122.310526    0.358554   \n",
       "min     29.000000    0.000000    0.000000   80.000000    0.000000    0.000000   \n",
       "25%     47.000000    1.000000    2.000000  120.000000    0.000000    0.000000   \n",
       "50%     54.000000    1.000000    3.000000  130.000000  216.000000    0.000000   \n",
       "75%     60.000000    1.000000    3.000000  142.450000  263.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  603.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  615.000000  615.000000  615.000000  615.000000  615.000000  615.000000   \n",
       "mean     0.414634  130.435220    0.466667    0.942377    0.808130    0.422764   \n",
       "std      0.611066   24.077586    0.499294    1.099715    0.578326    0.689712   \n",
       "min      0.000000   60.000000    0.000000   -2.600000    0.000000    0.000000   \n",
       "25%      0.000000  116.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000  129.000000    0.000000    0.700000    1.000000    0.000000   \n",
       "75%      1.000000  148.000000    1.000000    2.000000    1.000000    1.000000   \n",
       "max      2.000000  190.000000    1.000000    5.000000    2.000000    2.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  615.000000  615.000000  \n",
       "mean     2.347967    0.600000  \n",
       "std      0.887421    0.490297  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      3.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measure about the dataset A\n",
    "df_A.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93a17240-a2d2-4928-8760-ae4a4e1c2004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>2.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>0.600660</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>1.831683</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.956705</td>\n",
       "      <td>0.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    2.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    2.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    2.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    3.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    0.600660    0.663366   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.934375   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    1.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    3.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     1.831683    0.458746  \n",
       "std      0.956705    0.499120  \n",
       "min      1.000000    0.000000  \n",
       "25%      1.000000    0.000000  \n",
       "50%      1.000000    0.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measure about the dataset B\n",
    "df_B.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a6f21b3-09fa-4906-bcd0-787cec6e8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleanedup dataset A\n",
    "df_A.to_csv(\"Preprocessed_Cleveland+Hungary+VA_long_beach+Switzerland.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1379d430-3f33-4601-b561-d88b27bfb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleanedup dataset B\n",
    "df_B.to_csv(\"Preprocessed_Heart_disease_cleveland.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d65ebbf-ecdc-4821-9ae1-fd383ac64e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDatasets after preprocessing:\u001b[0m\n",
      "\u001b[1mMulti-hospital Dataset:\u001b[0m\n",
      "\u001b[1m            304     305    306\n",
      "age        29.0   29.00   30.0\n",
      "sex         1.0    1.00    0.0\n",
      "cp          1.0    1.00    0.0\n",
      "trestbps  120.0  140.00  170.0\n",
      "chol      243.0  240.48  237.0\n",
      "fbs         0.0    0.00    0.0\n",
      "restecg     0.0    0.00    1.0\n",
      "thalach   160.0  170.00  170.0\n",
      "exang       0.0    0.00    0.0\n",
      "oldpeak     0.0    0.00    0.0\n",
      "slope       0.0    0.00    0.0\n",
      "ca          0.0    0.00    0.0\n",
      "thal        1.0    1.00    2.0\n",
      "target      0.0    0.00    0.0\u001b[0m\n",
      "\n",
      "\u001b[1mCleveland Dataset:\u001b[0m\n",
      "\u001b[1m              0      1      2\n",
      "age        63.0   67.0   67.0\n",
      "sex         1.0    1.0    1.0\n",
      "cp          0.0    3.0    3.0\n",
      "trestbps  145.0  160.0  120.0\n",
      "chol      233.0  286.0  229.0\n",
      "fbs         1.0    0.0    0.0\n",
      "restecg     2.0    2.0    2.0\n",
      "thalach   150.0  108.0  129.0\n",
      "exang       0.0    1.0    1.0\n",
      "oldpeak     2.3    1.5    2.6\n",
      "slope       2.0    1.0    1.0\n",
      "ca          0.0    3.0    2.0\n",
      "thal        2.0    1.0    3.0\n",
      "target      0.0    1.0    1.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "print(f\"{BOLD}Datasets after preprocessing:{END}\")\n",
    "\n",
    "print(f\"{BOLD}Multi-hospital Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_A.head(3).T.to_string(line_width=1000)}{END}\")\n",
    "\n",
    "print(f\"\\n{BOLD}Cleveland Dataset:{END}\")\n",
    "# Changed .head() to .head(3)\n",
    "print(f\"{BOLD}{df_B.head(3).T.to_string(line_width=1000)}{END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2989af38-42d7-4737-877a-165b905ea3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 615 entries, 304 to 918\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       615 non-null    int64  \n",
      " 1   sex       615 non-null    int64  \n",
      " 2   cp        615 non-null    int64  \n",
      " 3   trestbps  615 non-null    float64\n",
      " 4   chol      615 non-null    float64\n",
      " 5   fbs       615 non-null    int64  \n",
      " 6   restecg   615 non-null    int64  \n",
      " 7   thalach   615 non-null    float64\n",
      " 8   exang     615 non-null    int64  \n",
      " 9   oldpeak   615 non-null    float64\n",
      " 10  slope     615 non-null    int64  \n",
      " 11  ca        615 non-null    float64\n",
      " 12  thal      615 non-null    int64  \n",
      " 13  target    615 non-null    int64  \n",
      "dtypes: float64(5), int64(9)\n",
      "memory usage: 72.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for dataset A to ensure all columns are non-null. \n",
    "df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a42ddf0-70a5-4544-becd-878ea6d9fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Do a final check for dataset B to ensure all columns are non-null. \n",
    "df_B.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159229f-e4d9-4664-8d8f-e1580b957da5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Data split and NO class imbalance handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d69b4881-6507-4e0d-97c5-f4669664b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pretrain = df_A.drop('target', axis=1) \n",
    "y_pretrain = df_A['target']               \n",
    "\n",
    "# Split the source domain into 80% train and 20% temp (for val+test)\n",
    "X_pretrain_train, X_pretrain_temp, y_pretrain_train, y_pretrain_temp = train_test_split(\n",
    "    X_pretrain, y_pretrain,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test)\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test â†’ each 10% of total\n",
    "X_pretrain_val, X_pretrain_test, y_pretrain_val, y_pretrain_test = train_test_split(\n",
    "    X_pretrain_temp, y_pretrain_temp,\n",
    "    test_size=0.5,          # half of temp = 10% of total\n",
    "    random_state=42,\n",
    "    stratify=y_pretrain_temp\n",
    ")\n",
    "\n",
    "# Target domain: Cleveland dataset for FINE-TUNING and evaluation\n",
    "X_finetune = df_B.drop('target', axis=1)\n",
    "y_finetune = df_B['target']\n",
    "\n",
    "\n",
    "# Split target domain into 80% train and 20% temp (for val+test)\n",
    "X_finetune_train, X_finetune_temp, y_finetune_train, y_finetune_temp = train_test_split(\n",
    "    X_finetune, y_finetune,\n",
    "    test_size=0.2,          # 20% goes to temp (val+test) \n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune     # preserve class distribution\n",
    ")\n",
    "\n",
    "# Split temp into 50% validation and 50% test â†’ each 10% of total\n",
    "X_finetune_val, X_finetune_test, y_finetune_val, y_finetune_test = train_test_split(\n",
    "    X_finetune_temp, y_finetune_temp,\n",
    "    test_size=0.5,          # 20% of training data will be used as the validation set\n",
    "    random_state=42,        # reproducible splits\n",
    "    stratify=y_finetune_temp  # preserve class distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "260d9c15-74da-40eb-a352-35ea458bc166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ðŸ“Š Source Domain Shapes ##\n",
      "---\n",
      "X_pretrain_train shape: (492, 13)\n",
      "X_pretrain_val   shape: (61, 13)\n",
      "X_pretrain_test  shape: (62, 13)\n",
      "Total X rows: 615\n",
      "\n",
      "\n",
      "y_pretrain_train shape: (492,)\n",
      "y_pretrain_val   shape: (61,)\n",
      "y_pretrain_test  shape: (62,)\n",
      "\n",
      "## ðŸŽ¯ Target Domain Shapes ##\n",
      "---\n",
      "X_finetune_train shape: (242, 13)\n",
      "X_finetune_val   shape: (30, 13)\n",
      "X_finetune_test  shape: (31, 13)\n",
      "Total X rows: 303\n",
      "\n",
      "\n",
      "y_finetune_train shape: (242,)\n",
      "y_finetune_val   shape: (30,)\n",
      "y_finetune_test  shape: (31,)\n"
     ]
    }
   ],
   "source": [
    "print(\"## ðŸ“Š Source Domain Shapes ##\")\n",
    "print(\"---\")\n",
    "\n",
    "# Feature Matrix (X) Shapes\n",
    "print(\"X_pretrain_train shape:\", X_pretrain_train.shape)\n",
    "print(\"X_pretrain_val   shape:\", X_pretrain_val.shape)\n",
    "print(\"X_pretrain_test  shape:\", X_pretrain_test.shape)\n",
    "print(\"Total X rows:\", \n",
    "      X_pretrain_train.shape[0] + X_pretrain_val.shape[0] + X_pretrain_test.shape[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Target Vector (y) Shapes\n",
    "print(\"y_pretrain_train shape:\", y_pretrain_train.shape)\n",
    "print(\"y_pretrain_val   shape:\", y_pretrain_val.shape)\n",
    "print(\"y_pretrain_test  shape:\", y_pretrain_test.shape)\n",
    "\n",
    "\n",
    "## --- Target domain Splits ---\n",
    "print(\"\\n## ðŸŽ¯ Target Domain Shapes ##\")\n",
    "print(\"---\")\n",
    "\n",
    "# Feature Matrix (X) Shapes\n",
    "print(\"X_finetune_train shape:\", X_finetune_train.shape)\n",
    "print(\"X_finetune_val   shape:\", X_finetune_val.shape)\n",
    "print(\"X_finetune_test  shape:\", X_finetune_test.shape)\n",
    "print(\"Total X rows:\", \n",
    "      X_finetune_train.shape[0] + X_finetune_val.shape[0] + X_finetune_test.shape[0]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Target Vector (y) Shapes\n",
    "print(\"y_finetune_train shape:\", y_finetune_train.shape)\n",
    "print(\"y_finetune_val   shape:\", y_finetune_val.shape)\n",
    "print(\"y_finetune_test  shape:\", y_finetune_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21018af5-37a7-4e67-878e-39dfb70cb439",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a6b5e-ed72-44d9-afb4-d1c9a756ceb7",
   "metadata": {},
   "source": [
    "### Pretraining on the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb972dad-3d65-4aa5-9a35-17ef70094585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best parameters found during the Grid Search for pretraining on Dataset A\n",
    "best_pretrain_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 8,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 0.5, \n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "# Best parameters for pretraining: {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 6,\n",
    "#                                   'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
    "# Best F1-score: 0.8647\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ff71334-005f-4c43-85e7-ad7ef8d86ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.01\n",
      "  max_depth: 8\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 0.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.66624\n",
      "[1]\tvalidation_0-logloss:0.66229\n",
      "[2]\tvalidation_0-logloss:0.65750\n",
      "[3]\tvalidation_0-logloss:0.65223\n",
      "[4]\tvalidation_0-logloss:0.64784\n",
      "[5]\tvalidation_0-logloss:0.64344\n",
      "[6]\tvalidation_0-logloss:0.63863\n",
      "[7]\tvalidation_0-logloss:0.63429\n",
      "[8]\tvalidation_0-logloss:0.63087\n",
      "[9]\tvalidation_0-logloss:0.62699\n",
      "[10]\tvalidation_0-logloss:0.62453\n",
      "[11]\tvalidation_0-logloss:0.62045\n",
      "[12]\tvalidation_0-logloss:0.61704\n",
      "[13]\tvalidation_0-logloss:0.61283\n",
      "[14]\tvalidation_0-logloss:0.60925\n",
      "[15]\tvalidation_0-logloss:0.60645\n",
      "[16]\tvalidation_0-logloss:0.60294\n",
      "[17]\tvalidation_0-logloss:0.60002\n",
      "[18]\tvalidation_0-logloss:0.59610\n",
      "[19]\tvalidation_0-logloss:0.59220\n",
      "[20]\tvalidation_0-logloss:0.58906\n",
      "[21]\tvalidation_0-logloss:0.58540\n",
      "[22]\tvalidation_0-logloss:0.58208\n",
      "[23]\tvalidation_0-logloss:0.57957\n",
      "[24]\tvalidation_0-logloss:0.57656\n",
      "[25]\tvalidation_0-logloss:0.57371\n",
      "[26]\tvalidation_0-logloss:0.57072\n",
      "[27]\tvalidation_0-logloss:0.56806\n",
      "[28]\tvalidation_0-logloss:0.56493\n",
      "[29]\tvalidation_0-logloss:0.56143\n",
      "[30]\tvalidation_0-logloss:0.55821\n",
      "[31]\tvalidation_0-logloss:0.55567\n",
      "[32]\tvalidation_0-logloss:0.55369\n",
      "[33]\tvalidation_0-logloss:0.55031\n",
      "[34]\tvalidation_0-logloss:0.54743\n",
      "[35]\tvalidation_0-logloss:0.54525\n",
      "[36]\tvalidation_0-logloss:0.54246\n",
      "[37]\tvalidation_0-logloss:0.54042\n",
      "[38]\tvalidation_0-logloss:0.53813\n",
      "[39]\tvalidation_0-logloss:0.53588\n",
      "[40]\tvalidation_0-logloss:0.53380\n",
      "[41]\tvalidation_0-logloss:0.53201\n",
      "[42]\tvalidation_0-logloss:0.52925\n",
      "[43]\tvalidation_0-logloss:0.52735\n",
      "[44]\tvalidation_0-logloss:0.52472\n",
      "[45]\tvalidation_0-logloss:0.52298\n",
      "[46]\tvalidation_0-logloss:0.52096\n",
      "[47]\tvalidation_0-logloss:0.51931\n",
      "[48]\tvalidation_0-logloss:0.51726\n",
      "[49]\tvalidation_0-logloss:0.51478\n",
      "[50]\tvalidation_0-logloss:0.51285\n",
      "[51]\tvalidation_0-logloss:0.51119\n",
      "[52]\tvalidation_0-logloss:0.50913\n",
      "[53]\tvalidation_0-logloss:0.50703\n",
      "[54]\tvalidation_0-logloss:0.50482\n",
      "[55]\tvalidation_0-logloss:0.50303\n",
      "[56]\tvalidation_0-logloss:0.50144\n",
      "[57]\tvalidation_0-logloss:0.50012\n",
      "[58]\tvalidation_0-logloss:0.49819\n",
      "[59]\tvalidation_0-logloss:0.49579\n",
      "[60]\tvalidation_0-logloss:0.49356\n",
      "[61]\tvalidation_0-logloss:0.49258\n",
      "[62]\tvalidation_0-logloss:0.49093\n",
      "[63]\tvalidation_0-logloss:0.48879\n",
      "[64]\tvalidation_0-logloss:0.48716\n",
      "[65]\tvalidation_0-logloss:0.48582\n",
      "[66]\tvalidation_0-logloss:0.48463\n",
      "[67]\tvalidation_0-logloss:0.48310\n",
      "[68]\tvalidation_0-logloss:0.48128\n",
      "[69]\tvalidation_0-logloss:0.47945\n",
      "[70]\tvalidation_0-logloss:0.47790\n",
      "[71]\tvalidation_0-logloss:0.47645\n",
      "[72]\tvalidation_0-logloss:0.47509\n",
      "[73]\tvalidation_0-logloss:0.47379\n",
      "[74]\tvalidation_0-logloss:0.47244\n",
      "[75]\tvalidation_0-logloss:0.47043\n",
      "[76]\tvalidation_0-logloss:0.46912\n",
      "[77]\tvalidation_0-logloss:0.46834\n",
      "[78]\tvalidation_0-logloss:0.46715\n",
      "[79]\tvalidation_0-logloss:0.46563\n",
      "[80]\tvalidation_0-logloss:0.46492\n",
      "[81]\tvalidation_0-logloss:0.46341\n",
      "[82]\tvalidation_0-logloss:0.46216\n",
      "[83]\tvalidation_0-logloss:0.46125\n",
      "[84]\tvalidation_0-logloss:0.45968\n",
      "[85]\tvalidation_0-logloss:0.45855\n",
      "[86]\tvalidation_0-logloss:0.45748\n",
      "[87]\tvalidation_0-logloss:0.45653\n",
      "[88]\tvalidation_0-logloss:0.45584\n",
      "[89]\tvalidation_0-logloss:0.45517\n",
      "[90]\tvalidation_0-logloss:0.45381\n",
      "[91]\tvalidation_0-logloss:0.45284\n",
      "[92]\tvalidation_0-logloss:0.45192\n",
      "[93]\tvalidation_0-logloss:0.45056\n",
      "[94]\tvalidation_0-logloss:0.44931\n",
      "[95]\tvalidation_0-logloss:0.44863\n",
      "[96]\tvalidation_0-logloss:0.44756\n",
      "[97]\tvalidation_0-logloss:0.44657\n",
      "[98]\tvalidation_0-logloss:0.44584\n",
      "[99]\tvalidation_0-logloss:0.44458\n",
      "[100]\tvalidation_0-logloss:0.44351\n",
      "[101]\tvalidation_0-logloss:0.44295\n",
      "[102]\tvalidation_0-logloss:0.44176\n",
      "[103]\tvalidation_0-logloss:0.44042\n",
      "[104]\tvalidation_0-logloss:0.43918\n",
      "[105]\tvalidation_0-logloss:0.43852\n",
      "[106]\tvalidation_0-logloss:0.43716\n",
      "[107]\tvalidation_0-logloss:0.43649\n",
      "[108]\tvalidation_0-logloss:0.43546\n",
      "[109]\tvalidation_0-logloss:0.43465\n",
      "[110]\tvalidation_0-logloss:0.43392\n",
      "[111]\tvalidation_0-logloss:0.43334\n",
      "[112]\tvalidation_0-logloss:0.43214\n",
      "[113]\tvalidation_0-logloss:0.43120\n",
      "[114]\tvalidation_0-logloss:0.43068\n",
      "[115]\tvalidation_0-logloss:0.42982\n",
      "[116]\tvalidation_0-logloss:0.42935\n",
      "[117]\tvalidation_0-logloss:0.42870\n",
      "[118]\tvalidation_0-logloss:0.42787\n",
      "[119]\tvalidation_0-logloss:0.42691\n",
      "[120]\tvalidation_0-logloss:0.42573\n",
      "[121]\tvalidation_0-logloss:0.42485\n",
      "[122]\tvalidation_0-logloss:0.42427\n",
      "[123]\tvalidation_0-logloss:0.42348\n",
      "[124]\tvalidation_0-logloss:0.42212\n",
      "[125]\tvalidation_0-logloss:0.42149\n",
      "[126]\tvalidation_0-logloss:0.42041\n",
      "[127]\tvalidation_0-logloss:0.42038\n",
      "[128]\tvalidation_0-logloss:0.41978\n",
      "[129]\tvalidation_0-logloss:0.41912\n",
      "[130]\tvalidation_0-logloss:0.41827\n",
      "[131]\tvalidation_0-logloss:0.41748\n",
      "[132]\tvalidation_0-logloss:0.41762\n",
      "[133]\tvalidation_0-logloss:0.41720\n",
      "[134]\tvalidation_0-logloss:0.41632\n",
      "[135]\tvalidation_0-logloss:0.41652\n",
      "[136]\tvalidation_0-logloss:0.41584\n",
      "[137]\tvalidation_0-logloss:0.41533\n",
      "[138]\tvalidation_0-logloss:0.41412\n",
      "[139]\tvalidation_0-logloss:0.41342\n",
      "[140]\tvalidation_0-logloss:0.41274\n",
      "[141]\tvalidation_0-logloss:0.41241\n",
      "[142]\tvalidation_0-logloss:0.41237\n",
      "[143]\tvalidation_0-logloss:0.41182\n",
      "[144]\tvalidation_0-logloss:0.41121\n",
      "[145]\tvalidation_0-logloss:0.41105\n",
      "[146]\tvalidation_0-logloss:0.41075\n",
      "[147]\tvalidation_0-logloss:0.41022\n",
      "[148]\tvalidation_0-logloss:0.41051\n",
      "[149]\tvalidation_0-logloss:0.41006\n",
      "[150]\tvalidation_0-logloss:0.40940\n",
      "[151]\tvalidation_0-logloss:0.40916\n",
      "[152]\tvalidation_0-logloss:0.40932\n",
      "[153]\tvalidation_0-logloss:0.40895\n",
      "[154]\tvalidation_0-logloss:0.40904\n",
      "[155]\tvalidation_0-logloss:0.40882\n",
      "[156]\tvalidation_0-logloss:0.40818\n",
      "[157]\tvalidation_0-logloss:0.40764\n",
      "[158]\tvalidation_0-logloss:0.40725\n",
      "[159]\tvalidation_0-logloss:0.40680\n",
      "[160]\tvalidation_0-logloss:0.40692\n",
      "[161]\tvalidation_0-logloss:0.40625\n",
      "[162]\tvalidation_0-logloss:0.40586\n",
      "[163]\tvalidation_0-logloss:0.40534\n",
      "[164]\tvalidation_0-logloss:0.40462\n",
      "[165]\tvalidation_0-logloss:0.40424\n",
      "[166]\tvalidation_0-logloss:0.40394\n",
      "[167]\tvalidation_0-logloss:0.40350\n",
      "[168]\tvalidation_0-logloss:0.40270\n",
      "[169]\tvalidation_0-logloss:0.40226\n",
      "[170]\tvalidation_0-logloss:0.40194\n",
      "[171]\tvalidation_0-logloss:0.40159\n",
      "[172]\tvalidation_0-logloss:0.40084\n",
      "[173]\tvalidation_0-logloss:0.40052\n",
      "[174]\tvalidation_0-logloss:0.40074\n",
      "[175]\tvalidation_0-logloss:0.40073\n",
      "[176]\tvalidation_0-logloss:0.40026\n",
      "[177]\tvalidation_0-logloss:0.39964\n",
      "[178]\tvalidation_0-logloss:0.39916\n",
      "[179]\tvalidation_0-logloss:0.39860\n",
      "[180]\tvalidation_0-logloss:0.39843\n",
      "[181]\tvalidation_0-logloss:0.39867\n",
      "[182]\tvalidation_0-logloss:0.39850\n",
      "[183]\tvalidation_0-logloss:0.39799\n",
      "[184]\tvalidation_0-logloss:0.39769\n",
      "[185]\tvalidation_0-logloss:0.39699\n",
      "[186]\tvalidation_0-logloss:0.39661\n",
      "[187]\tvalidation_0-logloss:0.39650\n",
      "[188]\tvalidation_0-logloss:0.39588\n",
      "[189]\tvalidation_0-logloss:0.39585\n",
      "[190]\tvalidation_0-logloss:0.39542\n",
      "[191]\tvalidation_0-logloss:0.39526\n",
      "[192]\tvalidation_0-logloss:0.39515\n",
      "[193]\tvalidation_0-logloss:0.39484\n",
      "[194]\tvalidation_0-logloss:0.39449\n",
      "[195]\tvalidation_0-logloss:0.39421\n",
      "[196]\tvalidation_0-logloss:0.39385\n",
      "[197]\tvalidation_0-logloss:0.39365\n",
      "[198]\tvalidation_0-logloss:0.39371\n",
      "[199]\tvalidation_0-logloss:0.39377\n",
      "[200]\tvalidation_0-logloss:0.39361\n",
      "[201]\tvalidation_0-logloss:0.39299\n",
      "[202]\tvalidation_0-logloss:0.39261\n",
      "[203]\tvalidation_0-logloss:0.39203\n",
      "[204]\tvalidation_0-logloss:0.39180\n",
      "[205]\tvalidation_0-logloss:0.39154\n",
      "[206]\tvalidation_0-logloss:0.39129\n",
      "[207]\tvalidation_0-logloss:0.39112\n",
      "[208]\tvalidation_0-logloss:0.39119\n",
      "[209]\tvalidation_0-logloss:0.39135\n",
      "[210]\tvalidation_0-logloss:0.39103\n",
      "[211]\tvalidation_0-logloss:0.39065\n",
      "[212]\tvalidation_0-logloss:0.39066\n",
      "[213]\tvalidation_0-logloss:0.39060\n",
      "[214]\tvalidation_0-logloss:0.39020\n",
      "[215]\tvalidation_0-logloss:0.39024\n",
      "[216]\tvalidation_0-logloss:0.38987\n",
      "[217]\tvalidation_0-logloss:0.38971\n",
      "[218]\tvalidation_0-logloss:0.38967\n",
      "[219]\tvalidation_0-logloss:0.38956\n",
      "[220]\tvalidation_0-logloss:0.38940\n",
      "[221]\tvalidation_0-logloss:0.38929\n",
      "[222]\tvalidation_0-logloss:0.38891\n",
      "[223]\tvalidation_0-logloss:0.38921\n",
      "[224]\tvalidation_0-logloss:0.38920\n",
      "[225]\tvalidation_0-logloss:0.38901\n",
      "[226]\tvalidation_0-logloss:0.38861\n",
      "[227]\tvalidation_0-logloss:0.38836\n",
      "[228]\tvalidation_0-logloss:0.38778\n",
      "[229]\tvalidation_0-logloss:0.38784\n",
      "[230]\tvalidation_0-logloss:0.38790\n",
      "[231]\tvalidation_0-logloss:0.38772\n",
      "[232]\tvalidation_0-logloss:0.38802\n",
      "[233]\tvalidation_0-logloss:0.38749\n",
      "[234]\tvalidation_0-logloss:0.38710\n",
      "[235]\tvalidation_0-logloss:0.38707\n",
      "[236]\tvalidation_0-logloss:0.38691\n",
      "[237]\tvalidation_0-logloss:0.38704\n",
      "[238]\tvalidation_0-logloss:0.38702\n",
      "[239]\tvalidation_0-logloss:0.38675\n",
      "[240]\tvalidation_0-logloss:0.38672\n",
      "[241]\tvalidation_0-logloss:0.38676\n",
      "[242]\tvalidation_0-logloss:0.38677\n",
      "[243]\tvalidation_0-logloss:0.38644\n",
      "[244]\tvalidation_0-logloss:0.38610\n",
      "[245]\tvalidation_0-logloss:0.38573\n",
      "[246]\tvalidation_0-logloss:0.38569\n",
      "[247]\tvalidation_0-logloss:0.38570\n",
      "[248]\tvalidation_0-logloss:0.38564\n",
      "[249]\tvalidation_0-logloss:0.38578\n",
      "[250]\tvalidation_0-logloss:0.38547\n",
      "[251]\tvalidation_0-logloss:0.38534\n",
      "[252]\tvalidation_0-logloss:0.38511\n",
      "[253]\tvalidation_0-logloss:0.38476\n",
      "[254]\tvalidation_0-logloss:0.38498\n",
      "[255]\tvalidation_0-logloss:0.38508\n",
      "[256]\tvalidation_0-logloss:0.38534\n",
      "[257]\tvalidation_0-logloss:0.38549\n",
      "[258]\tvalidation_0-logloss:0.38524\n",
      "[259]\tvalidation_0-logloss:0.38524\n",
      "[260]\tvalidation_0-logloss:0.38507\n",
      "[261]\tvalidation_0-logloss:0.38495\n",
      "[262]\tvalidation_0-logloss:0.38483\n",
      "[263]\tvalidation_0-logloss:0.38512\n",
      "[264]\tvalidation_0-logloss:0.38494\n",
      "[265]\tvalidation_0-logloss:0.38485\n",
      "[266]\tvalidation_0-logloss:0.38454\n",
      "[267]\tvalidation_0-logloss:0.38456\n",
      "[268]\tvalidation_0-logloss:0.38459\n",
      "[269]\tvalidation_0-logloss:0.38437\n",
      "[270]\tvalidation_0-logloss:0.38392\n",
      "[271]\tvalidation_0-logloss:0.38381\n",
      "[272]\tvalidation_0-logloss:0.38381\n",
      "[273]\tvalidation_0-logloss:0.38400\n",
      "[274]\tvalidation_0-logloss:0.38416\n",
      "[275]\tvalidation_0-logloss:0.38440\n",
      "[276]\tvalidation_0-logloss:0.38413\n",
      "[277]\tvalidation_0-logloss:0.38410\n",
      "[278]\tvalidation_0-logloss:0.38426\n",
      "[279]\tvalidation_0-logloss:0.38407\n",
      "[280]\tvalidation_0-logloss:0.38382\n",
      "[281]\tvalidation_0-logloss:0.38369\n",
      "[282]\tvalidation_0-logloss:0.38378\n",
      "[283]\tvalidation_0-logloss:0.38386\n",
      "[284]\tvalidation_0-logloss:0.38419\n",
      "[285]\tvalidation_0-logloss:0.38412\n",
      "[286]\tvalidation_0-logloss:0.38402\n",
      "[287]\tvalidation_0-logloss:0.38422\n",
      "[288]\tvalidation_0-logloss:0.38419\n",
      "[289]\tvalidation_0-logloss:0.38426\n",
      "[290]\tvalidation_0-logloss:0.38456\n",
      "[291]\tvalidation_0-logloss:0.38461\n",
      "[292]\tvalidation_0-logloss:0.38449\n",
      "[293]\tvalidation_0-logloss:0.38437\n",
      "[294]\tvalidation_0-logloss:0.38440\n",
      "[295]\tvalidation_0-logloss:0.38429\n",
      "[296]\tvalidation_0-logloss:0.38435\n",
      "[297]\tvalidation_0-logloss:0.38459\n",
      "[298]\tvalidation_0-logloss:0.38458\n",
      "[299]\tvalidation_0-logloss:0.38443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "# best_pretrain_params = grid_search.best_params_\n",
    "\n",
    "for param, value in best_pretrain_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Create and train fresh model\n",
    "xgb_pretrain = xgb.XGBClassifier(\n",
    "    **best_pretrain_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_pretrain.fit(\n",
    "    X_pretrain_train,\n",
    "    y_pretrain_train,\n",
    "    eval_set=[(X_pretrain_val, y_pretrain_val)],\n",
    "    verbose=1  # Show progress every 100 trees\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0502320a-0a6e-4474-9a85-d5ba30124a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Test Accuracy on Source domain: 79.03%\n",
      "Pretraining Test F1 on Source domain: 83.95%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 91.89%\n",
      "Pretraining Test Specificity on Source domain: 60.00%\n"
     ]
    }
   ],
   "source": [
    "# PRETRAINED MODEL EVALUATION ON A-TEST\n",
    "Dataset_A_Pretrain = xgb_pretrain.predict(X_pretrain_test)\n",
    "\n",
    "#Calculate and print metrics on source domain's test set\n",
    "Dataset_A_Pretrain_acc = accuracy_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "Dataset_A_Pretrain_f1  = f1_score(y_pretrain_test, Dataset_A_Pretrain) * 100\n",
    "\n",
    "cm_A = confusion_matrix(y_pretrain_test, Dataset_A_Pretrain)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A.ravel()\n",
    "\n",
    "\n",
    "recall_A = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A = TN_A / (TN_A + FP_A) * 100\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {Dataset_A_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {Dataset_A_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_A:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_A:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6f04989-11e6-4193-a3b7-c9861654f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Accuracy on target domain's test Set: 74.19%\n",
      "Pretraining F1 on target domain's test Set: 75.00%\n",
      "Pretraining Recall (Sensitivity) on target domain's test Set: 85.71%\n",
      "Pretraining Specificity on target domain's test Set: 64.71%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain = xgb_pretrain.predict(X_finetune_test)\n",
    "\n",
    "#Calculate and print metrics on target domain's test set\n",
    "Dataset_B_Pretrain_acc = accuracy_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "Dataset_B_Pretrain_f1 = f1_score(y_finetune_test, Dataset_B_Pretrain) * 100\n",
    "cm_B = confusion_matrix(y_finetune_test, Dataset_B_Pretrain)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B.ravel()\n",
    "recall_B = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pretraining Accuracy on target domain's test Set: {Dataset_B_Pretrain_acc:.2f}%\")\n",
    "print(f\"Pretraining F1 on target domain's test Set: {Dataset_B_Pretrain_f1:.2f}%\")\n",
    "print(f\"Pretraining Recall (Sensitivity) on target domain's test Set: {recall_B:.2f}%\")\n",
    "print(f\"Pretraining Specificity on target domain's test Set: {specificity_B:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cdaffd-5589-4825-a70c-53c2d7f5562f",
   "metadata": {},
   "source": [
    "### Finetuning on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bddce10f-fb66-44ac-8ecf-754a03f87809",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_finetune_params = {\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.009,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 300,\n",
    "    'reg_alpha': 0.1, \n",
    "    'reg_lambda': 1.5, \n",
    "    'subsample': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc73f4df-52f0-45e6-b742-9ada28c944aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  colsample_bytree: 0.7\n",
      "  learning_rate: 0.009\n",
      "  max_depth: 6\n",
      "  n_estimators: 300\n",
      "  reg_alpha: 0.1\n",
      "  reg_lambda: 1.5\n",
      "  subsample: 1.0\n",
      "[0]\tvalidation_0-logloss:0.27185\n",
      "[1]\tvalidation_0-logloss:0.27044\n",
      "[2]\tvalidation_0-logloss:0.26975\n",
      "[3]\tvalidation_0-logloss:0.26819\n",
      "[4]\tvalidation_0-logloss:0.26676\n",
      "[5]\tvalidation_0-logloss:0.26586\n",
      "[6]\tvalidation_0-logloss:0.26484\n",
      "[7]\tvalidation_0-logloss:0.26399\n",
      "[8]\tvalidation_0-logloss:0.26316\n",
      "[9]\tvalidation_0-logloss:0.26267\n",
      "[10]\tvalidation_0-logloss:0.26143\n",
      "[11]\tvalidation_0-logloss:0.25991\n",
      "[12]\tvalidation_0-logloss:0.25857\n",
      "[13]\tvalidation_0-logloss:0.25733\n",
      "[14]\tvalidation_0-logloss:0.25678\n",
      "[15]\tvalidation_0-logloss:0.25556\n",
      "[16]\tvalidation_0-logloss:0.25493\n",
      "[17]\tvalidation_0-logloss:0.25391\n",
      "[18]\tvalidation_0-logloss:0.25324\n",
      "[19]\tvalidation_0-logloss:0.25280\n",
      "[20]\tvalidation_0-logloss:0.25188\n",
      "[21]\tvalidation_0-logloss:0.25058\n",
      "[22]\tvalidation_0-logloss:0.24949\n",
      "[23]\tvalidation_0-logloss:0.24878\n",
      "[24]\tvalidation_0-logloss:0.24778\n",
      "[25]\tvalidation_0-logloss:0.24657\n",
      "[26]\tvalidation_0-logloss:0.24608\n",
      "[27]\tvalidation_0-logloss:0.24523\n",
      "[28]\tvalidation_0-logloss:0.24399\n",
      "[29]\tvalidation_0-logloss:0.24314\n",
      "[30]\tvalidation_0-logloss:0.24262\n",
      "[31]\tvalidation_0-logloss:0.24157\n",
      "[32]\tvalidation_0-logloss:0.24057\n",
      "[33]\tvalidation_0-logloss:0.23971\n",
      "[34]\tvalidation_0-logloss:0.23924\n",
      "[35]\tvalidation_0-logloss:0.23890\n",
      "[36]\tvalidation_0-logloss:0.23835\n",
      "[37]\tvalidation_0-logloss:0.23802\n",
      "[38]\tvalidation_0-logloss:0.23741\n",
      "[39]\tvalidation_0-logloss:0.23688\n",
      "[40]\tvalidation_0-logloss:0.23654\n",
      "[41]\tvalidation_0-logloss:0.23579\n",
      "[42]\tvalidation_0-logloss:0.23548\n",
      "[43]\tvalidation_0-logloss:0.23448\n",
      "[44]\tvalidation_0-logloss:0.23330\n",
      "[45]\tvalidation_0-logloss:0.23241\n",
      "[46]\tvalidation_0-logloss:0.23142\n",
      "[47]\tvalidation_0-logloss:0.23072\n",
      "[48]\tvalidation_0-logloss:0.23004\n",
      "[49]\tvalidation_0-logloss:0.22889\n",
      "[50]\tvalidation_0-logloss:0.22778\n",
      "[51]\tvalidation_0-logloss:0.22757\n",
      "[52]\tvalidation_0-logloss:0.22683\n",
      "[53]\tvalidation_0-logloss:0.22582\n",
      "[54]\tvalidation_0-logloss:0.22481\n",
      "[55]\tvalidation_0-logloss:0.22406\n",
      "[56]\tvalidation_0-logloss:0.22321\n",
      "[57]\tvalidation_0-logloss:0.22238\n",
      "[58]\tvalidation_0-logloss:0.22184\n",
      "[59]\tvalidation_0-logloss:0.22088\n",
      "[60]\tvalidation_0-logloss:0.22111\n",
      "[61]\tvalidation_0-logloss:0.22081\n",
      "[62]\tvalidation_0-logloss:0.22014\n",
      "[63]\tvalidation_0-logloss:0.21983\n",
      "[64]\tvalidation_0-logloss:0.21969\n",
      "[65]\tvalidation_0-logloss:0.21942\n",
      "[66]\tvalidation_0-logloss:0.21897\n",
      "[67]\tvalidation_0-logloss:0.21836\n",
      "[68]\tvalidation_0-logloss:0.21751\n",
      "[69]\tvalidation_0-logloss:0.21684\n",
      "[70]\tvalidation_0-logloss:0.21609\n",
      "[71]\tvalidation_0-logloss:0.21520\n",
      "[72]\tvalidation_0-logloss:0.21442\n",
      "[73]\tvalidation_0-logloss:0.21402\n",
      "[74]\tvalidation_0-logloss:0.21374\n",
      "[75]\tvalidation_0-logloss:0.21327\n",
      "[76]\tvalidation_0-logloss:0.21236\n",
      "[77]\tvalidation_0-logloss:0.21203\n",
      "[78]\tvalidation_0-logloss:0.21138\n",
      "[79]\tvalidation_0-logloss:0.21114\n",
      "[80]\tvalidation_0-logloss:0.21082\n",
      "[81]\tvalidation_0-logloss:0.21037\n",
      "[82]\tvalidation_0-logloss:0.21009\n",
      "[83]\tvalidation_0-logloss:0.20948\n",
      "[84]\tvalidation_0-logloss:0.20876\n",
      "[85]\tvalidation_0-logloss:0.20846\n",
      "[86]\tvalidation_0-logloss:0.20794\n",
      "[87]\tvalidation_0-logloss:0.20750\n",
      "[88]\tvalidation_0-logloss:0.20738\n",
      "[89]\tvalidation_0-logloss:0.20691\n",
      "[90]\tvalidation_0-logloss:0.20648\n",
      "[91]\tvalidation_0-logloss:0.20621\n",
      "[92]\tvalidation_0-logloss:0.20588\n",
      "[93]\tvalidation_0-logloss:0.20587\n",
      "[94]\tvalidation_0-logloss:0.20521\n",
      "[95]\tvalidation_0-logloss:0.20467\n",
      "[96]\tvalidation_0-logloss:0.20400\n",
      "[97]\tvalidation_0-logloss:0.20382\n",
      "[98]\tvalidation_0-logloss:0.20336\n",
      "[99]\tvalidation_0-logloss:0.20291\n",
      "[100]\tvalidation_0-logloss:0.20242\n",
      "[101]\tvalidation_0-logloss:0.20222\n",
      "[102]\tvalidation_0-logloss:0.20214\n",
      "[103]\tvalidation_0-logloss:0.20214\n",
      "[104]\tvalidation_0-logloss:0.20176\n",
      "[105]\tvalidation_0-logloss:0.20116\n",
      "[106]\tvalidation_0-logloss:0.20062\n",
      "[107]\tvalidation_0-logloss:0.20047\n",
      "[108]\tvalidation_0-logloss:0.20030\n",
      "[109]\tvalidation_0-logloss:0.19983\n",
      "[110]\tvalidation_0-logloss:0.19978\n",
      "[111]\tvalidation_0-logloss:0.19923\n",
      "[112]\tvalidation_0-logloss:0.19884\n",
      "[113]\tvalidation_0-logloss:0.19883\n",
      "[114]\tvalidation_0-logloss:0.19876\n",
      "[115]\tvalidation_0-logloss:0.19873\n",
      "[116]\tvalidation_0-logloss:0.19868\n",
      "[117]\tvalidation_0-logloss:0.19865\n",
      "[118]\tvalidation_0-logloss:0.19835\n",
      "[119]\tvalidation_0-logloss:0.19805\n",
      "[120]\tvalidation_0-logloss:0.19793\n",
      "[121]\tvalidation_0-logloss:0.19786\n",
      "[122]\tvalidation_0-logloss:0.19781\n",
      "[123]\tvalidation_0-logloss:0.19784\n",
      "[124]\tvalidation_0-logloss:0.19777\n",
      "[125]\tvalidation_0-logloss:0.19732\n",
      "[126]\tvalidation_0-logloss:0.19716\n",
      "[127]\tvalidation_0-logloss:0.19673\n",
      "[128]\tvalidation_0-logloss:0.19652\n",
      "[129]\tvalidation_0-logloss:0.19604\n",
      "[130]\tvalidation_0-logloss:0.19578\n",
      "[131]\tvalidation_0-logloss:0.19553\n",
      "[132]\tvalidation_0-logloss:0.19504\n",
      "[133]\tvalidation_0-logloss:0.19464\n",
      "[134]\tvalidation_0-logloss:0.19390\n",
      "[135]\tvalidation_0-logloss:0.19339\n",
      "[136]\tvalidation_0-logloss:0.19325\n",
      "[137]\tvalidation_0-logloss:0.19309\n",
      "[138]\tvalidation_0-logloss:0.19257\n",
      "[139]\tvalidation_0-logloss:0.19246\n",
      "[140]\tvalidation_0-logloss:0.19209\n",
      "[141]\tvalidation_0-logloss:0.19179\n",
      "[142]\tvalidation_0-logloss:0.19114\n",
      "[143]\tvalidation_0-logloss:0.19100\n",
      "[144]\tvalidation_0-logloss:0.19040\n",
      "[145]\tvalidation_0-logloss:0.19035\n",
      "[146]\tvalidation_0-logloss:0.18986\n",
      "[147]\tvalidation_0-logloss:0.18957\n",
      "[148]\tvalidation_0-logloss:0.18927\n",
      "[149]\tvalidation_0-logloss:0.18899\n",
      "[150]\tvalidation_0-logloss:0.18881\n",
      "[151]\tvalidation_0-logloss:0.18860\n",
      "[152]\tvalidation_0-logloss:0.18813\n",
      "[153]\tvalidation_0-logloss:0.18768\n",
      "[154]\tvalidation_0-logloss:0.18711\n",
      "[155]\tvalidation_0-logloss:0.18690\n",
      "[156]\tvalidation_0-logloss:0.18660\n",
      "[157]\tvalidation_0-logloss:0.18625\n",
      "[158]\tvalidation_0-logloss:0.18591\n",
      "[159]\tvalidation_0-logloss:0.18579\n",
      "[160]\tvalidation_0-logloss:0.18563\n",
      "[161]\tvalidation_0-logloss:0.18554\n",
      "[162]\tvalidation_0-logloss:0.18552\n",
      "[163]\tvalidation_0-logloss:0.18494\n",
      "[164]\tvalidation_0-logloss:0.18466\n",
      "[165]\tvalidation_0-logloss:0.18464\n",
      "[166]\tvalidation_0-logloss:0.18465\n",
      "[167]\tvalidation_0-logloss:0.18446\n",
      "[168]\tvalidation_0-logloss:0.18422\n",
      "[169]\tvalidation_0-logloss:0.18399\n",
      "[170]\tvalidation_0-logloss:0.18385\n",
      "[171]\tvalidation_0-logloss:0.18345\n",
      "[172]\tvalidation_0-logloss:0.18284\n",
      "[173]\tvalidation_0-logloss:0.18274\n",
      "[174]\tvalidation_0-logloss:0.18224\n",
      "[175]\tvalidation_0-logloss:0.18171\n",
      "[176]\tvalidation_0-logloss:0.18157\n",
      "[177]\tvalidation_0-logloss:0.18137\n",
      "[178]\tvalidation_0-logloss:0.18094\n",
      "[179]\tvalidation_0-logloss:0.18079\n",
      "[180]\tvalidation_0-logloss:0.18047\n",
      "[181]\tvalidation_0-logloss:0.18018\n",
      "[182]\tvalidation_0-logloss:0.17972\n",
      "[183]\tvalidation_0-logloss:0.17951\n",
      "[184]\tvalidation_0-logloss:0.17938\n",
      "[185]\tvalidation_0-logloss:0.17938\n",
      "[186]\tvalidation_0-logloss:0.17930\n",
      "[187]\tvalidation_0-logloss:0.17922\n",
      "[188]\tvalidation_0-logloss:0.17915\n",
      "[189]\tvalidation_0-logloss:0.17907\n",
      "[190]\tvalidation_0-logloss:0.17892\n",
      "[191]\tvalidation_0-logloss:0.17874\n",
      "[192]\tvalidation_0-logloss:0.17862\n",
      "[193]\tvalidation_0-logloss:0.17861\n",
      "[194]\tvalidation_0-logloss:0.17825\n",
      "[195]\tvalidation_0-logloss:0.17820\n",
      "[196]\tvalidation_0-logloss:0.17823\n",
      "[197]\tvalidation_0-logloss:0.17811\n",
      "[198]\tvalidation_0-logloss:0.17772\n",
      "[199]\tvalidation_0-logloss:0.17754\n",
      "[200]\tvalidation_0-logloss:0.17755\n",
      "[201]\tvalidation_0-logloss:0.17725\n",
      "[202]\tvalidation_0-logloss:0.17711\n",
      "[203]\tvalidation_0-logloss:0.17724\n",
      "[204]\tvalidation_0-logloss:0.17708\n",
      "[205]\tvalidation_0-logloss:0.17718\n",
      "[206]\tvalidation_0-logloss:0.17673\n",
      "[207]\tvalidation_0-logloss:0.17668\n",
      "[208]\tvalidation_0-logloss:0.17678\n",
      "[209]\tvalidation_0-logloss:0.17687\n",
      "[210]\tvalidation_0-logloss:0.17669\n",
      "[211]\tvalidation_0-logloss:0.17657\n",
      "[212]\tvalidation_0-logloss:0.17614\n",
      "[213]\tvalidation_0-logloss:0.17604\n",
      "[214]\tvalidation_0-logloss:0.17593\n",
      "[215]\tvalidation_0-logloss:0.17576\n",
      "[216]\tvalidation_0-logloss:0.17536\n",
      "[217]\tvalidation_0-logloss:0.17528\n",
      "[218]\tvalidation_0-logloss:0.17526\n",
      "[219]\tvalidation_0-logloss:0.17487\n",
      "[220]\tvalidation_0-logloss:0.17484\n",
      "[221]\tvalidation_0-logloss:0.17499\n",
      "[222]\tvalidation_0-logloss:0.17492\n",
      "[223]\tvalidation_0-logloss:0.17461\n",
      "[224]\tvalidation_0-logloss:0.17434\n",
      "[225]\tvalidation_0-logloss:0.17392\n",
      "[226]\tvalidation_0-logloss:0.17361\n",
      "[227]\tvalidation_0-logloss:0.17347\n",
      "[228]\tvalidation_0-logloss:0.17372\n",
      "[229]\tvalidation_0-logloss:0.17346\n",
      "[230]\tvalidation_0-logloss:0.17333\n",
      "[231]\tvalidation_0-logloss:0.17333\n",
      "[232]\tvalidation_0-logloss:0.17301\n",
      "[233]\tvalidation_0-logloss:0.17312\n",
      "[234]\tvalidation_0-logloss:0.17286\n",
      "[235]\tvalidation_0-logloss:0.17269\n",
      "[236]\tvalidation_0-logloss:0.17265\n",
      "[237]\tvalidation_0-logloss:0.17244\n",
      "[238]\tvalidation_0-logloss:0.17224\n",
      "[239]\tvalidation_0-logloss:0.17251\n",
      "[240]\tvalidation_0-logloss:0.17218\n",
      "[241]\tvalidation_0-logloss:0.17217\n",
      "[242]\tvalidation_0-logloss:0.17210\n",
      "[243]\tvalidation_0-logloss:0.17213\n",
      "[244]\tvalidation_0-logloss:0.17229\n",
      "[245]\tvalidation_0-logloss:0.17207\n",
      "[246]\tvalidation_0-logloss:0.17230\n",
      "[247]\tvalidation_0-logloss:0.17195\n",
      "[248]\tvalidation_0-logloss:0.17188\n",
      "[249]\tvalidation_0-logloss:0.17190\n",
      "[250]\tvalidation_0-logloss:0.17185\n",
      "[251]\tvalidation_0-logloss:0.17178\n",
      "[252]\tvalidation_0-logloss:0.17140\n",
      "[253]\tvalidation_0-logloss:0.17140\n",
      "[254]\tvalidation_0-logloss:0.17168\n",
      "[255]\tvalidation_0-logloss:0.17150\n",
      "[256]\tvalidation_0-logloss:0.17133\n",
      "[257]\tvalidation_0-logloss:0.17146\n",
      "[258]\tvalidation_0-logloss:0.17134\n",
      "[259]\tvalidation_0-logloss:0.17144\n",
      "[260]\tvalidation_0-logloss:0.17157\n",
      "[261]\tvalidation_0-logloss:0.17149\n",
      "[262]\tvalidation_0-logloss:0.17163\n",
      "[263]\tvalidation_0-logloss:0.17158\n",
      "[264]\tvalidation_0-logloss:0.17125\n",
      "[265]\tvalidation_0-logloss:0.17134\n",
      "[266]\tvalidation_0-logloss:0.17138\n",
      "[267]\tvalidation_0-logloss:0.17147\n",
      "[268]\tvalidation_0-logloss:0.17137\n",
      "[269]\tvalidation_0-logloss:0.17140\n",
      "[270]\tvalidation_0-logloss:0.17140\n",
      "[271]\tvalidation_0-logloss:0.17140\n",
      "[272]\tvalidation_0-logloss:0.17117\n",
      "[273]\tvalidation_0-logloss:0.17112\n",
      "[274]\tvalidation_0-logloss:0.17106\n",
      "[275]\tvalidation_0-logloss:0.17088\n",
      "[276]\tvalidation_0-logloss:0.17071\n",
      "[277]\tvalidation_0-logloss:0.17051\n",
      "[278]\tvalidation_0-logloss:0.17014\n",
      "[279]\tvalidation_0-logloss:0.17022\n",
      "[280]\tvalidation_0-logloss:0.17005\n",
      "[281]\tvalidation_0-logloss:0.16985\n",
      "[282]\tvalidation_0-logloss:0.16980\n",
      "[283]\tvalidation_0-logloss:0.16979\n",
      "[284]\tvalidation_0-logloss:0.16979\n",
      "[285]\tvalidation_0-logloss:0.16976\n",
      "[286]\tvalidation_0-logloss:0.16941\n",
      "[287]\tvalidation_0-logloss:0.16960\n",
      "[288]\tvalidation_0-logloss:0.16980\n",
      "[289]\tvalidation_0-logloss:0.17008\n",
      "[290]\tvalidation_0-logloss:0.17000\n",
      "[291]\tvalidation_0-logloss:0.16999\n",
      "[292]\tvalidation_0-logloss:0.17005\n",
      "[293]\tvalidation_0-logloss:0.16990\n",
      "[294]\tvalidation_0-logloss:0.16994\n",
      "[295]\tvalidation_0-logloss:0.16997\n",
      "[296]\tvalidation_0-logloss:0.16997\n",
      "[297]\tvalidation_0-logloss:0.16983\n",
      "[298]\tvalidation_0-logloss:0.16968\n",
      "[299]\tvalidation_0-logloss:0.16972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.009, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters from fine-tuning grid search\n",
    "# best_finetune_params = grid_search_finetune.best_params_\n",
    "\n",
    "for param, value in best_finetune_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "xgb_finetune = xgb.XGBClassifier(\n",
    "    **best_finetune_params,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_finetune.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train, \n",
    "    eval_set=[(X_finetune_val, y_finetune_val)], \n",
    "    xgb_model=xgb_pretrain.get_booster(),\n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b386de1-f1cb-4ba2-ad3c-dd10c4138c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test Accuracy on Source domain: 80.65%\n",
      "Fine-Tuning Test F1 on Source domain: 85.00%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Source domain: 91.89%\n",
      "Fine-Tuning Test Specificity on Source domain: 64.00%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON A-TEST (Checking for Catastrophic Forgetting)\n",
    "Dataset_A_Finetune = xgb_finetune.predict(X_pretrain_test) # Using the fine-tuned model on A's test set\n",
    "\n",
    "# Calculate and print metrics on source domain's test set\n",
    "acc_A_Finetune = accuracy_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "f1_A_Finetune = f1_score(y_pretrain_test, Dataset_A_Finetune) * 100\n",
    "\n",
    "cm_A_Finetune = confusion_matrix(y_pretrain_test, Dataset_A_Finetune)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune.ravel()\n",
    "\n",
    "recall_A_Finetune = TP_A_F / (TP_A_F + FN_A_F) * 100\n",
    "specificity_A_Finetune = TN_A_F / (TN_A_F + FP_A_F) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test Accuracy on Source domain: {acc_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Source domain: {f1_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Source domain: {recall_A_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Source domain: {specificity_A_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afac6e80-0424-49c3-abc1-27ce75b57a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Test ROC-AUC on Target domain (B): 81.72%\n",
      "Fine-Tuning Test Accuracy on Target domain (B): 80.65%\n",
      "Fine-Tuning Test F1 on Target domain (B): 81.25%\n",
      "Fine-Tuning Test Recall (Sensitivity) on Target domain (B): 92.86%\n",
      "Fine-Tuning Test Specificity on Target domain (B): 70.59%\n"
     ]
    }
   ],
   "source": [
    "# FINE-TUNED MODEL EVALUATION ON B-TEST (Final Transfer Learning Performance)\n",
    "Dataset_B_Finetune = xgb_finetune.predict(X_finetune_test) # Using the fine-tuned model on B's test set\n",
    "\n",
    "# Calculate and print metrics on target domain's test set\n",
    "acc_B_Finetune = accuracy_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1_B_Finetune = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "cm_B_Finetune = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "TN_B_F, FP_B_F, FN_B_F, TP_B_F = cm_B_Finetune.ravel()\n",
    "\n",
    "recall_B_Finetune = TP_B_F / (TP_B_F + FN_B_F) * 100\n",
    "specificity_B_Finetune = TN_B_F / (TN_B_F + FP_B_F) * 100\n",
    "roc_auc_B_Finetune = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"Fine-Tuning Test ROC-AUC on Target domain (B): {roc_auc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Accuracy on Target domain (B): {acc_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test F1 on Target domain (B): {f1_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Recall (Sensitivity) on Target domain (B): {recall_B_Finetune:.2f}%\")\n",
    "print(f\"Fine-Tuning Test Specificity on Target domain (B): {specificity_B_Finetune:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66408ef9-e5a5-41ea-9707-7417a382bb75",
   "metadata": {},
   "source": [
    "#### SHAP figure from the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f9d46-d7cd-4c36-acf5-464f9c42e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "\n",
    "# Create SHAP explainer for XGBoost model\n",
    "explainer = shap.TreeExplainer(xgb_finetune)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(X_finetune_test)\n",
    "\n",
    "# Create a larger figure\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Generate summary plot with custom settings, no caption\n",
    "shap.summary_plot(shap_values, X_finetune_test, \n",
    "                  max_display=20,  # Show top 20 features\n",
    "                  show=False)\n",
    "\n",
    "# Customize the plot\n",
    "plt.gcf().axes[-1].set_aspect(100)\n",
    "plt.gcf().axes[-1].set_box_aspect(100)\n",
    "\n",
    "# Save the plot as an image with high resolution and no caption\n",
    "plt.savefig('shap_summary_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2010a-5856-4e2c-962f-158e8df937bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Confusion matrix and ROC-AUC curve for the proposed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba10ea4-ab9b-4d57-914a-c4f843778d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global font to Times New Roman\n",
    "# plt.rcParams.update({'font.family': 'Times New Roman'})\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Assuming y_finetune_test and Dataset_B_Finetune are already defined\n",
    "cm = confusion_matrix(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "# plt.title('Confusion Matrix of the fine-tuned model')\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.invert_yaxis()  # You can uncomment this if you want to invert the Y-axis\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['No Disease', 'Disease']) \n",
    "plt.yticks([0, 1], ['No Disease', 'Disease']) \n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm.min(), vmax=cm.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        # Set the text in Times New Roman\n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c790849-940f-44e0-b416-6e65f4e90ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Calculate Precision, Recall, F1-Score\n",
    "precision = precision_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "recall = recall_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "f1 = f1_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "# Calculate Specificity: TN / (TN + FP)\n",
    "specificity = (tn / (tn + fp)) * 100\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_finetune_test, Dataset_B_Finetune) * 100\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}%\")\n",
    "\n",
    "# Plot ROC curve with blue tones (IEEE standard)\n",
    "fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the ROC curve: Use 'orange' color and update the label\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve (AUC = {roc_auc_value:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Set limits and labels as in the original image\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate') # Changed back to match the image axis label\n",
    "\n",
    "# Adjust legend location to match the original image\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Save the ROC curve image (you can keep your original filename or update it)\n",
    "plt.savefig('roc_curve_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a481e-9936-409b-972e-3021ab1952b7",
   "metadata": {},
   "source": [
    "### XGBoost with no Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44636e68-a03d-4dca-ae99-4163c450919b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.69079\n",
      "[1]\tvalidation_0-logloss:0.69034\n",
      "[2]\tvalidation_0-logloss:0.68981\n",
      "[3]\tvalidation_0-logloss:0.68941\n",
      "[4]\tvalidation_0-logloss:0.68885\n",
      "[5]\tvalidation_0-logloss:0.68831\n",
      "[6]\tvalidation_0-logloss:0.68795\n",
      "[7]\tvalidation_0-logloss:0.68741\n",
      "[8]\tvalidation_0-logloss:0.68698\n",
      "[9]\tvalidation_0-logloss:0.68645\n",
      "[10]\tvalidation_0-logloss:0.68608\n",
      "[11]\tvalidation_0-logloss:0.68561\n",
      "[12]\tvalidation_0-logloss:0.68514\n",
      "[13]\tvalidation_0-logloss:0.68471\n",
      "[14]\tvalidation_0-logloss:0.68417\n",
      "[15]\tvalidation_0-logloss:0.68380\n",
      "[16]\tvalidation_0-logloss:0.68330\n",
      "[17]\tvalidation_0-logloss:0.68293\n",
      "[18]\tvalidation_0-logloss:0.68257\n",
      "[19]\tvalidation_0-logloss:0.68216\n",
      "[20]\tvalidation_0-logloss:0.68179\n",
      "[21]\tvalidation_0-logloss:0.68139\n",
      "[22]\tvalidation_0-logloss:0.68098\n",
      "[23]\tvalidation_0-logloss:0.68048\n",
      "[24]\tvalidation_0-logloss:0.68001\n",
      "[25]\tvalidation_0-logloss:0.67964\n",
      "[26]\tvalidation_0-logloss:0.67912\n",
      "[27]\tvalidation_0-logloss:0.67866\n",
      "[28]\tvalidation_0-logloss:0.67829\n",
      "[29]\tvalidation_0-logloss:0.67793\n",
      "[30]\tvalidation_0-logloss:0.67738\n",
      "[31]\tvalidation_0-logloss:0.67688\n",
      "[32]\tvalidation_0-logloss:0.67656\n",
      "[33]\tvalidation_0-logloss:0.67610\n",
      "[34]\tvalidation_0-logloss:0.67578\n",
      "[35]\tvalidation_0-logloss:0.67531\n",
      "[36]\tvalidation_0-logloss:0.67496\n",
      "[37]\tvalidation_0-logloss:0.67465\n",
      "[38]\tvalidation_0-logloss:0.67423\n",
      "[39]\tvalidation_0-logloss:0.67384\n",
      "[40]\tvalidation_0-logloss:0.67342\n",
      "[41]\tvalidation_0-logloss:0.67311\n",
      "[42]\tvalidation_0-logloss:0.67280\n",
      "[43]\tvalidation_0-logloss:0.67250\n",
      "[44]\tvalidation_0-logloss:0.67209\n",
      "[45]\tvalidation_0-logloss:0.67160\n",
      "[46]\tvalidation_0-logloss:0.67128\n",
      "[47]\tvalidation_0-logloss:0.67074\n",
      "[48]\tvalidation_0-logloss:0.67033\n",
      "[49]\tvalidation_0-logloss:0.66988\n",
      "[50]\tvalidation_0-logloss:0.66937\n",
      "[51]\tvalidation_0-logloss:0.66884\n",
      "[52]\tvalidation_0-logloss:0.66838\n",
      "[53]\tvalidation_0-logloss:0.66810\n",
      "[54]\tvalidation_0-logloss:0.66773\n",
      "[55]\tvalidation_0-logloss:0.66742\n",
      "[56]\tvalidation_0-logloss:0.66705\n",
      "[57]\tvalidation_0-logloss:0.66659\n",
      "[58]\tvalidation_0-logloss:0.66615\n",
      "[59]\tvalidation_0-logloss:0.66577\n",
      "[60]\tvalidation_0-logloss:0.66525\n",
      "[61]\tvalidation_0-logloss:0.66491\n",
      "[62]\tvalidation_0-logloss:0.66438\n",
      "[63]\tvalidation_0-logloss:0.66393\n",
      "[64]\tvalidation_0-logloss:0.66361\n",
      "[65]\tvalidation_0-logloss:0.66325\n",
      "[66]\tvalidation_0-logloss:0.66281\n",
      "[67]\tvalidation_0-logloss:0.66251\n",
      "[68]\tvalidation_0-logloss:0.66203\n",
      "[69]\tvalidation_0-logloss:0.66169\n",
      "[70]\tvalidation_0-logloss:0.66119\n",
      "[71]\tvalidation_0-logloss:0.66084\n",
      "[72]\tvalidation_0-logloss:0.66052\n",
      "[73]\tvalidation_0-logloss:0.66002\n",
      "[74]\tvalidation_0-logloss:0.65972\n",
      "[75]\tvalidation_0-logloss:0.65946\n",
      "[76]\tvalidation_0-logloss:0.65916\n",
      "[77]\tvalidation_0-logloss:0.65894\n",
      "[78]\tvalidation_0-logloss:0.65857\n",
      "[79]\tvalidation_0-logloss:0.65824\n",
      "[80]\tvalidation_0-logloss:0.65803\n",
      "[81]\tvalidation_0-logloss:0.65768\n",
      "[82]\tvalidation_0-logloss:0.65722\n",
      "[83]\tvalidation_0-logloss:0.65691\n",
      "[84]\tvalidation_0-logloss:0.65647\n",
      "[85]\tvalidation_0-logloss:0.65613\n",
      "[86]\tvalidation_0-logloss:0.65580\n",
      "[87]\tvalidation_0-logloss:0.65536\n",
      "[88]\tvalidation_0-logloss:0.65491\n",
      "[89]\tvalidation_0-logloss:0.65454\n",
      "[90]\tvalidation_0-logloss:0.65403\n",
      "[91]\tvalidation_0-logloss:0.65352\n",
      "[92]\tvalidation_0-logloss:0.65321\n",
      "[93]\tvalidation_0-logloss:0.65284\n",
      "[94]\tvalidation_0-logloss:0.65247\n",
      "[95]\tvalidation_0-logloss:0.65205\n",
      "[96]\tvalidation_0-logloss:0.65159\n",
      "[97]\tvalidation_0-logloss:0.65118\n",
      "[98]\tvalidation_0-logloss:0.65108\n",
      "[99]\tvalidation_0-logloss:0.65065\n",
      "[100]\tvalidation_0-logloss:0.65024\n",
      "[101]\tvalidation_0-logloss:0.64986\n",
      "[102]\tvalidation_0-logloss:0.64954\n",
      "[103]\tvalidation_0-logloss:0.64914\n",
      "[104]\tvalidation_0-logloss:0.64881\n",
      "[105]\tvalidation_0-logloss:0.64837\n",
      "[106]\tvalidation_0-logloss:0.64786\n",
      "[107]\tvalidation_0-logloss:0.64737\n",
      "[108]\tvalidation_0-logloss:0.64693\n",
      "[109]\tvalidation_0-logloss:0.64651\n",
      "[110]\tvalidation_0-logloss:0.64612\n",
      "[111]\tvalidation_0-logloss:0.64564\n",
      "[112]\tvalidation_0-logloss:0.64515\n",
      "[113]\tvalidation_0-logloss:0.64475\n",
      "[114]\tvalidation_0-logloss:0.64443\n",
      "[115]\tvalidation_0-logloss:0.64406\n",
      "[116]\tvalidation_0-logloss:0.64369\n",
      "[117]\tvalidation_0-logloss:0.64333\n",
      "[118]\tvalidation_0-logloss:0.64291\n",
      "[119]\tvalidation_0-logloss:0.64250\n",
      "[120]\tvalidation_0-logloss:0.64199\n",
      "[121]\tvalidation_0-logloss:0.64167\n",
      "[122]\tvalidation_0-logloss:0.64140\n",
      "[123]\tvalidation_0-logloss:0.64102\n",
      "[124]\tvalidation_0-logloss:0.64059\n",
      "[125]\tvalidation_0-logloss:0.64027\n",
      "[126]\tvalidation_0-logloss:0.63988\n",
      "[127]\tvalidation_0-logloss:0.63962\n",
      "[128]\tvalidation_0-logloss:0.63935\n",
      "[129]\tvalidation_0-logloss:0.63904\n",
      "[130]\tvalidation_0-logloss:0.63867\n",
      "[131]\tvalidation_0-logloss:0.63819\n",
      "[132]\tvalidation_0-logloss:0.63787\n",
      "[133]\tvalidation_0-logloss:0.63748\n",
      "[134]\tvalidation_0-logloss:0.63720\n",
      "[135]\tvalidation_0-logloss:0.63678\n",
      "[136]\tvalidation_0-logloss:0.63635\n",
      "[137]\tvalidation_0-logloss:0.63597\n",
      "[138]\tvalidation_0-logloss:0.63557\n",
      "[139]\tvalidation_0-logloss:0.63533\n",
      "[140]\tvalidation_0-logloss:0.63497\n",
      "[141]\tvalidation_0-logloss:0.63464\n",
      "[142]\tvalidation_0-logloss:0.63438\n",
      "[143]\tvalidation_0-logloss:0.63407\n",
      "[144]\tvalidation_0-logloss:0.63362\n",
      "[145]\tvalidation_0-logloss:0.63318\n",
      "[146]\tvalidation_0-logloss:0.63280\n",
      "[147]\tvalidation_0-logloss:0.63245\n",
      "[148]\tvalidation_0-logloss:0.63220\n",
      "[149]\tvalidation_0-logloss:0.63193\n",
      "[150]\tvalidation_0-logloss:0.63154\n",
      "[151]\tvalidation_0-logloss:0.63110\n",
      "[152]\tvalidation_0-logloss:0.63080\n",
      "[153]\tvalidation_0-logloss:0.63046\n",
      "[154]\tvalidation_0-logloss:0.63008\n",
      "[155]\tvalidation_0-logloss:0.62978\n",
      "[156]\tvalidation_0-logloss:0.62949\n",
      "[157]\tvalidation_0-logloss:0.62915\n",
      "[158]\tvalidation_0-logloss:0.62887\n",
      "[159]\tvalidation_0-logloss:0.62847\n",
      "[160]\tvalidation_0-logloss:0.62808\n",
      "[161]\tvalidation_0-logloss:0.62761\n",
      "[162]\tvalidation_0-logloss:0.62717\n",
      "[163]\tvalidation_0-logloss:0.62676\n",
      "[164]\tvalidation_0-logloss:0.62645\n",
      "[165]\tvalidation_0-logloss:0.62601\n",
      "[166]\tvalidation_0-logloss:0.62572\n",
      "[167]\tvalidation_0-logloss:0.62538\n",
      "[168]\tvalidation_0-logloss:0.62510\n",
      "[169]\tvalidation_0-logloss:0.62474\n",
      "[170]\tvalidation_0-logloss:0.62435\n",
      "[171]\tvalidation_0-logloss:0.62405\n",
      "[172]\tvalidation_0-logloss:0.62365\n",
      "[173]\tvalidation_0-logloss:0.62327\n",
      "[174]\tvalidation_0-logloss:0.62299\n",
      "[175]\tvalidation_0-logloss:0.62280\n",
      "[176]\tvalidation_0-logloss:0.62253\n",
      "[177]\tvalidation_0-logloss:0.62219\n",
      "[178]\tvalidation_0-logloss:0.62182\n",
      "[179]\tvalidation_0-logloss:0.62157\n",
      "[180]\tvalidation_0-logloss:0.62118\n",
      "[181]\tvalidation_0-logloss:0.62081\n",
      "[182]\tvalidation_0-logloss:0.62050\n",
      "[183]\tvalidation_0-logloss:0.62003\n",
      "[184]\tvalidation_0-logloss:0.61978\n",
      "[185]\tvalidation_0-logloss:0.61944\n",
      "[186]\tvalidation_0-logloss:0.61913\n",
      "[187]\tvalidation_0-logloss:0.61887\n",
      "[188]\tvalidation_0-logloss:0.61862\n",
      "[189]\tvalidation_0-logloss:0.61834\n",
      "[190]\tvalidation_0-logloss:0.61807\n",
      "[191]\tvalidation_0-logloss:0.61798\n",
      "[192]\tvalidation_0-logloss:0.61772\n",
      "[193]\tvalidation_0-logloss:0.61739\n",
      "[194]\tvalidation_0-logloss:0.61695\n",
      "[195]\tvalidation_0-logloss:0.61668\n",
      "[196]\tvalidation_0-logloss:0.61631\n",
      "[197]\tvalidation_0-logloss:0.61603\n",
      "[198]\tvalidation_0-logloss:0.61574\n",
      "[199]\tvalidation_0-logloss:0.61555\n",
      "[200]\tvalidation_0-logloss:0.61530\n",
      "[201]\tvalidation_0-logloss:0.61488\n",
      "[202]\tvalidation_0-logloss:0.61452\n",
      "[203]\tvalidation_0-logloss:0.61426\n",
      "[204]\tvalidation_0-logloss:0.61388\n",
      "[205]\tvalidation_0-logloss:0.61358\n",
      "[206]\tvalidation_0-logloss:0.61310\n",
      "[207]\tvalidation_0-logloss:0.61272\n",
      "[208]\tvalidation_0-logloss:0.61242\n",
      "[209]\tvalidation_0-logloss:0.61200\n",
      "[210]\tvalidation_0-logloss:0.61174\n",
      "[211]\tvalidation_0-logloss:0.61146\n",
      "[212]\tvalidation_0-logloss:0.61121\n",
      "[213]\tvalidation_0-logloss:0.61084\n",
      "[214]\tvalidation_0-logloss:0.61054\n",
      "[215]\tvalidation_0-logloss:0.61024\n",
      "[216]\tvalidation_0-logloss:0.61014\n",
      "[217]\tvalidation_0-logloss:0.60982\n",
      "[218]\tvalidation_0-logloss:0.60949\n",
      "[219]\tvalidation_0-logloss:0.60920\n",
      "[220]\tvalidation_0-logloss:0.60886\n",
      "[221]\tvalidation_0-logloss:0.60854\n",
      "[222]\tvalidation_0-logloss:0.60848\n",
      "[223]\tvalidation_0-logloss:0.60828\n",
      "[224]\tvalidation_0-logloss:0.60789\n",
      "[225]\tvalidation_0-logloss:0.60749\n",
      "[226]\tvalidation_0-logloss:0.60704\n",
      "[227]\tvalidation_0-logloss:0.60675\n",
      "[228]\tvalidation_0-logloss:0.60650\n",
      "[229]\tvalidation_0-logloss:0.60625\n",
      "[230]\tvalidation_0-logloss:0.60585\n",
      "[231]\tvalidation_0-logloss:0.60552\n",
      "[232]\tvalidation_0-logloss:0.60532\n",
      "[233]\tvalidation_0-logloss:0.60494\n",
      "[234]\tvalidation_0-logloss:0.60453\n",
      "[235]\tvalidation_0-logloss:0.60427\n",
      "[236]\tvalidation_0-logloss:0.60398\n",
      "[237]\tvalidation_0-logloss:0.60367\n",
      "[238]\tvalidation_0-logloss:0.60344\n",
      "[239]\tvalidation_0-logloss:0.60298\n",
      "[240]\tvalidation_0-logloss:0.60266\n",
      "[241]\tvalidation_0-logloss:0.60240\n",
      "[242]\tvalidation_0-logloss:0.60211\n",
      "[243]\tvalidation_0-logloss:0.60179\n",
      "[244]\tvalidation_0-logloss:0.60145\n",
      "[245]\tvalidation_0-logloss:0.60111\n",
      "[246]\tvalidation_0-logloss:0.60081\n",
      "[247]\tvalidation_0-logloss:0.60044\n",
      "[248]\tvalidation_0-logloss:0.60017\n",
      "[249]\tvalidation_0-logloss:0.59996\n",
      "[250]\tvalidation_0-logloss:0.59960\n",
      "[251]\tvalidation_0-logloss:0.59935\n",
      "[252]\tvalidation_0-logloss:0.59903\n",
      "[253]\tvalidation_0-logloss:0.59875\n",
      "[254]\tvalidation_0-logloss:0.59853\n",
      "[255]\tvalidation_0-logloss:0.59831\n",
      "[256]\tvalidation_0-logloss:0.59798\n",
      "[257]\tvalidation_0-logloss:0.59772\n",
      "[258]\tvalidation_0-logloss:0.59736\n",
      "[259]\tvalidation_0-logloss:0.59695\n",
      "[260]\tvalidation_0-logloss:0.59666\n",
      "[261]\tvalidation_0-logloss:0.59641\n",
      "[262]\tvalidation_0-logloss:0.59617\n",
      "[263]\tvalidation_0-logloss:0.59592\n",
      "[264]\tvalidation_0-logloss:0.59566\n",
      "[265]\tvalidation_0-logloss:0.59539\n",
      "[266]\tvalidation_0-logloss:0.59507\n",
      "[267]\tvalidation_0-logloss:0.59468\n",
      "[268]\tvalidation_0-logloss:0.59431\n",
      "[269]\tvalidation_0-logloss:0.59409\n",
      "[270]\tvalidation_0-logloss:0.59370\n",
      "[271]\tvalidation_0-logloss:0.59363\n",
      "[272]\tvalidation_0-logloss:0.59337\n",
      "[273]\tvalidation_0-logloss:0.59302\n",
      "[274]\tvalidation_0-logloss:0.59261\n",
      "[275]\tvalidation_0-logloss:0.59225\n",
      "[276]\tvalidation_0-logloss:0.59203\n",
      "[277]\tvalidation_0-logloss:0.59168\n",
      "[278]\tvalidation_0-logloss:0.59134\n",
      "[279]\tvalidation_0-logloss:0.59104\n",
      "[280]\tvalidation_0-logloss:0.59079\n",
      "[281]\tvalidation_0-logloss:0.59039\n",
      "[282]\tvalidation_0-logloss:0.59004\n",
      "[283]\tvalidation_0-logloss:0.58966\n",
      "[284]\tvalidation_0-logloss:0.58951\n",
      "[285]\tvalidation_0-logloss:0.58912\n",
      "[286]\tvalidation_0-logloss:0.58891\n",
      "[287]\tvalidation_0-logloss:0.58864\n",
      "[288]\tvalidation_0-logloss:0.58831\n",
      "[289]\tvalidation_0-logloss:0.58804\n",
      "[290]\tvalidation_0-logloss:0.58778\n",
      "[291]\tvalidation_0-logloss:0.58749\n",
      "[292]\tvalidation_0-logloss:0.58721\n",
      "[293]\tvalidation_0-logloss:0.58696\n",
      "[294]\tvalidation_0-logloss:0.58655\n",
      "[295]\tvalidation_0-logloss:0.58617\n",
      "[296]\tvalidation_0-logloss:0.58583\n",
      "[297]\tvalidation_0-logloss:0.58556\n",
      "[298]\tvalidation_0-logloss:0.58516\n",
      "[299]\tvalidation_0-logloss:0.58475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, device=None, early_stopping_rounds=50,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, feature_weights=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.001, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = XGBClassifier(\n",
    "    # 'colsample_bytree': 0.7,\n",
    "    # 'learning_rate': 0.009,\n",
    "    # 'max_depth': 6,\n",
    "    # 'n_estimators': 300,\n",
    "    # 'reg_alpha': 0.1, \n",
    "    # 'reg_lambda': 1.5, \n",
    "    # 'subsample': 1.0\n",
    "    n_estimators=300,            \n",
    "    max_depth=10,\n",
    "    learning_rate=0.001,          # slightly higher for adaptation\n",
    "    subsample=1.0,\n",
    "    seed=42,\n",
    "    colsample_bytree=0.7,\n",
    "    eval_metric='logloss',\n",
    "    reg_lambda = 1.5,\n",
    "    reg_alpha = 0.1,\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train using only Dataset B (resampled training set)\n",
    "baseline_model.fit(\n",
    "    X_finetune_train,\n",
    "    y_finetune_train,\n",
    "    eval_set=[(X_finetune_val, y_finetune_val)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bab295b0-00fb-44d5-be89-b0a3367bbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (Dataset B): 80.65%\n",
      "Baseline F1-score (Dataset B): 76.92%\n",
      "Baseline Recall (Sensitivity): 71.43%\n",
      "Baseline Specificity: 88.24%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Dataset B test set\n",
    "y_pred_baseline = baseline_model.predict(X_finetune_test)\n",
    "\n",
    "baseline_acc = accuracy_score(y_finetune_test, y_pred_baseline) * 100\n",
    "baseline_f1  = f1_score(y_finetune_test, y_pred_baseline) * 100\n",
    "\n",
    "cm = confusion_matrix(y_finetune_test, y_pred_baseline)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "recall_score_calc = TP / (TP + FN) * 100\n",
    "specificity_score_calc = TN / (TN + FP) * 100\n",
    "\n",
    "\n",
    "print(f\"Baseline Accuracy (Dataset B): {baseline_acc:.2f}%\")\n",
    "print(f\"Baseline F1-score (Dataset B): {baseline_f1:.2f}%\")\n",
    "print(f\"Baseline Recall (Sensitivity): {recall_score_calc:.2f}%\")\n",
    "print(f\"Baseline Specificity: {specificity_score_calc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ada6c-57c4-4083-b15b-4a9f32ce3e7d",
   "metadata": {},
   "source": [
    "## 5. Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce404869-1c59-4adf-af80-11c0431b1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2baf0ab6-9b0b-462b-9157-66d45fdc5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training, validation, and test datasets for the source domain\n",
    "X_A_train = X_pretrain_train.values  # Features for training on the source domain (pre-training phase)\n",
    "y_A_train = y_pretrain_train.values  # Target labels for training on the source domain\n",
    "\n",
    "X_A_val   = X_pretrain_val.values  # Features for validation on the source domain\n",
    "y_A_val   = y_pretrain_val.values  # Target labels for validation on the source domain\n",
    "\n",
    "X_A_test  = X_pretrain_test.values  # Features for testing on the source domain\n",
    "y_A_test  = y_pretrain_test.values  # Target labels for testing on the source domain\n",
    "\n",
    "# Defining the training, validation, and test datasets for the target domain\n",
    "X_B_train = X_finetune_train.values  # Features for training on the target domain (fine-tuning phase)\n",
    "y_B_train = y_finetune_train.values  # Target labels for training on the target domain\n",
    "\n",
    "X_B_val   = X_finetune_val.values  # Features for validation on the target domain\n",
    "y_B_val   = y_finetune_val.values  # Target labels for validation on the target domain\n",
    "\n",
    "X_B_test  = X_finetune_test.values  # Features for testing on the target domain\n",
    "y_B_test  = y_finetune_test.values  # Target labels for testing on the target domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71aa0290-a98b-4f3c-916e-427ebc557794",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_A_train = scaler.fit_transform(X_A_train).astype(np.float32)  # Fit scaler on source train set, transform it\n",
    "X_A_val = scaler.transform(X_A_val).astype(np.float32)          # Transform source validation set\n",
    "X_A_test = scaler.transform(X_A_test).astype(np.float32)        # Transform source test set\n",
    "\n",
    "y_A_train = y_A_train.astype(np.int64)  # Convert source train labels to int64\n",
    "y_A_val = y_A_val.astype(np.int64)      # Convert source validation labels\n",
    "y_A_test = y_A_test.astype(np.int64)    # Convert source test labels\n",
    "\n",
    "X_B_train = scaler.transform(X_B_train).astype(np.float32)      # Apply source-domain scaling to target train set\n",
    "X_B_val = scaler.transform(X_B_val).astype(np.float32)          # Apply scaling to target validation set\n",
    "X_B_test = scaler.transform(X_B_test).astype(np.float32)        # Apply scaling to target test set\n",
    "\n",
    "y_B_train = y_B_train.astype(np.int64)  # Convert target train labels to int64\n",
    "y_B_val = y_B_val.astype(np.int64)      # Convert target validation labels\n",
    "y_B_test = y_B_test.astype(np.int64)    # Convert target test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79f43b5b-4246-48f2-bf12-642d16222412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_d_a: 16\n",
      "n_steps: 9\n",
      "gamma: 1.7899467948557366\n",
      "lambda_sparse: 4.387608964907318e-05\n",
      "lr: 0.003074702431245894\n",
      "momentum: 0.22\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 40\n",
      "scheduler_gamma: 0.9464940708357479\n"
     ]
    }
   ],
   "source": [
    "best_pretrain_params = {\n",
    "    \"n_d_a\": 16,\n",
    "    \"n_steps\": 9,\n",
    "    \"gamma\": 1.7899467948557366,\n",
    "    \"lambda_sparse\": 4.387608964907318e-05,\n",
    "    \"lr\": 0.003074702431245894,\n",
    "    \"momentum\": 0.22,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 40,\n",
    "    \"scheduler_gamma\": 0.9464940708357479,\n",
    "}\n",
    "for key, value in best_pretrain_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e6cf23c-94a0-4d00-b5b7-94b8f78973a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.27448 | val_logloss: 0.80151 |  0:00:00s\n",
      "epoch 1  | loss: 0.90652 | val_logloss: 0.94948 |  0:00:01s\n",
      "epoch 2  | loss: 0.767   | val_logloss: 0.55012 |  0:00:02s\n",
      "epoch 3  | loss: 0.75719 | val_logloss: 0.90148 |  0:00:03s\n",
      "epoch 4  | loss: 0.70271 | val_logloss: 0.83693 |  0:00:04s\n",
      "epoch 5  | loss: 0.69054 | val_logloss: 0.64045 |  0:00:04s\n",
      "epoch 6  | loss: 0.64496 | val_logloss: 0.80293 |  0:00:05s\n",
      "epoch 7  | loss: 0.57968 | val_logloss: 0.60868 |  0:00:06s\n",
      "epoch 8  | loss: 0.68451 | val_logloss: 0.84744 |  0:00:07s\n",
      "epoch 9  | loss: 0.656   | val_logloss: 0.81741 |  0:00:08s\n",
      "epoch 10 | loss: 0.6109  | val_logloss: 0.72011 |  0:00:08s\n",
      "epoch 11 | loss: 0.55664 | val_logloss: 0.78506 |  0:00:09s\n",
      "epoch 12 | loss: 0.51877 | val_logloss: 0.61658 |  0:00:10s\n",
      "epoch 13 | loss: 0.52401 | val_logloss: 0.55633 |  0:00:11s\n",
      "epoch 14 | loss: 0.50404 | val_logloss: 0.63907 |  0:00:12s\n",
      "epoch 15 | loss: 0.54062 | val_logloss: 0.76155 |  0:00:12s\n",
      "epoch 16 | loss: 0.54955 | val_logloss: 0.63958 |  0:00:13s\n",
      "epoch 17 | loss: 0.49672 | val_logloss: 0.59105 |  0:00:14s\n",
      "epoch 18 | loss: 0.51677 | val_logloss: 0.72968 |  0:00:15s\n",
      "epoch 19 | loss: 0.55945 | val_logloss: 0.51177 |  0:00:16s\n",
      "epoch 20 | loss: 0.44326 | val_logloss: 0.55159 |  0:00:16s\n",
      "epoch 21 | loss: 0.50885 | val_logloss: 0.51575 |  0:00:17s\n",
      "epoch 22 | loss: 0.43838 | val_logloss: 0.48867 |  0:00:18s\n",
      "epoch 23 | loss: 0.51202 | val_logloss: 0.63499 |  0:00:19s\n",
      "epoch 24 | loss: 0.50195 | val_logloss: 0.63926 |  0:00:19s\n",
      "epoch 25 | loss: 0.49594 | val_logloss: 0.55369 |  0:00:20s\n",
      "epoch 26 | loss: 0.44844 | val_logloss: 0.58605 |  0:00:21s\n",
      "epoch 27 | loss: 0.41052 | val_logloss: 0.66946 |  0:00:22s\n",
      "epoch 28 | loss: 0.38668 | val_logloss: 0.66013 |  0:00:23s\n",
      "epoch 29 | loss: 0.52631 | val_logloss: 0.69346 |  0:00:23s\n",
      "epoch 30 | loss: 0.43809 | val_logloss: 0.7594  |  0:00:24s\n",
      "epoch 31 | loss: 0.4748  | val_logloss: 0.65658 |  0:00:25s\n",
      "epoch 32 | loss: 0.43322 | val_logloss: 0.66298 |  0:00:26s\n",
      "epoch 33 | loss: 0.46478 | val_logloss: 0.61984 |  0:00:26s\n",
      "epoch 34 | loss: 0.41262 | val_logloss: 0.49449 |  0:00:27s\n",
      "epoch 35 | loss: 0.38012 | val_logloss: 0.47953 |  0:00:28s\n",
      "epoch 36 | loss: 0.37995 | val_logloss: 0.46562 |  0:00:29s\n",
      "epoch 37 | loss: 0.41348 | val_logloss: 0.49765 |  0:00:29s\n",
      "epoch 38 | loss: 0.38883 | val_logloss: 0.3971  |  0:00:30s\n",
      "epoch 39 | loss: 0.43887 | val_logloss: 0.48653 |  0:00:31s\n",
      "epoch 40 | loss: 0.4019  | val_logloss: 0.48747 |  0:00:32s\n",
      "epoch 41 | loss: 0.41359 | val_logloss: 0.51365 |  0:00:32s\n",
      "epoch 42 | loss: 0.40954 | val_logloss: 0.43849 |  0:00:33s\n",
      "epoch 43 | loss: 0.40891 | val_logloss: 0.50326 |  0:00:34s\n",
      "epoch 44 | loss: 0.42347 | val_logloss: 0.50665 |  0:00:35s\n",
      "epoch 45 | loss: 0.39642 | val_logloss: 0.40717 |  0:00:36s\n",
      "epoch 46 | loss: 0.37489 | val_logloss: 0.50079 |  0:00:36s\n",
      "epoch 47 | loss: 0.40383 | val_logloss: 0.46083 |  0:00:37s\n",
      "epoch 48 | loss: 0.36611 | val_logloss: 0.50267 |  0:00:38s\n",
      "epoch 49 | loss: 0.3809  | val_logloss: 0.47812 |  0:00:39s\n",
      "epoch 50 | loss: 0.40473 | val_logloss: 0.49837 |  0:00:39s\n",
      "epoch 51 | loss: 0.36228 | val_logloss: 0.54839 |  0:00:40s\n",
      "epoch 52 | loss: 0.37449 | val_logloss: 0.39634 |  0:00:41s\n",
      "epoch 53 | loss: 0.42364 | val_logloss: 0.52873 |  0:00:42s\n",
      "epoch 54 | loss: 0.4064  | val_logloss: 0.52384 |  0:00:43s\n",
      "epoch 55 | loss: 0.40122 | val_logloss: 0.49526 |  0:00:43s\n",
      "epoch 56 | loss: 0.44349 | val_logloss: 0.41568 |  0:00:44s\n",
      "epoch 57 | loss: 0.42929 | val_logloss: 0.49268 |  0:00:45s\n",
      "epoch 58 | loss: 0.39014 | val_logloss: 0.49286 |  0:00:46s\n",
      "epoch 59 | loss: 0.41641 | val_logloss: 0.48839 |  0:00:46s\n",
      "epoch 60 | loss: 0.33853 | val_logloss: 0.46527 |  0:00:47s\n",
      "epoch 61 | loss: 0.35501 | val_logloss: 0.52159 |  0:00:48s\n",
      "epoch 62 | loss: 0.36776 | val_logloss: 0.51511 |  0:00:49s\n",
      "epoch 63 | loss: 0.39202 | val_logloss: 0.53073 |  0:00:50s\n",
      "epoch 64 | loss: 0.40195 | val_logloss: 0.53776 |  0:00:51s\n",
      "epoch 65 | loss: 0.39292 | val_logloss: 0.43342 |  0:00:52s\n",
      "epoch 66 | loss: 0.38267 | val_logloss: 0.39766 |  0:00:53s\n",
      "epoch 67 | loss: 0.37882 | val_logloss: 0.42787 |  0:00:54s\n",
      "epoch 68 | loss: 0.3515  | val_logloss: 0.4633  |  0:00:55s\n",
      "epoch 69 | loss: 0.39133 | val_logloss: 0.45547 |  0:00:56s\n",
      "epoch 70 | loss: 0.41738 | val_logloss: 0.68551 |  0:00:57s\n",
      "epoch 71 | loss: 0.42685 | val_logloss: 0.52716 |  0:00:58s\n",
      "epoch 72 | loss: 0.35599 | val_logloss: 0.59049 |  0:00:59s\n",
      "epoch 73 | loss: 0.39129 | val_logloss: 0.57097 |  0:01:00s\n",
      "epoch 74 | loss: 0.39784 | val_logloss: 0.53477 |  0:01:01s\n",
      "epoch 75 | loss: 0.37745 | val_logloss: 0.50753 |  0:01:02s\n",
      "epoch 76 | loss: 0.34791 | val_logloss: 0.52716 |  0:01:03s\n",
      "epoch 77 | loss: 0.41955 | val_logloss: 0.5718  |  0:01:04s\n",
      "epoch 78 | loss: 0.35253 | val_logloss: 0.50937 |  0:01:05s\n",
      "epoch 79 | loss: 0.36809 | val_logloss: 0.48277 |  0:01:06s\n",
      "epoch 80 | loss: 0.34594 | val_logloss: 0.49406 |  0:01:07s\n",
      "epoch 81 | loss: 0.40088 | val_logloss: 0.51202 |  0:01:07s\n",
      "epoch 82 | loss: 0.33054 | val_logloss: 0.47382 |  0:01:08s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 52 and best_val_logloss = 0.39634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at tabnet_pretrain_model.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tabnet_pretrain_model.zip'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_params = study_scratch.best_params\n",
    "\n",
    "tabnet_pretrain = TabNetClassifier(\n",
    "    n_d=best_pretrain_params['n_d_a'],           # split n_d_a into n_d\n",
    "    n_a=best_pretrain_params['n_d_a'],           # and n_a\n",
    "    n_steps=best_pretrain_params['n_steps'],\n",
    "    gamma=best_pretrain_params['gamma'],\n",
    "    lambda_sparse=best_pretrain_params['lambda_sparse'],\n",
    "    momentum=best_pretrain_params['momentum'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={'lr': best_pretrain_params['lr']},\n",
    "    mask_type='sparsemax',\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_pretrain_params['step_size'], 'gamma': best_pretrain_params['scheduler_gamma']},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "# Train the final model\n",
    "tabnet_pretrain.fit(\n",
    "    X_train=X_A_train,\n",
    "    y_train=y_A_train,\n",
    "    eval_set=[(X_A_val, y_A_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"logloss\"],\n",
    "    max_epochs=150,\n",
    "    patience=30,\n",
    "    batch_size=best_pretrain_params['batch_size'],\n",
    "    virtual_batch_size=best_pretrain_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "tabnet_pretrain.save_model(\"tabnet_pretrain_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8244220-7390-4797-a19a-4d7e158111ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset A, Test Accuracy: 79.03%\n",
      "Pre-training, test on Dataset A, Test F1-score: 82.19%\n",
      "Pre-training, test on Dataset A, Test Recall (Sensitivity): 81.08%\n",
      "Pre-training, test on Dataset A, Test Specificity: 76.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Pretrain_TNet = tabnet_pretrain.predict(X_A_test)\n",
    "\n",
    "cm_A_TNet = confusion_matrix(y_A_test, Dataset_A_Pretrain_TNet)\n",
    "TN_A, FP_A, FN_A, TP_A = cm_A_TNet.ravel()\n",
    "\n",
    "# Calculate Metrics for TabNet on Dataset A\n",
    "acc_A_TNet = accuracy_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "f1_A_TNet = f1_score(y_A_test, Dataset_A_Pretrain_TNet) * 100\n",
    "recall_A_TNet = TP_A / (TP_A + FN_A) * 100\n",
    "specificity_A_TNet = TN_A / (TN_A + FP_A) * 100\n",
    "\n",
    "\n",
    "print(f\"Pre-training, test on Dataset A, Test Accuracy: {acc_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test F1-score: {f1_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Recall (Sensitivity): {recall_A_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset A, Test Specificity: {specificity_A_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c40aac0-e457-447b-8a49-bca02c5b9a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training, test on Dataset B, Accuracy: 83.87%\n",
      "Pre-training, test on Dataset B, F1-score: 81.48%\n",
      "Pre-training, test on Dataset B, Recall (Sensitivity): 78.57%\n",
      "Pre-training, test on Dataset B, Specificity: 88.24%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Pretrain_TNet = tabnet_pretrain.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_TNet = confusion_matrix(y_B_test, Dataset_B_Pretrain_TNet)\n",
    "TN_B, FP_B, FN_B, TP_B = cm_B_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_TNet = accuracy_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "f1_B_TNet = f1_score(y_B_test, Dataset_B_Pretrain_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_TNet = TP_B / (TP_B + FN_B) * 100\n",
    "specificity_B_TNet = TN_B / (TN_B + FP_B) * 100\n",
    "\n",
    "print(f\"Pre-training, test on Dataset B, Accuracy: {acc_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, F1-score: {f1_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Recall (Sensitivity): {recall_B_TNet:.2f}%\")\n",
    "print(f\"Pre-training, test on Dataset B, Specificity: {specificity_B_TNet:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08c2ea6a-c6c8-4ca0-80aa-dea7c5ee0780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 1.8676698399014517\n",
      "lambda_sparse: 0.0042824862550021525\n",
      "lr: 0.0013627631079900057\n",
      "momentum: 0.92\n",
      "batch_size: 32\n",
      "virtual_batch_size: 32\n",
      "step_size: 10\n",
      "scheduler_gamma: 0.8296240533908424\n"
     ]
    }
   ],
   "source": [
    "best_finetune_params = {\n",
    "    \"gamma\": 1.8676698399014517,\n",
    "    \"lambda_sparse\": 0.0042824862550021525,\n",
    "    \"lr\": 0.0013627631079900058,\n",
    "    \"momentum\": 0.92,\n",
    "    \"batch_size\": 32,\n",
    "    \"virtual_batch_size\": 32,\n",
    "    \"step_size\": 10,\n",
    "    \"scheduler_gamma\": 0.8296240533908424,\n",
    "}\n",
    "for key, value in best_finetune_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60a1ed99-b4e0-49c3-b7f3-3e48f2446be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_a changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_d changed from 8 to 16\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:118: UserWarning: Pretraining: n_steps changed from 3 to 9\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
      "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6337  | val_logloss: 0.29008 |  0:00:00s\n",
      "epoch 1  | loss: 0.61888 | val_logloss: 0.22487 |  0:00:00s\n",
      "epoch 2  | loss: 0.66477 | val_logloss: 0.23841 |  0:00:01s\n",
      "epoch 3  | loss: 0.57045 | val_logloss: 0.26257 |  0:00:01s\n",
      "epoch 4  | loss: 0.5691  | val_logloss: 0.25684 |  0:00:02s\n",
      "epoch 5  | loss: 0.54943 | val_logloss: 0.39612 |  0:00:02s\n",
      "epoch 6  | loss: 0.57882 | val_logloss: 0.37099 |  0:00:03s\n",
      "epoch 7  | loss: 0.53552 | val_logloss: 0.35785 |  0:00:03s\n",
      "epoch 8  | loss: 0.50991 | val_logloss: 0.55618 |  0:00:03s\n",
      "epoch 9  | loss: 0.57154 | val_logloss: 0.51816 |  0:00:04s\n",
      "epoch 10 | loss: 0.56153 | val_logloss: 0.47322 |  0:00:04s\n",
      "epoch 11 | loss: 0.54187 | val_logloss: 0.4601  |  0:00:05s\n",
      "epoch 12 | loss: 0.51525 | val_logloss: 0.4153  |  0:00:05s\n",
      "epoch 13 | loss: 0.52878 | val_logloss: 0.39446 |  0:00:05s\n",
      "epoch 14 | loss: 0.51475 | val_logloss: 0.35433 |  0:00:06s\n",
      "epoch 15 | loss: 0.4903  | val_logloss: 0.44938 |  0:00:06s\n",
      "epoch 16 | loss: 0.48271 | val_logloss: 0.32531 |  0:00:06s\n",
      "epoch 17 | loss: 0.50936 | val_logloss: 0.28656 |  0:00:07s\n",
      "epoch 18 | loss: 0.43275 | val_logloss: 0.32614 |  0:00:07s\n",
      "epoch 19 | loss: 0.43022 | val_logloss: 0.34489 |  0:00:08s\n",
      "epoch 20 | loss: 0.49622 | val_logloss: 0.2703  |  0:00:08s\n",
      "epoch 21 | loss: 0.46389 | val_logloss: 0.27403 |  0:00:08s\n",
      "epoch 22 | loss: 0.54547 | val_logloss: 0.26004 |  0:00:09s\n",
      "epoch 23 | loss: 0.52305 | val_logloss: 0.26381 |  0:00:09s\n",
      "epoch 24 | loss: 0.50626 | val_logloss: 0.26394 |  0:00:10s\n",
      "epoch 25 | loss: 0.48256 | val_logloss: 0.22411 |  0:00:10s\n",
      "epoch 26 | loss: 0.43451 | val_logloss: 0.22243 |  0:00:10s\n",
      "epoch 27 | loss: 0.42459 | val_logloss: 0.23959 |  0:00:11s\n",
      "epoch 28 | loss: 0.49152 | val_logloss: 0.24789 |  0:00:11s\n",
      "epoch 29 | loss: 0.45258 | val_logloss: 0.24709 |  0:00:11s\n",
      "epoch 30 | loss: 0.40524 | val_logloss: 0.2531  |  0:00:12s\n",
      "epoch 31 | loss: 0.47473 | val_logloss: 0.24322 |  0:00:12s\n",
      "epoch 32 | loss: 0.44346 | val_logloss: 0.2561  |  0:00:13s\n",
      "epoch 33 | loss: 0.43511 | val_logloss: 0.25023 |  0:00:13s\n",
      "epoch 34 | loss: 0.40634 | val_logloss: 0.24155 |  0:00:13s\n",
      "epoch 35 | loss: 0.43758 | val_logloss: 0.25182 |  0:00:14s\n",
      "epoch 36 | loss: 0.46117 | val_logloss: 0.24359 |  0:00:14s\n",
      "epoch 37 | loss: 0.41183 | val_logloss: 0.26166 |  0:00:15s\n",
      "epoch 38 | loss: 0.46114 | val_logloss: 0.29316 |  0:00:15s\n",
      "epoch 39 | loss: 0.44689 | val_logloss: 0.25315 |  0:00:15s\n",
      "epoch 40 | loss: 0.43158 | val_logloss: 0.256   |  0:00:16s\n",
      "epoch 41 | loss: 0.42968 | val_logloss: 0.26055 |  0:00:16s\n",
      "epoch 42 | loss: 0.38117 | val_logloss: 0.27562 |  0:00:16s\n",
      "epoch 43 | loss: 0.46402 | val_logloss: 0.30524 |  0:00:17s\n",
      "epoch 44 | loss: 0.47528 | val_logloss: 0.27438 |  0:00:17s\n",
      "epoch 45 | loss: 0.44336 | val_logloss: 0.28067 |  0:00:18s\n",
      "epoch 46 | loss: 0.45045 | val_logloss: 0.27933 |  0:00:18s\n",
      "epoch 47 | loss: 0.43463 | val_logloss: 0.27253 |  0:00:18s\n",
      "epoch 48 | loss: 0.4646  | val_logloss: 0.26772 |  0:00:19s\n",
      "epoch 49 | loss: 0.44938 | val_logloss: 0.27549 |  0:00:19s\n",
      "epoch 50 | loss: 0.44782 | val_logloss: 0.26987 |  0:00:20s\n",
      "epoch 51 | loss: 0.40032 | val_logloss: 0.26893 |  0:00:20s\n",
      "epoch 52 | loss: 0.45304 | val_logloss: 0.27111 |  0:00:20s\n",
      "epoch 53 | loss: 0.41438 | val_logloss: 0.28405 |  0:00:21s\n",
      "epoch 54 | loss: 0.46253 | val_logloss: 0.27721 |  0:00:21s\n",
      "epoch 55 | loss: 0.45022 | val_logloss: 0.28269 |  0:00:22s\n",
      "epoch 56 | loss: 0.45677 | val_logloss: 0.27305 |  0:00:22s\n",
      "epoch 57 | loss: 0.40787 | val_logloss: 0.28768 |  0:00:22s\n",
      "epoch 58 | loss: 0.39702 | val_logloss: 0.28473 |  0:00:23s\n",
      "epoch 59 | loss: 0.42023 | val_logloss: 0.2578  |  0:00:23s\n",
      "epoch 60 | loss: 0.44955 | val_logloss: 0.26683 |  0:00:23s\n",
      "epoch 61 | loss: 0.41805 | val_logloss: 0.302   |  0:00:24s\n",
      "epoch 62 | loss: 0.41723 | val_logloss: 0.29261 |  0:00:24s\n",
      "epoch 63 | loss: 0.42659 | val_logloss: 0.26354 |  0:00:25s\n",
      "epoch 64 | loss: 0.39145 | val_logloss: 0.2575  |  0:00:25s\n",
      "epoch 65 | loss: 0.46089 | val_logloss: 0.29971 |  0:00:25s\n",
      "epoch 66 | loss: 0.43403 | val_logloss: 0.31003 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 26 and best_val_logloss = 0.22243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# best_finetune_params = study_finetune.best_params\n",
    "\n",
    "# Create a new model for fine-tuning\n",
    "tabnet_finetuned = TabNetClassifier(\n",
    "    n_d=8,\n",
    "    n_a=8,\n",
    "    n_steps=3,\n",
    "    gamma=best_finetune_params['gamma'],\n",
    "    lambda_sparse=best_finetune_params['lambda_sparse'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params={\n",
    "        'lr': best_finetune_params['lr']\n",
    "    },\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={'step_size': best_finetune_params['step_size'], 'gamma': best_finetune_params['scheduler_gamma']},\n",
    "    seed=42,\n",
    "    verbose=1,\n",
    "    device_name='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "tabnet_finetuned.fit(\n",
    "    X_train=X_B_train,\n",
    "    y_train=y_B_train,           \n",
    "    eval_set=[(X_B_val, y_B_val)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=['logloss'],\n",
    "    max_epochs=100,\n",
    "    patience=40,\n",
    "    batch_size=best_finetune_params['batch_size'],\n",
    "    virtual_batch_size=best_finetune_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    "    # Initialize with pre-trained weights\n",
    "    from_unsupervised=tabnet_pretrain  # Transfer learning!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fcb0603e-8399-4861-9f00-b943aeff7fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset A, Test Accuracy: 80.65%\n",
      "Fine-tuned, test on Dataset A, Test F1-score: 84.21%\n",
      "Fine-tuned, test on Dataset A, Test Recall (Sensitivity): 86.49%\n",
      "Fine-tuned, test on Dataset A, Test Specificity: 72.00%\n"
     ]
    }
   ],
   "source": [
    "Dataset_A_Finetune_TNet = tabnet_finetuned.predict(X_A_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset A\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_A_Finetune_TNet = confusion_matrix(y_A_test, Dataset_A_Finetune_TNet)\n",
    "TN_A_F, FP_A_F, FN_A_F, TP_A_F = cm_A_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_A_Finetune_TNet = accuracy_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "f1_A_Finetune_TNet = f1_score(y_A_test, Dataset_A_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_A_Finetune_TNet = TP_A_F / (TP_A_F + FN_A_F) * 100 if (TP_A_F + FN_A_F) > 0 else 0\n",
    "specificity_A_Finetune_TNet = TN_A_F / (TN_A_F + FP_A_F) * 100 if (TN_A_F + FP_A_F) > 0 else 0\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Accuracy: {acc_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test F1-score: {f1_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Recall (Sensitivity): {recall_A_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset A, Test Specificity: {specificity_A_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "357c6039-9f26-4de1-a9da-1f10dcda17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned, test on Dataset B, Accuracy: 77.42%\n",
      "Fine-tuned, test on Dataset B, F1-score: 74.07%\n",
      "Fine-tuned, test on Dataset B, Recall (Sensitivity): 71.43%\n",
      "Fine-tuned, test on Dataset B, Specificity: 82.35%\n"
     ]
    }
   ],
   "source": [
    "Dataset_B_Finetune_TNet = tabnet_finetuned.predict(X_B_test)\n",
    "\n",
    "# Calculate Confusion Matrix for Fine-Tuned TabNet on Dataset B\n",
    "# Structure: [[TN, FP], [FN, TP]]\n",
    "cm_B_Finetune_TNet = confusion_matrix(y_B_test, Dataset_B_Finetune_TNet)\n",
    "TN_F, FP_F, FN_F, TP_F = cm_B_Finetune_TNet.ravel()\n",
    "\n",
    "# Calculate Core Metrics\n",
    "acc_B_Finetune_TNet = accuracy_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "f1_B_Finetune_TNet = f1_score(y_B_test, Dataset_B_Finetune_TNet) * 100\n",
    "\n",
    "# Calculate Recall (Sensitivity) and Specificity\n",
    "recall_B_Finetune_TNet = TP_F / (TP_F + FN_F) * 100\n",
    "specificity_B_Finetune_TNet = TN_F / (TN_F + FP_F) * 100\n",
    "\n",
    "print(f\"Fine-tuned, test on Dataset B, Accuracy: {acc_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, F1-score: {f1_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Recall (Sensitivity): {recall_B_Finetune_TNet:.2f}%\")\n",
    "print(f\"Fine-tuned, test on Dataset B, Specificity: {specificity_B_Finetune_TNet:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d28fe7-74ba-41e7-8fef-2b8d2b0f3303",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1df4cc-4459-498a-a4e1-6bc8757c079b",
   "metadata": {},
   "source": [
    "### Pretraining phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b6deece6-fe3b-4e0e-beed-38de643fc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'learning_rate' : 0.01,\n",
    "    'l2_reg' : 0.0001,\n",
    "    'neurons_l1' : 128,\n",
    "    'dropout_rate' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "90ed9878-a295-4f60-b9fb-cc2c0715e139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m1,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_mlp_model(input_shape, best_params):\n",
    "    neurons_l1 = best_params['neurons_l1']\n",
    "    dropout_rate = best_params['dropout_rate']\n",
    "    l2_reg = best_params['l2_reg']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(neurons_l1, activation='relu', name='feature_layer_1', kernel_regularizer=keras.regularizers.l2(l2_reg))(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/2), activation='relu', name='feature_layer_2', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(int(neurons_l1/4), activation='relu', name='feature_layer_3', kernel_regularizer=keras.regularizers.l2(l2_reg))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "input_dim = X_pretrain_train.shape[1]\n",
    "mlp_pretrain = create_mlp_model(input_dim, best_params)\n",
    "mlp_pretrain.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "654d4553-dfdd-48c9-a387-9d970de06b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.5772 - auc: 0.5576 - loss: 7.7950 - val_accuracy: 0.5738 - val_auc: 0.6295 - val_loss: 0.6738\n",
      "Epoch 2/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5549 - auc: 0.5696 - loss: 0.7730 - val_accuracy: 0.6230 - val_auc: 0.6661 - val_loss: 0.6226\n",
      "Epoch 3/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6159 - auc: 0.6834 - loss: 0.6386 - val_accuracy: 0.6230 - val_auc: 0.7027 - val_loss: 0.6195\n",
      "Epoch 4/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6321 - auc: 0.7059 - loss: 0.6306 - val_accuracy: 0.6557 - val_auc: 0.6931 - val_loss: 0.6153\n",
      "Epoch 5/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6016 - auc: 0.6866 - loss: 0.6153 - val_accuracy: 0.6230 - val_auc: 0.7055 - val_loss: 0.6111\n",
      "Epoch 6/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5752 - auc: 0.6690 - loss: 0.6341 - val_accuracy: 0.6230 - val_auc: 0.7342 - val_loss: 0.6093\n",
      "Epoch 7/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6504 - auc: 0.7059 - loss: 0.6203 - val_accuracy: 0.6393 - val_auc: 0.7410 - val_loss: 0.5988\n",
      "Epoch 8/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6565 - auc: 0.7296 - loss: 0.6048 - val_accuracy: 0.6885 - val_auc: 0.7416 - val_loss: 0.6024\n",
      "Epoch 9/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6992 - auc: 0.7539 - loss: 0.6012 - val_accuracy: 0.6393 - val_auc: 0.7523 - val_loss: 0.5919\n",
      "Epoch 10/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7378 - auc: 0.7945 - loss: 0.5643 - val_accuracy: 0.6557 - val_auc: 0.7613 - val_loss: 0.5955\n",
      "Epoch 11/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7419 - auc: 0.8024 - loss: 0.5496 - val_accuracy: 0.6557 - val_auc: 0.7461 - val_loss: 0.5977\n",
      "Epoch 12/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7358 - auc: 0.7914 - loss: 0.5592 - val_accuracy: 0.7213 - val_auc: 0.7545 - val_loss: 0.5895\n",
      "Epoch 13/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7663 - auc: 0.8219 - loss: 0.5260 - val_accuracy: 0.6721 - val_auc: 0.7680 - val_loss: 0.6123\n",
      "Epoch 14/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7561 - auc: 0.8308 - loss: 0.5173 - val_accuracy: 0.6721 - val_auc: 0.7793 - val_loss: 0.5838\n",
      "Epoch 15/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7520 - auc: 0.8171 - loss: 0.5291 - val_accuracy: 0.6393 - val_auc: 0.7714 - val_loss: 0.5934\n",
      "Epoch 16/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7561 - auc: 0.8323 - loss: 0.5072 - val_accuracy: 0.6885 - val_auc: 0.7900 - val_loss: 0.5991\n",
      "Epoch 17/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7561 - auc: 0.8328 - loss: 0.5194 - val_accuracy: 0.7049 - val_auc: 0.8119 - val_loss: 0.5424\n",
      "Epoch 18/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7907 - auc: 0.8582 - loss: 0.4790 - val_accuracy: 0.6885 - val_auc: 0.8007 - val_loss: 0.5820\n",
      "Epoch 19/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7907 - auc: 0.8500 - loss: 0.4886 - val_accuracy: 0.6885 - val_auc: 0.8035 - val_loss: 0.5899\n",
      "Epoch 20/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7907 - auc: 0.8571 - loss: 0.4885 - val_accuracy: 0.7213 - val_auc: 0.8131 - val_loss: 0.5594\n",
      "Epoch 21/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7927 - auc: 0.8669 - loss: 0.4723 - val_accuracy: 0.7377 - val_auc: 0.8271 - val_loss: 0.5563\n",
      "Epoch 22/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7947 - auc: 0.8637 - loss: 0.4749 - val_accuracy: 0.7049 - val_auc: 0.8226 - val_loss: 0.5477\n",
      "Epoch 23/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8150 - auc: 0.8838 - loss: 0.4432 - val_accuracy: 0.7377 - val_auc: 0.8176 - val_loss: 0.5257\n",
      "Epoch 24/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8028 - auc: 0.8683 - loss: 0.4696 - val_accuracy: 0.7705 - val_auc: 0.8305 - val_loss: 0.5497\n",
      "Epoch 25/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8130 - auc: 0.8683 - loss: 0.4820 - val_accuracy: 0.7213 - val_auc: 0.8271 - val_loss: 0.5225\n",
      "Epoch 26/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8130 - auc: 0.8749 - loss: 0.4633 - val_accuracy: 0.7377 - val_auc: 0.8463 - val_loss: 0.5168\n",
      "Epoch 27/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7927 - auc: 0.8610 - loss: 0.4822 - val_accuracy: 0.7541 - val_auc: 0.8316 - val_loss: 0.5303\n",
      "Epoch 28/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8211 - auc: 0.8811 - loss: 0.4518 - val_accuracy: 0.7049 - val_auc: 0.8395 - val_loss: 0.5256\n",
      "Epoch 29/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8232 - auc: 0.8843 - loss: 0.4509 - val_accuracy: 0.7213 - val_auc: 0.8390 - val_loss: 0.5296\n",
      "Epoch 30/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8150 - auc: 0.8787 - loss: 0.4619 - val_accuracy: 0.7213 - val_auc: 0.8412 - val_loss: 0.5064\n",
      "Epoch 31/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8293 - auc: 0.8898 - loss: 0.4368 - val_accuracy: 0.7541 - val_auc: 0.8615 - val_loss: 0.5091\n",
      "Epoch 32/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8354 - auc: 0.8933 - loss: 0.4387 - val_accuracy: 0.7541 - val_auc: 0.8457 - val_loss: 0.5257\n",
      "Epoch 33/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8476 - auc: 0.9060 - loss: 0.4078 - val_accuracy: 0.7541 - val_auc: 0.8502 - val_loss: 0.5148\n",
      "Epoch 34/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - auc: 0.8891 - loss: 0.4395 - val_accuracy: 0.7705 - val_auc: 0.8378 - val_loss: 0.5220\n",
      "Epoch 35/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - auc: 0.8978 - loss: 0.4192 - val_accuracy: 0.7541 - val_auc: 0.8440 - val_loss: 0.5063\n",
      "Epoch 36/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8272 - auc: 0.9102 - loss: 0.3965 - val_accuracy: 0.7705 - val_auc: 0.8660 - val_loss: 0.4943\n",
      "Epoch 37/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8069 - auc: 0.8868 - loss: 0.4500 - val_accuracy: 0.7377 - val_auc: 0.8677 - val_loss: 0.4709\n",
      "Epoch 38/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8232 - auc: 0.8955 - loss: 0.4473 - val_accuracy: 0.7869 - val_auc: 0.8789 - val_loss: 0.4695\n",
      "Epoch 39/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8191 - auc: 0.8887 - loss: 0.4385 - val_accuracy: 0.7705 - val_auc: 0.8542 - val_loss: 0.5553\n",
      "Epoch 40/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7988 - auc: 0.8746 - loss: 0.4775 - val_accuracy: 0.7541 - val_auc: 0.8587 - val_loss: 0.4908\n",
      "Epoch 41/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8211 - auc: 0.8887 - loss: 0.4358 - val_accuracy: 0.7541 - val_auc: 0.8756 - val_loss: 0.4750\n",
      "Epoch 42/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8313 - auc: 0.9031 - loss: 0.4185 - val_accuracy: 0.7541 - val_auc: 0.8637 - val_loss: 0.4752\n",
      "Epoch 43/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8415 - auc: 0.8885 - loss: 0.4449 - val_accuracy: 0.7705 - val_auc: 0.8773 - val_loss: 0.4654\n",
      "Epoch 44/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8435 - auc: 0.9026 - loss: 0.4174 - val_accuracy: 0.7705 - val_auc: 0.8705 - val_loss: 0.5281\n",
      "Epoch 45/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9129 - loss: 0.3950 - val_accuracy: 0.7705 - val_auc: 0.8756 - val_loss: 0.4740\n",
      "Epoch 46/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - auc: 0.8972 - loss: 0.4274 - val_accuracy: 0.7705 - val_auc: 0.8789 - val_loss: 0.4611\n",
      "Epoch 47/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9230 - loss: 0.3723 - val_accuracy: 0.7869 - val_auc: 0.8857 - val_loss: 0.4594\n",
      "Epoch 48/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - auc: 0.9224 - loss: 0.3800 - val_accuracy: 0.7705 - val_auc: 0.8801 - val_loss: 0.4818\n",
      "Epoch 49/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - auc: 0.9164 - loss: 0.3930 - val_accuracy: 0.7869 - val_auc: 0.8784 - val_loss: 0.4753\n",
      "Epoch 50/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8374 - auc: 0.9044 - loss: 0.4134 - val_accuracy: 0.7705 - val_auc: 0.8654 - val_loss: 0.4858\n",
      "Epoch 51/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9211 - loss: 0.3844 - val_accuracy: 0.8197 - val_auc: 0.8834 - val_loss: 0.4532\n",
      "Epoch 52/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8557 - auc: 0.9228 - loss: 0.3780 - val_accuracy: 0.7705 - val_auc: 0.8840 - val_loss: 0.4969\n",
      "Epoch 53/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9192 - loss: 0.3827 - val_accuracy: 0.7541 - val_auc: 0.8992 - val_loss: 0.4734\n",
      "Epoch 54/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8435 - auc: 0.9101 - loss: 0.4040 - val_accuracy: 0.8033 - val_auc: 0.8812 - val_loss: 0.4526\n",
      "Epoch 55/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - auc: 0.9200 - loss: 0.3821 - val_accuracy: 0.7541 - val_auc: 0.8801 - val_loss: 0.5045\n",
      "Epoch 56/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8557 - auc: 0.9184 - loss: 0.3842 - val_accuracy: 0.7869 - val_auc: 0.8857 - val_loss: 0.4616\n",
      "Epoch 57/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - auc: 0.9132 - loss: 0.3964 - val_accuracy: 0.7377 - val_auc: 0.8739 - val_loss: 0.4999\n",
      "Epoch 58/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8394 - auc: 0.9230 - loss: 0.3792 - val_accuracy: 0.8033 - val_auc: 0.8925 - val_loss: 0.4936\n",
      "Epoch 59/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8415 - auc: 0.9006 - loss: 0.4147 - val_accuracy: 0.7869 - val_auc: 0.8947 - val_loss: 0.4461\n",
      "Epoch 60/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8720 - auc: 0.9269 - loss: 0.3672 - val_accuracy: 0.7705 - val_auc: 0.8953 - val_loss: 0.4863\n",
      "Epoch 61/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8232 - auc: 0.9108 - loss: 0.3999 - val_accuracy: 0.7705 - val_auc: 0.8857 - val_loss: 0.4670\n",
      "Epoch 62/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8659 - auc: 0.9191 - loss: 0.3871 - val_accuracy: 0.8361 - val_auc: 0.8964 - val_loss: 0.4359\n",
      "Epoch 63/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8740 - auc: 0.9229 - loss: 0.3725 - val_accuracy: 0.8361 - val_auc: 0.8930 - val_loss: 0.4387\n",
      "Epoch 64/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - auc: 0.9287 - loss: 0.3605 - val_accuracy: 0.7869 - val_auc: 0.8880 - val_loss: 0.5056\n",
      "Epoch 65/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8638 - auc: 0.9150 - loss: 0.3909 - val_accuracy: 0.7705 - val_auc: 0.8795 - val_loss: 0.4618\n",
      "Epoch 66/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8659 - auc: 0.9196 - loss: 0.3865 - val_accuracy: 0.7705 - val_auc: 0.8823 - val_loss: 0.4653\n",
      "Epoch 67/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8577 - auc: 0.9275 - loss: 0.3691 - val_accuracy: 0.8361 - val_auc: 0.8868 - val_loss: 0.4584\n",
      "Epoch 68/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9089 - loss: 0.4019 - val_accuracy: 0.7869 - val_auc: 0.8806 - val_loss: 0.4674\n",
      "Epoch 69/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8699 - auc: 0.9259 - loss: 0.3695 - val_accuracy: 0.7869 - val_auc: 0.8930 - val_loss: 0.4943\n",
      "Epoch 70/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8659 - auc: 0.9316 - loss: 0.3566 - val_accuracy: 0.7869 - val_auc: 0.8953 - val_loss: 0.4872\n",
      "Epoch 71/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - auc: 0.9170 - loss: 0.3877 - val_accuracy: 0.7705 - val_auc: 0.8739 - val_loss: 0.4739\n",
      "Epoch 72/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8618 - auc: 0.9314 - loss: 0.3581 - val_accuracy: 0.8361 - val_auc: 0.8891 - val_loss: 0.4493\n",
      "Epoch 73/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8780 - auc: 0.9269 - loss: 0.3603 - val_accuracy: 0.8197 - val_auc: 0.8885 - val_loss: 0.4456\n",
      "Epoch 74/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - auc: 0.9342 - loss: 0.3507 - val_accuracy: 0.7869 - val_auc: 0.8885 - val_loss: 0.4684\n",
      "Epoch 75/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - auc: 0.9285 - loss: 0.3647 - val_accuracy: 0.8361 - val_auc: 0.8930 - val_loss: 0.4403\n",
      "Epoch 76/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8435 - auc: 0.9117 - loss: 0.4045 - val_accuracy: 0.7541 - val_auc: 0.8778 - val_loss: 0.4760\n",
      "Epoch 77/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8537 - auc: 0.9193 - loss: 0.3839 - val_accuracy: 0.7377 - val_auc: 0.8525 - val_loss: 0.5019\n",
      "Epoch 78/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9187 - loss: 0.3849 - val_accuracy: 0.8197 - val_auc: 0.8970 - val_loss: 0.4378\n",
      "Epoch 79/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - auc: 0.9216 - loss: 0.3793 - val_accuracy: 0.8033 - val_auc: 0.8913 - val_loss: 0.4539\n",
      "Epoch 80/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9301 - loss: 0.3654 - val_accuracy: 0.8361 - val_auc: 0.8930 - val_loss: 0.4540\n",
      "Epoch 81/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - auc: 0.9239 - loss: 0.3792 - val_accuracy: 0.7377 - val_auc: 0.8530 - val_loss: 0.5197\n",
      "Epoch 82/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9263 - loss: 0.3704 - val_accuracy: 0.7869 - val_auc: 0.8863 - val_loss: 0.4589\n",
      "Epoch 83/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9228 - loss: 0.3779 - val_accuracy: 0.8361 - val_auc: 0.8981 - val_loss: 0.4315\n",
      "Epoch 84/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - auc: 0.9338 - loss: 0.3551 - val_accuracy: 0.7869 - val_auc: 0.8688 - val_loss: 0.5178\n",
      "Epoch 85/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8455 - auc: 0.9197 - loss: 0.3810 - val_accuracy: 0.8033 - val_auc: 0.8930 - val_loss: 0.4698\n",
      "Epoch 86/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - auc: 0.9292 - loss: 0.3647 - val_accuracy: 0.8525 - val_auc: 0.8880 - val_loss: 0.4648\n",
      "Epoch 87/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9225 - loss: 0.3758 - val_accuracy: 0.7869 - val_auc: 0.8716 - val_loss: 0.4951\n",
      "Epoch 88/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9254 - loss: 0.3712 - val_accuracy: 0.8361 - val_auc: 0.8947 - val_loss: 0.4687\n",
      "Epoch 89/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - auc: 0.9146 - loss: 0.3986 - val_accuracy: 0.8361 - val_auc: 0.8784 - val_loss: 0.4578\n",
      "Epoch 90/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8638 - auc: 0.9241 - loss: 0.3801 - val_accuracy: 0.8361 - val_auc: 0.8947 - val_loss: 0.4477\n",
      "Epoch 91/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - auc: 0.9180 - loss: 0.3887 - val_accuracy: 0.7869 - val_auc: 0.8941 - val_loss: 0.4561\n",
      "Epoch 92/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8374 - auc: 0.9155 - loss: 0.3951 - val_accuracy: 0.8689 - val_auc: 0.9065 - val_loss: 0.4098\n",
      "Epoch 93/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8557 - auc: 0.9252 - loss: 0.3733 - val_accuracy: 0.8033 - val_auc: 0.8891 - val_loss: 0.4840\n",
      "Epoch 94/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8455 - auc: 0.9070 - loss: 0.4045 - val_accuracy: 0.8197 - val_auc: 0.9009 - val_loss: 0.4431\n",
      "Epoch 95/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - auc: 0.9252 - loss: 0.3756 - val_accuracy: 0.8197 - val_auc: 0.9060 - val_loss: 0.4618\n",
      "Epoch 96/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8435 - auc: 0.9262 - loss: 0.3769 - val_accuracy: 0.8197 - val_auc: 0.8992 - val_loss: 0.4608\n",
      "Epoch 97/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8455 - auc: 0.9297 - loss: 0.3652 - val_accuracy: 0.8033 - val_auc: 0.8885 - val_loss: 0.4651\n",
      "Epoch 98/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9313 - loss: 0.3641 - val_accuracy: 0.7869 - val_auc: 0.8930 - val_loss: 0.4496\n",
      "Epoch 99/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8679 - auc: 0.9338 - loss: 0.3511 - val_accuracy: 0.7705 - val_auc: 0.8947 - val_loss: 0.4524\n",
      "Epoch 100/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8557 - auc: 0.9317 - loss: 0.3595 - val_accuracy: 0.7869 - val_auc: 0.8913 - val_loss: 0.4778\n",
      "Epoch 101/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - auc: 0.9311 - loss: 0.3710 - val_accuracy: 0.8197 - val_auc: 0.8863 - val_loss: 0.4421\n",
      "Epoch 102/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - auc: 0.9245 - loss: 0.3744 - val_accuracy: 0.7213 - val_auc: 0.8694 - val_loss: 0.5699\n",
      "Epoch 103/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8293 - auc: 0.9022 - loss: 0.4246 - val_accuracy: 0.8197 - val_auc: 0.8925 - val_loss: 0.4897\n",
      "Epoch 104/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8394 - auc: 0.9126 - loss: 0.4041 - val_accuracy: 0.7869 - val_auc: 0.8998 - val_loss: 0.4914\n",
      "Epoch 105/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9142 - loss: 0.4051 - val_accuracy: 0.8197 - val_auc: 0.8953 - val_loss: 0.4500\n",
      "Epoch 106/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9311 - loss: 0.3576 - val_accuracy: 0.8525 - val_auc: 0.8868 - val_loss: 0.4467\n",
      "Epoch 107/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8577 - auc: 0.9194 - loss: 0.3838 - val_accuracy: 0.8525 - val_auc: 0.8953 - val_loss: 0.4317\n",
      "Epoch 108/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8476 - auc: 0.9303 - loss: 0.3598 - val_accuracy: 0.7869 - val_auc: 0.8750 - val_loss: 0.5098\n",
      "Epoch 109/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - auc: 0.9211 - loss: 0.3854 - val_accuracy: 0.8033 - val_auc: 0.9009 - val_loss: 0.4616\n",
      "Epoch 110/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8415 - auc: 0.9177 - loss: 0.3889 - val_accuracy: 0.7869 - val_auc: 0.8885 - val_loss: 0.4623\n",
      "Epoch 111/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8496 - auc: 0.9267 - loss: 0.3686 - val_accuracy: 0.8033 - val_auc: 0.8958 - val_loss: 0.4368\n",
      "Epoch 112/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8679 - auc: 0.9249 - loss: 0.3794 - val_accuracy: 0.8033 - val_auc: 0.9009 - val_loss: 0.4515\n",
      "Epoch 113/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8333 - auc: 0.9208 - loss: 0.3831 - val_accuracy: 0.8197 - val_auc: 0.8947 - val_loss: 0.4381\n",
      "Epoch 114/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8679 - auc: 0.9345 - loss: 0.3575 - val_accuracy: 0.8033 - val_auc: 0.8868 - val_loss: 0.4765\n",
      "Epoch 115/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8659 - auc: 0.9318 - loss: 0.3568 - val_accuracy: 0.7377 - val_auc: 0.9071 - val_loss: 0.5233\n",
      "Epoch 116/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - auc: 0.8907 - loss: 0.4346 - val_accuracy: 0.8033 - val_auc: 0.8958 - val_loss: 0.4755\n",
      "Epoch 117/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8455 - auc: 0.9292 - loss: 0.3666 - val_accuracy: 0.8033 - val_auc: 0.8936 - val_loss: 0.4701\n",
      "Epoch 118/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - auc: 0.9268 - loss: 0.3681 - val_accuracy: 0.7869 - val_auc: 0.8744 - val_loss: 0.4718\n",
      "Epoch 119/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8638 - auc: 0.9323 - loss: 0.3548 - val_accuracy: 0.8033 - val_auc: 0.9009 - val_loss: 0.4705\n",
      "Epoch 120/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8537 - auc: 0.9343 - loss: 0.3584 - val_accuracy: 0.8033 - val_auc: 0.8947 - val_loss: 0.4903\n",
      "Epoch 121/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8516 - auc: 0.9318 - loss: 0.3499 - val_accuracy: 0.8525 - val_auc: 0.9032 - val_loss: 0.4484\n",
      "Epoch 122/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8720 - auc: 0.9458 - loss: 0.3274 - val_accuracy: 0.7869 - val_auc: 0.8953 - val_loss: 0.4355\n",
      "Epoch 123/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - auc: 0.9333 - loss: 0.3596 - val_accuracy: 0.7869 - val_auc: 0.8880 - val_loss: 0.4760\n",
      "Epoch 124/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8516 - auc: 0.9286 - loss: 0.3647 - val_accuracy: 0.8033 - val_auc: 0.9032 - val_loss: 0.4433\n",
      "Epoch 125/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9319 - loss: 0.3577 - val_accuracy: 0.8033 - val_auc: 0.9133 - val_loss: 0.4175\n",
      "Epoch 126/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8455 - auc: 0.9237 - loss: 0.3864 - val_accuracy: 0.8197 - val_auc: 0.9015 - val_loss: 0.4534\n",
      "Epoch 127/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - auc: 0.9301 - loss: 0.3616 - val_accuracy: 0.8033 - val_auc: 0.8761 - val_loss: 0.4856\n",
      "Epoch 128/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - auc: 0.9332 - loss: 0.3551 - val_accuracy: 0.8197 - val_auc: 0.8953 - val_loss: 0.4665\n",
      "Epoch 129/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8313 - auc: 0.9203 - loss: 0.3851 - val_accuracy: 0.7869 - val_auc: 0.8863 - val_loss: 0.4454\n",
      "Epoch 130/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8638 - auc: 0.9309 - loss: 0.3620 - val_accuracy: 0.8033 - val_auc: 0.8891 - val_loss: 0.5052\n",
      "Epoch 131/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8232 - auc: 0.9198 - loss: 0.3863 - val_accuracy: 0.8033 - val_auc: 0.9032 - val_loss: 0.4481\n",
      "Epoch 132/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - auc: 0.9370 - loss: 0.3421 - val_accuracy: 0.8033 - val_auc: 0.8902 - val_loss: 0.4506\n",
      "Epoch 133/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8537 - auc: 0.9294 - loss: 0.3609 - val_accuracy: 0.8361 - val_auc: 0.8851 - val_loss: 0.4467\n",
      "Epoch 134/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8720 - auc: 0.9415 - loss: 0.3414 - val_accuracy: 0.8033 - val_auc: 0.8908 - val_loss: 0.4444\n",
      "Epoch 135/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8537 - auc: 0.9288 - loss: 0.3640 - val_accuracy: 0.8033 - val_auc: 0.8981 - val_loss: 0.4498\n",
      "Epoch 136/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8496 - auc: 0.9353 - loss: 0.3450 - val_accuracy: 0.8033 - val_auc: 0.9026 - val_loss: 0.5026\n",
      "Epoch 137/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8394 - auc: 0.9223 - loss: 0.3817 - val_accuracy: 0.7705 - val_auc: 0.8941 - val_loss: 0.4885\n",
      "Epoch 138/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8516 - auc: 0.9301 - loss: 0.3628 - val_accuracy: 0.8033 - val_auc: 0.8863 - val_loss: 0.4548\n",
      "Epoch 139/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8679 - auc: 0.9378 - loss: 0.3418 - val_accuracy: 0.8033 - val_auc: 0.8902 - val_loss: 0.4664\n",
      "Epoch 140/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8598 - auc: 0.9282 - loss: 0.3622 - val_accuracy: 0.8197 - val_auc: 0.8840 - val_loss: 0.4845\n",
      "Epoch 141/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - auc: 0.9300 - loss: 0.3695 - val_accuracy: 0.8033 - val_auc: 0.8801 - val_loss: 0.4789\n",
      "Epoch 142/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8557 - auc: 0.9363 - loss: 0.3398 - val_accuracy: 0.7869 - val_auc: 0.8823 - val_loss: 0.4782\n",
      "Epoch 143/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8455 - auc: 0.9294 - loss: 0.3648 - val_accuracy: 0.7869 - val_auc: 0.8840 - val_loss: 0.4519\n",
      "Epoch 144/150\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8699 - auc: 0.9358 - loss: 0.3462 - val_accuracy: 0.8033 - val_auc: 0.8711 - val_loss: 0.4777\n"
     ]
    }
   ],
   "source": [
    "pretrain_history = mlp_pretrain.fit(\n",
    "    X_pretrain_train, \n",
    "    y_pretrain_train,\n",
    "    epochs=150, # Start with a reasonable number of epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_pretrain_val, y_pretrain_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=52, restore_best_weights=True)\n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the pre-trained weights using the required extension\n",
    "mlp_pretrain.save_weights('mlp_pretrain.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d505ca53-a0de-4398-87c6-ccfe472c3f4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.6855\n",
      "Max F1 Score at this threshold: 0.9286\n"
     ]
    }
   ],
   "source": [
    "# Use the fine-tune validation set (X_finetune_val) to find the threshold\n",
    "y_val_proba = mlp_pretrain.predict(X_finetune_val).ravel()\n",
    "precision, recall, thresholds = precision_recall_curve(y_finetune_val, y_val_proba)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6) # Added 1e-6 to prevent division by zero\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")\n",
    "\n",
    "# Now, use best_threshold instead of 0.5 for final testing (e.g., y_pred = (y_pred_proba > best_threshold).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4cf444f1-dd04-40e2-9648-f1314e5065f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000029C9C63F380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Pretraining Test Accuracy on Source domain: 72.58%\n",
      "Pretraining Test F1 on Source domain: 75.36%\n",
      "Pretraining Test Recall (Sensitivity) on Source domain: 70.27%\n",
      "Pretraining Test Specificity on Source domain: 76.00%\n",
      "Pretraining Test ROC-AUC on Source domain: 0.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset A (Source Domain) ---\")\n",
    "\n",
    "y_pred_proba_a = mlp_pretrain.predict(X_pretrain_test).ravel()\n",
    "\n",
    "\n",
    "y_pred_a = (y_pred_proba_a > best_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a = accuracy_score(y_pretrain_test, y_pred_a) * 100\n",
    "f1_a = f1_score(y_pretrain_test, y_pred_a) * 100\n",
    "roc_auc_a = roc_auc_score(y_pretrain_test, y_pred_proba_a) * 100\n",
    "recall_a = recall_score(y_pretrain_test, y_pred_a) * 100\n",
    "precision_a = precision_score(y_pretrain_test, y_pred_a) * 100\n",
    "specificity_a = recall_score(y_pretrain_test, y_pred_a, pos_label=0) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Pretraining Test Accuracy on Source domain: {accuracy_a:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on Source domain: {f1_a:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on Source domain: {recall_a:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on Source domain: {specificity_a:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on Source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b01219ae-3d2a-4660-88f5-84ef12d70ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Pretraining Test Accuracy on target domain: 74.19%\n",
      "Pretraining Test F1 on target domain: 71.43%\n",
      "Pretraining Test Recall (Sensitivity) on target domain: 71.43%\n",
      "Pretraining Test Specificity on target domain: 76.47%\n",
      "Pretraining Test ROC-AUC on target domain: 0.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Pre-trained MLP on Dataset B (Zero-Shot Transfer) ---\")\n",
    "\n",
    "# Get raw probability predictions\n",
    "y_pred_proba_b = mlp_pretrain.predict(X_finetune_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_b = (y_pred_proba_b > best_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b = accuracy_score(y_finetune_test, y_pred_b) * 100\n",
    "f1_b = f1_score(y_finetune_test, y_pred_b) * 100\n",
    "roc_auc_b = roc_auc_score(y_finetune_test, y_pred_proba_b) * 100\n",
    "recall_b = recall_score(y_finetune_test, y_pred_b) * 100\n",
    "precision_b = precision_score(y_finetune_test, y_pred_b) * 100\n",
    "specificity_b = recall_score(y_finetune_test, y_pred_b, pos_label=0) * 100\n",
    "\n",
    "print(f\"Pretraining Test Accuracy on target domain: {accuracy_b:.2f}%\")\n",
    "print(f\"Pretraining Test F1 on target domain: {f1_b:.2f}%\")\n",
    "print(f\"Pretraining Test Recall (Sensitivity) on target domain: {recall_b:.2f}%\")\n",
    "print(f\"Pretraining Test Specificity on target domain: {specificity_b:.2f}%\")\n",
    "print(f\"Pretraining Test ROC-AUC on target domain: {roc_auc_score(y_finetune_test, y_pred_proba_b):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e01e12-434e-48a8-bd31-fe2a5ae61bbf",
   "metadata": {},
   "source": [
    "### Finetuning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0cdd7167-26dd-4d0c-9a56-ca4e44086c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prosp\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_1 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚           \u001b[38;5;34m1,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_2 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ feature_layer_3 (\u001b[38;5;33mDense\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output_layer (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m33\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,161</span> (47.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,161\u001b[0m (47.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,369</span> (40.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,369\u001b[0m (40.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def setup_fine_tuning(input_shape, pretrain_weights_path, best_params, fine_tune_lr=1e-1):\n",
    "    # Create the model with exactly the same architecture as pre-training\n",
    "    model_ft = create_mlp_model(input_shape, best_params)\n",
    "    \n",
    "    # Load pre-trained weights\n",
    "    model_ft.load_weights(pretrain_weights_path)\n",
    "\n",
    "    # Freeze layers for fine-tuning\n",
    "    model_ft.get_layer('feature_layer_1').trainable = False\n",
    "    model_ft.get_layer('feature_layer_2').trainable = True\n",
    "    model_ft.get_layer('feature_layer_3').trainable = True\n",
    "    \n",
    "    # Recompile with lower learning rate for fine-tuning\n",
    "    model_ft.compile(\n",
    "        optimizer=Adam(learning_rate=fine_tune_lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "\n",
    "    )\n",
    "    \n",
    "    finetune_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return model_ft, finetune_scheduler\n",
    "\n",
    "\n",
    "mlp_finetune, finetune_scheduler = setup_fine_tuning(\n",
    "    input_shape=input_dim,  # Use the input dimension from Dataset B\n",
    "    pretrain_weights_path='mlp_pretrain.weights.h5', \n",
    "    best_params=best_params,  # Add best_trial here\n",
    "    fine_tune_lr=0.05\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Save the fine-tuned model weights (optional)\n",
    "mlp_finetune.save_weights('mlp_finetune_weights.weights.h5')\n",
    "\n",
    "# Check the model summary to ensure layers are frozen correctly\n",
    "mlp_finetune.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3fc5d9c6-5dbc-425f-b6e0-5d5891ec0c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7521 - auc: 0.8287 - loss: 0.7714 - val_accuracy: 0.4667 - val_auc: 0.4754 - val_loss: 0.7188\n",
      "Epoch 2/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7149 - auc: 0.8021 - loss: 0.5978 - val_accuracy: 0.9333 - val_auc: 0.9732 - val_loss: 0.2977\n",
      "Epoch 3/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7851 - auc: 0.8620 - loss: 0.4884 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3886\n",
      "Epoch 4/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - auc: 0.8664 - loss: 0.4908 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3571\n",
      "Epoch 5/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8886 - loss: 0.4326 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.2920\n",
      "Epoch 6/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8560 - loss: 0.5219 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3893\n",
      "Epoch 7/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.8847 - loss: 0.4782 - val_accuracy: 0.8667 - val_auc: 0.9554 - val_loss: 0.3608\n",
      "Epoch 8/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7893 - auc: 0.8690 - loss: 0.4905 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3077\n",
      "Epoch 9/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7934 - auc: 0.8812 - loss: 0.4470 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2606\n",
      "Epoch 10/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7769 - auc: 0.8691 - loss: 0.5356 - val_accuracy: 0.9667 - val_auc: 0.9777 - val_loss: 0.2797\n",
      "Epoch 11/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - auc: 0.8723 - loss: 0.4618 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.2903\n",
      "Epoch 12/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - auc: 0.8791 - loss: 0.4716 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.3436\n",
      "Epoch 13/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8969 - loss: 0.4219 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3145\n",
      "Epoch 14/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.8935 - loss: 0.4543 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3511\n",
      "Epoch 15/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8836 - loss: 0.4760 - val_accuracy: 0.9000 - val_auc: 0.9844 - val_loss: 0.2810\n",
      "Epoch 16/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - auc: 0.8855 - loss: 0.4785 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.2985\n",
      "Epoch 17/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - auc: 0.8641 - loss: 0.5484 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3212\n",
      "Epoch 18/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7893 - auc: 0.8529 - loss: 0.5342 - val_accuracy: 0.9333 - val_auc: 0.9844 - val_loss: 0.3271\n",
      "Epoch 19/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - auc: 0.8804 - loss: 0.4733 - val_accuracy: 0.8000 - val_auc: 0.9732 - val_loss: 0.4036\n",
      "Epoch 20/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7645 - auc: 0.8718 - loss: 0.4678 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.2698\n",
      "Epoch 21/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7975 - auc: 0.8770 - loss: 0.4783 - val_accuracy: 0.9333 - val_auc: 0.9754 - val_loss: 0.2828\n",
      "Epoch 22/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7934 - auc: 0.8812 - loss: 0.4677 - val_accuracy: 0.9000 - val_auc: 0.9665 - val_loss: 0.3786\n",
      "Epoch 23/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8933 - loss: 0.5331 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.2797\n",
      "Epoch 24/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8058 - auc: 0.8768 - loss: 0.4915 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2831\n",
      "Epoch 25/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8866 - loss: 0.4719 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.3203\n",
      "Epoch 26/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7851 - auc: 0.8743 - loss: 0.4834 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3336\n",
      "Epoch 27/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8757 - loss: 0.5502 - val_accuracy: 0.9333 - val_auc: 0.9821 - val_loss: 0.3127\n",
      "Epoch 28/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8223 - auc: 0.8780 - loss: 0.4772 - val_accuracy: 0.9000 - val_auc: 0.9844 - val_loss: 0.3272\n",
      "Epoch 29/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8099 - auc: 0.8878 - loss: 0.4486 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2885\n",
      "Epoch 30/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8306 - auc: 0.9050 - loss: 0.4127 - val_accuracy: 0.8333 - val_auc: 0.9732 - val_loss: 0.3325\n",
      "Epoch 31/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8347 - auc: 0.8973 - loss: 0.4287 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.2908\n",
      "Epoch 32/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8182 - auc: 0.8662 - loss: 0.4697 - val_accuracy: 0.9000 - val_auc: 0.9844 - val_loss: 0.3071\n",
      "Epoch 33/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8099 - auc: 0.8843 - loss: 0.4768 - val_accuracy: 0.9000 - val_auc: 0.9799 - val_loss: 0.3231\n",
      "Epoch 34/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.9020 - loss: 0.4173 - val_accuracy: 0.9000 - val_auc: 0.9866 - val_loss: 0.2736\n",
      "Epoch 35/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8791 - loss: 0.4937 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2778\n",
      "Epoch 36/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8223 - auc: 0.8665 - loss: 0.4943 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.4145\n",
      "Epoch 37/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7975 - auc: 0.8591 - loss: 0.5079 - val_accuracy: 0.9333 - val_auc: 0.9866 - val_loss: 0.2496\n",
      "Epoch 38/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8755 - loss: 0.4754 - val_accuracy: 0.9333 - val_auc: 0.9821 - val_loss: 0.2683\n",
      "Epoch 39/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8704 - loss: 0.4631 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3231\n",
      "Epoch 40/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8801 - loss: 0.4697 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3289\n",
      "Epoch 41/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - auc: 0.8986 - loss: 0.4148 - val_accuracy: 0.9000 - val_auc: 0.9754 - val_loss: 0.3680\n",
      "Epoch 42/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - auc: 0.9002 - loss: 0.4210 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.2817\n",
      "Epoch 43/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.8985 - loss: 0.4402 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3072\n",
      "Epoch 44/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8223 - auc: 0.8832 - loss: 0.4634 - val_accuracy: 0.8667 - val_auc: 0.9688 - val_loss: 0.3365\n",
      "Epoch 45/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8223 - auc: 0.8766 - loss: 0.4671 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3334\n",
      "Epoch 46/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.8856 - loss: 0.4622 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.3280\n",
      "Epoch 47/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8058 - auc: 0.8879 - loss: 0.4510 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3162\n",
      "Epoch 48/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8058 - auc: 0.8588 - loss: 0.5076 - val_accuracy: 0.9000 - val_auc: 0.9665 - val_loss: 0.3746\n",
      "Epoch 49/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8430 - auc: 0.8803 - loss: 0.4419 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3241\n",
      "Epoch 50/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8388 - auc: 0.8996 - loss: 0.4159 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3009\n",
      "Epoch 51/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8058 - auc: 0.8900 - loss: 0.4489 - val_accuracy: 0.9000 - val_auc: 0.9710 - val_loss: 0.3296\n",
      "Epoch 52/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.9011 - loss: 0.4165 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.2845\n",
      "Epoch 53/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8928 - loss: 0.4309 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3430\n",
      "Epoch 54/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8099 - auc: 0.8875 - loss: 0.4564 - val_accuracy: 0.9333 - val_auc: 0.9799 - val_loss: 0.2856\n",
      "Epoch 55/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8058 - auc: 0.8948 - loss: 0.4244 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.2717\n",
      "Epoch 56/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8430 - auc: 0.9094 - loss: 0.4105 - val_accuracy: 0.9333 - val_auc: 0.9732 - val_loss: 0.2940\n",
      "Epoch 57/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8731 - loss: 0.4676 - val_accuracy: 0.9000 - val_auc: 0.9844 - val_loss: 0.2759\n",
      "Epoch 58/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8388 - auc: 0.8954 - loss: 0.4530 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3206\n",
      "Epoch 59/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8264 - auc: 0.8978 - loss: 0.4386 - val_accuracy: 0.9000 - val_auc: 0.9643 - val_loss: 0.3633\n",
      "Epoch 60/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8182 - auc: 0.8763 - loss: 0.4537 - val_accuracy: 0.9333 - val_auc: 0.9732 - val_loss: 0.3004\n",
      "Epoch 61/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8930 - loss: 0.4585 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3079\n",
      "Epoch 62/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8388 - auc: 0.8838 - loss: 0.4562 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3072\n",
      "Epoch 63/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - auc: 0.9052 - loss: 0.4118 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3543\n",
      "Epoch 64/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8347 - auc: 0.8972 - loss: 0.4096 - val_accuracy: 0.9333 - val_auc: 0.9732 - val_loss: 0.2739\n",
      "Epoch 65/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8826 - loss: 0.4360 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.2636\n",
      "Epoch 66/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - auc: 0.8991 - loss: 0.4240 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3338\n",
      "Epoch 67/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - auc: 0.8892 - loss: 0.4242 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3274\n",
      "Epoch 68/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8991 - loss: 0.4257 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.2890\n",
      "Epoch 69/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - auc: 0.8799 - loss: 0.4502 - val_accuracy: 0.9000 - val_auc: 0.9554 - val_loss: 0.3796\n",
      "Epoch 70/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - auc: 0.8867 - loss: 0.4509 - val_accuracy: 0.9000 - val_auc: 0.9821 - val_loss: 0.2619\n",
      "Epoch 71/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8099 - auc: 0.8793 - loss: 0.4418 - val_accuracy: 0.9000 - val_auc: 0.9754 - val_loss: 0.2685\n",
      "Epoch 72/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8264 - auc: 0.8958 - loss: 0.4348 - val_accuracy: 0.9000 - val_auc: 0.9643 - val_loss: 0.3088\n",
      "Epoch 73/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8140 - auc: 0.8776 - loss: 0.4569 - val_accuracy: 0.9000 - val_auc: 0.9643 - val_loss: 0.3313\n",
      "Epoch 74/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.8895 - loss: 0.4396 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.2876\n",
      "Epoch 75/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8264 - auc: 0.9003 - loss: 0.4132 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.2666\n",
      "Epoch 76/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8347 - auc: 0.9011 - loss: 0.4156 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3057\n",
      "Epoch 77/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8223 - auc: 0.8954 - loss: 0.4203 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.2997\n",
      "Epoch 78/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8306 - auc: 0.8941 - loss: 0.4194 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.3187\n",
      "Epoch 79/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8264 - auc: 0.8915 - loss: 0.4305 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.2749\n",
      "Epoch 80/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8993 - loss: 0.4167 - val_accuracy: 0.9000 - val_auc: 0.9732 - val_loss: 0.2861\n",
      "Epoch 81/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.9079 - loss: 0.4073 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3047\n",
      "Epoch 82/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8306 - auc: 0.8725 - loss: 0.4712 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3289\n",
      "Epoch 83/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8058 - auc: 0.8747 - loss: 0.4702 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.2865\n",
      "Epoch 84/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8388 - auc: 0.8833 - loss: 0.4969 - val_accuracy: 0.9000 - val_auc: 0.9777 - val_loss: 0.3590\n",
      "Epoch 85/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8099 - auc: 0.8711 - loss: 0.4801 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.2959\n",
      "Epoch 86/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - auc: 0.9006 - loss: 0.4327 - val_accuracy: 0.9000 - val_auc: 0.9688 - val_loss: 0.3025\n",
      "Epoch 87/300\n",
      "\u001b[1m16/16\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8182 - auc: 0.8784 - loss: 0.5234 - val_accuracy: 0.9000 - val_auc: 0.9598 - val_loss: 0.4233\n",
      "Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\n"
     ]
    }
   ],
   "source": [
    "history_finetune = mlp_finetune.fit(\n",
    "    X_finetune_train, \n",
    "    y_finetune_train,\n",
    "    epochs=300, # Fewer epochs are usually needed for fine-tuning\n",
    "    batch_size=16, # Smaller batch size often works better for smaller datasets\n",
    "    validation_data=(X_finetune_val, y_finetune_val),\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True), \n",
    "    ],\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete. The 'mlp_finetune' model is your final transfer model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03afe4a2-81e2-4c23-8d80-0081becbce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Optimal Threshold (Max F1 on Validation): 0.6765\n",
      "Max F1 Score at this threshold: 0.9630\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Use the fine-tune validation set (X_finetune_val) to find the optimal threshold ---\n",
    "y_val_proba_ft = mlp_finetune.predict(X_finetune_val).ravel()  # Raw probability predictions\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_finetune_val, y_val_proba_ft)\n",
    "\n",
    "# Calculate F1 score for all thresholds\n",
    "fscore = (2 * precision * recall) / (precision + recall + 1e-6)  # Adding 1e-6 to prevent division by zero\n",
    "\n",
    "# Find the threshold that yields the maximum F1 score\n",
    "ix = np.argmax(fscore)\n",
    "best_finetune_threshold = thresholds[ix]\n",
    "\n",
    "print(f\"Optimal Threshold (Max F1 on Validation): {best_finetune_threshold:.4f}\")\n",
    "print(f\"Max F1 Score at this threshold: {fscore[ix]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f96e9a9-99dc-4097-9b40-12d0919b4b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000029C9C4C3920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Finetune Test Accuracy on source domain: 53.23%\n",
      "Finetune Test F1 on source domain: 40.82%\n",
      "Finetune Test Recall (Sensitivity) on source domain: 27.03%\n",
      "Finetune Test Specificity on source domain: 92.00%\n",
      "Finetune Test ROC-AUC on source domain: 0.52%\n"
     ]
    }
   ],
   "source": [
    "# Get raw probability predictions\n",
    "y_pred_proba_a_ft = mlp_finetune.predict(X_pretrain_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions\n",
    "y_pred_a_ft = (y_pred_proba_a_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_a_ft = accuracy_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "f1_a_ft = f1_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "roc_auc_a_ft = roc_auc_score(y_pretrain_test, y_pred_proba_a_ft) * 100\n",
    "recall_a_ft = recall_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "precision_a_ft = precision_score(y_pretrain_test, y_pred_a_ft) * 100\n",
    "specificity_a_ft = recall_score(y_pretrain_test, y_pred_a_ft, pos_label=0) * 100\n",
    "\n",
    "print(f\"Finetune Test Accuracy on source domain: {accuracy_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on source domain: {f1_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on source domain: {recall_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on source domain: {specificity_a_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on source domain: {roc_auc_score(y_pretrain_test, y_pred_proba_a_ft):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2cab0016-9400-41f5-a52c-f41a284ef14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Finetune Test Accuracy on target domain: 80.65%\n",
      "Finetune Test F1 on target domain: 76.92%\n",
      "Finetune Test Recall (Sensitivity) on target domain: 71.43%\n",
      "Finetune Test Specificity on target domain: 88.24%\n",
      "Finetune Test ROC-AUC on target domain:0.89%\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_b_ft = mlp_finetune.predict(X_finetune_test).ravel()\n",
    "\n",
    "# Convert probabilities to binary class predictions using a 0.5 threshold\n",
    "y_pred_b_ft = (y_pred_proba_b_ft > best_finetune_threshold).astype(int)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy_b_ft = accuracy_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "f1_b_ft = f1_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "roc_auc_b_ft = roc_auc_score(y_finetune_test, y_pred_proba_b_ft) * 100\n",
    "recall_b_ft = recall_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "precision_b_ft = precision_score(y_finetune_test, y_pred_b_ft) * 100\n",
    "specificity_b_ft = recall_score(y_finetune_test, y_pred_b_ft, pos_label=0) * 100\n",
    "\n",
    "\n",
    "print(f\"Finetune Test Accuracy on target domain: {accuracy_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test F1 on target domain: {f1_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test Recall (Sensitivity) on target domain: {recall_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test Specificity on target domain: {specificity_b_ft:.2f}%\")\n",
    "print(f\"Finetune Test ROC-AUC on target domain:{roc_auc_score(y_finetune_test, y_pred_proba_b_ft):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41a579-48bb-43e7-a376-f650c63a5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size' : '16'})\n",
    "\n",
    "# Confusion matrix\n",
    "cm_mlp = confusion_matrix(y_finetune_test, y_pred_b_ft)\n",
    "# Unravel the confusion matrix to get TN, FP, FN, TP\n",
    "tn, fp, fn, tp = cm_mlp.ravel()\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "im = plt.imshow(cm_mlp, cmap='Blues', interpolation='nearest') \n",
    "\n",
    "vmax = cm_mlp.max()\n",
    "colorbar_ticks = np.arange(0, vmax + 10, 10)\n",
    "plt.colorbar(im, ticks=colorbar_ticks)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set X-axis labels (Predicted: Disease then No Disease)\n",
    "plt.xticks([0, 1], ['Disease', 'No Disease'])\n",
    "# Set Y-axis labels (Actual: Disease then No Disease)\n",
    "plt.yticks([0, 1], ['No Disease', 'Disease'], rotation=90)  # Horizontal labels\n",
    "\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Dynamic text color for contrast\n",
    "norm = mcolors.Normalize(vmin=cm_mlp.min(), vmax=cm_mlp.max())\n",
    "cmap = plt.colormaps['Blues']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cell_value = cm_mlp[i, j]\n",
    "        cell_color = cmap(norm(cell_value))\n",
    "        luminance = 0.299 * cell_color[0] + 0.587 * cell_color[1] + 0.114 * cell_color[2]\n",
    "        text_color = 'white' if luminance < 0.5 else 'black'\n",
    "        \n",
    "        plt.text(j, i, f'{cell_value}', ha='center', va='center', color=text_color, fontsize=24, fontweight='bold')\n",
    "\n",
    "# Save the confusion matrix image\n",
    "plt.savefig('confusion_matrix_mlp.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13e93627-3128-4f21-a053-1e4f5f70dedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_mlp = mlp_finetune.predict(X_finetune_test)\n",
    "y_pred_prob_tabnet = tabnet_finetuned.predict(X_B_test)\n",
    "y_pred_prob_xgb = xgb_finetune.predict_proba(X_finetune_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "958f0f19-fcd3-4444-b6ee-8111823392c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "MLP AUC (auc function): 0.8908\n",
      "MLP AUC (roc_auc_score): 0.8908\n",
      "TabNet AUC: 0.7689\n",
      "XGBoost AUC: 0.8172\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "plt.rcParams.update({'font.family': 'Times New Roman', 'font.weight': 'bold', 'font.size': 18})\n",
    "\n",
    "# Get predicted probabilities for each model\n",
    "y_pred_prob_mlp = mlp_finetune.predict(X_finetune_test)\n",
    "y_pred_prob_tabnet = tabnet_finetuned.predict(X_B_test)  # Probabilities for the positive class (ROC)\n",
    "y_pred_proba_xgb = xgb_finetune.predict(X_finetune_test) \n",
    "\n",
    "# Calculate ROC curve and AUC for each model\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_finetune_test, y_pred_prob_mlp)\n",
    "fpr_tabnet, tpr_tabnet, _ = roc_curve(y_B_test, y_pred_prob_tabnet)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Calculate AUC for each model\n",
    "roc_auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "roc_auc_tabnet = auc(fpr_tabnet, tpr_tabnet)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(y_finetune_test, Dataset_B_Finetune)\n",
    "\n",
    "# Also calculate using roc_auc_score for verification\n",
    "roc_auc_score_mlp = roc_auc_score(y_B_test, y_pred_prob_mlp)\n",
    "roc_auc_score_tabnet = roc_auc_score(y_B_test, y_pred_prob_tabnet)\n",
    "roc_auc_score_xgb = roc_auc_score(y_B_test, y_pred_proba_xgb)\n",
    "\n",
    "print(f\"MLP AUC (auc function): {roc_auc_mlp:.4f}\")\n",
    "print(f\"MLP AUC (roc_auc_score): {roc_auc_score_mlp:.4f}\")\n",
    "print(f\"TabNet AUC: {roc_auc_tabnet:.4f}\")\n",
    "print(f\"XGBoost AUC: {roc_auc_xgb:.4f}\")\n",
    "\n",
    "# Plot combined ROC curve\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot each ROC curve\n",
    "plt.plot(fpr_mlp, tpr_mlp, color='red', lw=2, label=f'MLP (AUC = {roc_auc_mlp:.2f})')\n",
    "plt.plot(fpr_tabnet, tpr_tabnet, color='green', lw=2, label=f'TabNet (AUC = {roc_auc_tabnet:.2f})')\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='orange', lw=2, label=f'XGBoost (AUC = {roc_auc_xgb:.2f})')\n",
    "\n",
    "# Diagonal line for random classifier\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', lw=2, linestyle='--')\n",
    "\n",
    "# Adjust plot settings\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('Combined ROC Curve for Fine-Tuned Models')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Save the combined ROC curve\n",
    "plt.savefig('roc_curve_combined.png', dpi=300, bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f768dd-9508-4dc0-81b2-d060810cb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from your table\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "# Model performance data\n",
    "xgboost = {\n",
    "    \"Accuracy\": [85.48, 88.71, 90.32, 83.87],\n",
    "    \"F1-Score\": [84.85, 88.37, 89.66, 83.87],\n",
    "    \"Sensitivity\": [85.71, 92.86, 92.86, 92.86],\n",
    "    \"Specificity\": [85.29, 85.29, 88.24, 76.47]\n",
    "}\n",
    "\n",
    "tabnet = {\n",
    "    \"Accuracy\": [80.65, 82.26, 83.87, 77.42],\n",
    "    \"F1-Score\": [82.76, 83.33, 84.85, 78.79],\n",
    "    \"Sensitivity\": [92.86, 100.00, 100.00, 85.71],\n",
    "    \"Specificity\": [70.59, 70.59, 70.59, 70.59]\n",
    "}\n",
    "\n",
    "mlp = {\n",
    "    \"Accuracy\": [83.87, 85.48, 87.10, 79.03],\n",
    "    \"F1-Score\": [82.76, 84.21, 85.71, 78.13],\n",
    "    \"Sensitivity\": [85.71, 85.71, 85.71, 78.57],\n",
    "    \"Specificity\": [82.35, 85.29, 88.24, 79.41]\n",
    "}\n",
    "\n",
    "resnet = {\n",
    "    \"Accuracy\": [85.48, 87.10, 88.71, 83.87],\n",
    "    \"F1-Score\": [85.71, 87.18, 88.37, 84.21],\n",
    "    \"Sensitivity\": [92.86, 92.86, 92.86, 92.86],\n",
    "    \"Specificity\": [79.41, 82.35, 85.29, 76.47]\n",
    "}\n",
    "\n",
    "# List of models for iteration\n",
    "models = ['XGBoost', 'TabNet', 'MLP', 'ResNet']\n",
    "metrics = ['Accuracy', 'F1-Score', 'Sensitivity', 'Specificity']\n",
    "\n",
    "# Plotting graphs for each model and metric\n",
    "for model, data in zip(models, [xgboost, tabnet, mlp, resnet]):\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(learning_rates, data[metric], marker='P', linestyle='-', label=f'{model} - {metric}')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{model} - {metric} vs Learning Rate')\n",
    "        plt.xscale('log')  # Log scale for better visualization if needed\n",
    "        plt.xticks(learning_rates)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        # Save the image\n",
    "        plt.savefig(f'{model}_{metric}_vs_learning_rate.png')\n",
    "        plt.close()  # Close the plot to prevent overlapping with the next one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de987cf3-400e-4aae-a75e-f89021b617ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
